{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWZXS3eKoeND"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "levXP7WqERZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6yg_2AppgFX",
        "outputId": "d6ca4c15-2150-4a9b-fb00-063d10838484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxnlERggq-n_",
        "outputId": "f5379fd7-75fe-4675-f6e7-aa82850806f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "ytpkdhRZrvHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "MLxbueDis9m3",
        "outputId": "4e4ef1c4-41eb-4090-b63b-018030261b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d137511-a02e-4c9f-a602-7582de6e3a54\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d137511-a02e-4c9f-a602-7582de6e3a54\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"selimaygn\",\"key\":\"2211657622f8a3e34a1fbcf241a8a719\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "9IEWBorZtDER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "GiTwqeVmtPzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d dbdmobile/myanimelist-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcy9zeh4tXsf",
        "outputId": "2134e039-3e90-46f2-ddfa-7b827fd4f181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading myanimelist-dataset.zip to /content\n",
            "100% 1.80G/1.80G [00:21<00:00, 54.5MB/s]\n",
            "100% 1.80G/1.80G [00:21<00:00, 88.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir myanimelist-dataset"
      ],
      "metadata": {
        "id": "wYsfVlXLtrKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip myanimelist-dataset.zip -d myanimelist-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcBvukY_t10N",
        "outputId": "f00461ca-2a5d-42be-b966-5a4c98992102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  myanimelist-dataset.zip\n",
            "  inflating: myanimelist-dataset/anime-dataset-2023.csv  \n",
            "  inflating: myanimelist-dataset/anime-filtered.csv  \n",
            "  inflating: myanimelist-dataset/final_animedataset.csv  \n",
            "  inflating: myanimelist-dataset/user-filtered.csv  \n",
            "  inflating: myanimelist-dataset/users-details-2023.csv  \n",
            "  inflating: myanimelist-dataset/users-score-2023.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/myanimelist-dataset')\n"
      ],
      "metadata": {
        "id": "_za1sXcbvufQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a DataFrame named df with an index column\n",
        "df = pd.read_csv('users-score-2023.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnzMeIOUwD1x",
        "outputId": "6733779f-3388-43ae-fd53-0a5c7e2fdec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 24325191 entries, 0 to 24325190\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Dtype \n",
            "---  ------       ----- \n",
            " 0   user_id      int64 \n",
            " 1   Username     object\n",
            " 2   anime_id     int64 \n",
            " 3   Anime Title  object\n",
            " 4   rating       int64 \n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 927.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Username', 'Anime Title'], axis=1)"
      ],
      "metadata": {
        "id": "Na3lkK4RwVpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rating.value_counts() # Count of each rating"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXRFMZBpwYsu",
        "outputId": "59fa31d7-523d-452e-f5e1-331e81f97fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8     6060484\n",
              "7     5452152\n",
              "9     4429914\n",
              "10    3210021\n",
              "6     2766482\n",
              "5     1379480\n",
              "4      562822\n",
              "3      233675\n",
              "2      132092\n",
              "1       98069\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "23oNw_Jc5lQE",
        "outputId": "3c5baea7-167b-41ce-ba4c-4e3d576f3e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  anime_id  rating\n",
              "0        1        21       9\n",
              "1        1        48       7\n",
              "2        1       320       5\n",
              "3        1        49       8\n",
              "4        1       304       8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f50ca2ea-73ae-4a72-bc31-80d0038518bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>304</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f50ca2ea-73ae-4a72-bc31-80d0038518bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f50ca2ea-73ae-4a72-bc31-80d0038518bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f50ca2ea-73ae-4a72-bc31-80d0038518bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfe32e32-2258-4b5e-a1f7-9f9590c115a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfe32e32-2258-4b5e-a1f7-9f9590c115a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfe32e32-2258-4b5e-a1f7-9f9590c115a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete users after the 100,000th user id\n",
        "threshold = 800\n",
        "df = df[df['user_id'] <= threshold]\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Write the updated DataFrame to a new CSV file\n",
        "df.to_csv('updated_userr_data.csv', index=False)"
      ],
      "metadata": {
        "id": "tV3GE844hs_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "H54-XLutik8n",
        "outputId": "7fca0df8-e114-4e3f-a62c-e42ae3ebafb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       user_id  anime_id  rating\n",
              "0            1        21       9\n",
              "1            1        48       7\n",
              "2            1       320       5\n",
              "3            1        49       8\n",
              "4            1       304       8\n",
              "...        ...       ...     ...\n",
              "48098      797      1221       4\n",
              "48099      797       232       3\n",
              "48100      797       859       5\n",
              "48101      797       690       1\n",
              "48102      797         6       4\n",
              "\n",
              "[48103 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-217a8854-f025-458c-a9f6-99f41b80a75f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>320</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>304</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48098</th>\n",
              "      <td>797</td>\n",
              "      <td>1221</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48099</th>\n",
              "      <td>797</td>\n",
              "      <td>232</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48100</th>\n",
              "      <td>797</td>\n",
              "      <td>859</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48101</th>\n",
              "      <td>797</td>\n",
              "      <td>690</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48102</th>\n",
              "      <td>797</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48103 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-217a8854-f025-458c-a9f6-99f41b80a75f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-217a8854-f025-458c-a9f6-99f41b80a75f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-217a8854-f025-458c-a9f6-99f41b80a75f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a968464a-593a-4ebf-8e34-88d143653546\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a968464a-593a-4ebf-8e34-88d143653546')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a968464a-593a-4ebf-8e34-88d143653546 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d4bf4a72-6f09-450a-8385-fdddad1349b0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d4bf4a72-6f09-450a-8385-fdddad1349b0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimeDataset:\n",
        "    def __init__(self, users, animes, ratings):\n",
        "        self.users = users\n",
        "        self.animes = animes\n",
        "        self.ratings = ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.users)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        users = self.users[item]\n",
        "        animes = self.animes[item]\n",
        "        ratings = self.ratings[item]\n",
        "\n",
        "        return {\n",
        "            'users': torch.tensor(users, dtype=torch.long),\n",
        "            'animes': torch.tensor(animes, dtype=torch.long),\n",
        "            'ratings': torch.tensor(ratings, dtype=torch.long),\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Ay5QMQKW0LvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecSysModel(nn.Module):\n",
        "    def __init__(self, n_users, n_animes):\n",
        "        super().__init__()\n",
        "        # trainable lookup matrix for shallow embedding vectors\n",
        "        self.user_embed = nn.Embedding(n_users, 32)\n",
        "        self.anime_embed = nn.Embedding(n_animes, 32)\n",
        "        # hidden layer\n",
        "        self.hidden = nn.Linear(64, 32)\n",
        "        # output layer\n",
        "        self.out = nn.Linear(32, 1)\n",
        "        # activation function\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, users, animes, ratings=None):\n",
        "        user_embeds = self.user_embed(users)\n",
        "        anime_embeds = self.anime_embed(animes)\n",
        "        x = torch.cat([user_embeds, anime_embeds], dim=1)\n",
        "        # pass through hidden layer\n",
        "        x = self.hidden(x)\n",
        "        x = self.activation(x)\n",
        "        output = self.out(x)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "MZKlMhT73fsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing, model_selection\n",
        "\n",
        "# encode the user and anime id to start from 0 so we don't run into index out of bound with Embedding\n",
        "lbl_user = preprocessing.LabelEncoder()\n",
        "lbl_anime = preprocessing.LabelEncoder()\n",
        "df.user_id = lbl_user.fit_transform(df.user_id.values)\n",
        "df.anime_id = lbl_anime.fit_transform(df.anime_id.values)\n",
        "\n",
        "df_train, df_valid = model_selection.train_test_split(\n",
        "    df, test_size=0.1, random_state=42, stratify=df.rating.values\n",
        ")\n",
        "\n",
        "train_dataset = AnimeDataset(\n",
        "    users=df_train.user_id.values,\n",
        "    animes=df_train.anime_id.values,\n",
        "    ratings=df_train.rating.values\n",
        ")\n",
        "\n",
        "valid_dataset = AnimeDataset(\n",
        "    users=df_valid.user_id.values,\n",
        "    animes=df_valid.anime_id.values,\n",
        "    ratings=df_valid.rating.values\n",
        ")\n"
      ],
      "metadata": {
        "id": "C0tsA0wm0owP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "    batch_size=4,\n",
        "    num_workers=2)\n",
        "\n",
        "validation_loader = DataLoader(dataset=valid_dataset,\n",
        "    batch_size=4,\n",
        "    num_workers=2)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "dataloader_data = dataiter.__next__()\n",
        "print(dataloader_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmfgZdub05UH",
        "outputId": "98063418-03f3-4293-9c87-1fffabb109a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'users': tensor([219, 148, 153, 112]), 'animes': tensor([4283, 3728,  439,  451]), 'ratings': tensor([8, 9, 8, 6])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RecSysModel(\n",
        "    n_users=len(lbl_user.classes_),\n",
        "    n_animes=len(lbl_anime.classes_),\n",
        ").to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "print(len(lbl_user.classes_))\n",
        "print(len(lbl_anime.classes_))\n",
        "print(df.anime_id.max())\n",
        "print(len(train_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztxu4UsRDQ0E",
        "outputId": "36939954-ed68-40e9-8fe0-07fa39c51844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236\n",
            "5810\n",
            "5809\n",
            "43292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataloader_data['users'])\n",
        "print(dataloader_data['users'].size())\n",
        "print(dataloader_data['animes'])\n",
        "print(dataloader_data['animes'].size())\n",
        "user_embed = nn.Embedding(len(lbl_user.classes_), 32)\n",
        "anime_embed = nn.Embedding(len(lbl_anime.classes_), 32)\n",
        "out = nn.Linear(64, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpKUrayRCuUJ",
        "outputId": "97daf993-a7be-4b7e-a53e-7912d41c88d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([219, 148, 153, 112])\n",
            "torch.Size([4])\n",
            "tensor([4283, 3728,  439,  451])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeds = user_embed(dataloader_data['users'])\n",
        "anime_embeds = anime_embed(dataloader_data['animes'])\n",
        "print(f\"user_embeds {user_embeds.size()}\")\n",
        "print(f\"user_embeds {user_embeds}\")\n",
        "\n",
        "print(f\"anime_embeds {anime_embeds.size()}\")\n",
        "print(f\"anime_embeds {anime_embeds}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fGifxryEqce",
        "outputId": "4007e2be-5ce4-48ed-da37-fd51c7af9883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user_embeds torch.Size([4, 32])\n",
            "user_embeds tensor([[-0.3251,  0.3353, -0.3637,  0.2465, -0.1960, -0.9632,  1.6926,  1.4058,\n",
            "          0.6570, -1.7376,  2.0150, -0.3514,  1.0254,  0.9068, -0.3824,  0.1586,\n",
            "          0.2370,  0.5138,  0.3973,  0.2801, -0.2476, -0.0795, -1.0306,  1.1178,\n",
            "          1.1902,  1.2711, -0.0895, -1.0493, -0.3827, -0.7957,  1.4933, -1.2286],\n",
            "        [ 2.1587, -0.4387,  0.0128, -0.4048, -1.2158, -0.9304, -0.7692, -0.7243,\n",
            "         -0.5725,  0.4232,  1.0663, -0.4102, -0.8984, -0.1411,  0.4718,  0.2453,\n",
            "          1.5104,  0.3618, -0.0384,  0.7564,  1.8981, -1.0455, -0.7017,  0.3638,\n",
            "         -0.1137, -0.5155,  1.3155, -0.5152,  1.1457, -0.5372, -1.3169, -2.3833],\n",
            "        [-1.3951, -0.2399,  0.9798,  0.4603, -0.4096,  0.7480,  1.5816, -0.3328,\n",
            "          1.0690,  1.7428,  1.2825, -0.1802, -0.0786, -0.5064, -0.0680, -0.2241,\n",
            "         -0.6549, -0.1813,  0.2172, -1.1393, -0.3796,  0.0616, -0.1430, -0.4901,\n",
            "          0.6916, -1.0638, -0.2092, -0.5586,  0.8687, -0.3716, -0.4819, -0.0793],\n",
            "        [ 0.5195,  0.9200,  0.7274, -0.1604,  0.0087,  0.2986, -0.7392,  0.2276,\n",
            "          0.0184,  0.2049, -0.6170,  2.1771, -0.1257,  0.3664,  0.3289,  0.8703,\n",
            "         -1.3675, -0.5052, -0.5362,  1.0171,  2.2226, -0.5035,  0.8899, -0.7315,\n",
            "          0.9115,  2.7544,  1.5880,  0.8312,  0.3963,  2.1068, -1.3354, -0.0811]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "anime_embeds torch.Size([4, 32])\n",
            "anime_embeds tensor([[ 0.4034,  0.3106,  0.6807,  0.4948,  0.4996,  0.4766, -0.5311,  0.8023,\n",
            "         -0.5759,  0.5897,  0.6038,  0.1869, -1.9695, -2.2420, -2.1162, -0.3370,\n",
            "         -0.3322,  0.5389, -0.4216,  1.8618,  0.9881,  2.5928,  1.4862,  0.7208,\n",
            "          1.5716,  0.5388,  1.0691,  0.4490,  1.7645, -0.3221,  0.0948, -0.1027],\n",
            "        [-0.7674,  0.8923, -0.3522,  0.9421, -1.3564, -0.1291, -1.0565, -0.1079,\n",
            "         -0.6940,  0.1891,  0.9766, -0.0664, -0.1906, -0.9743,  1.3231,  0.1755,\n",
            "         -0.2275,  0.8182, -0.8851, -0.4826,  1.2774, -2.3619,  0.5328, -0.6748,\n",
            "         -0.4376, -0.1428,  0.0762, -1.0452,  1.5655,  1.8064, -0.5404, -0.8354],\n",
            "        [-0.3033,  0.8906,  0.7545,  0.5482,  1.7804, -0.3220,  1.1756,  0.5015,\n",
            "          0.0900,  1.1492, -0.0776,  1.3181,  0.2151,  0.5503, -2.3662,  0.1003,\n",
            "         -0.2172,  1.2400, -2.1741, -0.3902,  0.0700, -1.5077, -2.3029, -1.7046,\n",
            "          0.5702,  0.2104,  1.1803, -1.6425,  0.0664, -1.1061,  0.3083,  0.6981],\n",
            "        [ 0.4265, -0.4976,  0.9627, -0.2197, -0.7466,  0.5334,  1.8464,  0.3776,\n",
            "          0.4402,  0.0707,  0.4887, -1.4813,  0.4457, -1.2659, -0.6267, -0.9980,\n",
            "         -0.5930, -0.1577,  0.5783, -0.6362, -0.2201, -0.1386, -0.0704, -0.9200,\n",
            "         -2.3621, -0.0174,  0.5050, -0.3919, -0.4725, -1.2348,  0.1481, -0.2908]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.cat([user_embeds, anime_embeds], dim=1)\n",
        "print(f\"output: {output.size()}\")\n",
        "print(f\"output: {output}\")\n",
        "output = out(output)\n",
        "print(f\"output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzEdeCfuFVn8",
        "outputId": "763753b0-7647-4257-dc66-7ba9c0905d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output: torch.Size([4, 64])\n",
            "output: tensor([[-0.3251,  0.3353, -0.3637,  0.2465, -0.1960, -0.9632,  1.6926,  1.4058,\n",
            "          0.6570, -1.7376,  2.0150, -0.3514,  1.0254,  0.9068, -0.3824,  0.1586,\n",
            "          0.2370,  0.5138,  0.3973,  0.2801, -0.2476, -0.0795, -1.0306,  1.1178,\n",
            "          1.1902,  1.2711, -0.0895, -1.0493, -0.3827, -0.7957,  1.4933, -1.2286,\n",
            "          0.4034,  0.3106,  0.6807,  0.4948,  0.4996,  0.4766, -0.5311,  0.8023,\n",
            "         -0.5759,  0.5897,  0.6038,  0.1869, -1.9695, -2.2420, -2.1162, -0.3370,\n",
            "         -0.3322,  0.5389, -0.4216,  1.8618,  0.9881,  2.5928,  1.4862,  0.7208,\n",
            "          1.5716,  0.5388,  1.0691,  0.4490,  1.7645, -0.3221,  0.0948, -0.1027],\n",
            "        [ 2.1587, -0.4387,  0.0128, -0.4048, -1.2158, -0.9304, -0.7692, -0.7243,\n",
            "         -0.5725,  0.4232,  1.0663, -0.4102, -0.8984, -0.1411,  0.4718,  0.2453,\n",
            "          1.5104,  0.3618, -0.0384,  0.7564,  1.8981, -1.0455, -0.7017,  0.3638,\n",
            "         -0.1137, -0.5155,  1.3155, -0.5152,  1.1457, -0.5372, -1.3169, -2.3833,\n",
            "         -0.7674,  0.8923, -0.3522,  0.9421, -1.3564, -0.1291, -1.0565, -0.1079,\n",
            "         -0.6940,  0.1891,  0.9766, -0.0664, -0.1906, -0.9743,  1.3231,  0.1755,\n",
            "         -0.2275,  0.8182, -0.8851, -0.4826,  1.2774, -2.3619,  0.5328, -0.6748,\n",
            "         -0.4376, -0.1428,  0.0762, -1.0452,  1.5655,  1.8064, -0.5404, -0.8354],\n",
            "        [-1.3951, -0.2399,  0.9798,  0.4603, -0.4096,  0.7480,  1.5816, -0.3328,\n",
            "          1.0690,  1.7428,  1.2825, -0.1802, -0.0786, -0.5064, -0.0680, -0.2241,\n",
            "         -0.6549, -0.1813,  0.2172, -1.1393, -0.3796,  0.0616, -0.1430, -0.4901,\n",
            "          0.6916, -1.0638, -0.2092, -0.5586,  0.8687, -0.3716, -0.4819, -0.0793,\n",
            "         -0.3033,  0.8906,  0.7545,  0.5482,  1.7804, -0.3220,  1.1756,  0.5015,\n",
            "          0.0900,  1.1492, -0.0776,  1.3181,  0.2151,  0.5503, -2.3662,  0.1003,\n",
            "         -0.2172,  1.2400, -2.1741, -0.3902,  0.0700, -1.5077, -2.3029, -1.7046,\n",
            "          0.5702,  0.2104,  1.1803, -1.6425,  0.0664, -1.1061,  0.3083,  0.6981],\n",
            "        [ 0.5195,  0.9200,  0.7274, -0.1604,  0.0087,  0.2986, -0.7392,  0.2276,\n",
            "          0.0184,  0.2049, -0.6170,  2.1771, -0.1257,  0.3664,  0.3289,  0.8703,\n",
            "         -1.3675, -0.5052, -0.5362,  1.0171,  2.2226, -0.5035,  0.8899, -0.7315,\n",
            "          0.9115,  2.7544,  1.5880,  0.8312,  0.3963,  2.1068, -1.3354, -0.0811,\n",
            "          0.4265, -0.4976,  0.9627, -0.2197, -0.7466,  0.5334,  1.8464,  0.3776,\n",
            "          0.4402,  0.0707,  0.4887, -1.4813,  0.4457, -1.2659, -0.6267, -0.9980,\n",
            "         -0.5930, -0.1577,  0.5783, -0.6362, -0.2201, -0.1386, -0.0704, -0.9200,\n",
            "         -2.3621, -0.0174,  0.5050, -0.3919, -0.4725, -1.2348,  0.1481, -0.2908]],\n",
            "       grad_fn=<CatBackward0>)\n",
            "output: tensor([[-0.2534],\n",
            "        [-0.1639],\n",
            "        [ 0.4056],\n",
            "        [-0.3726]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "with torch.no_grad():\n",
        "    model_output = model(dataloader_data['users'],\n",
        "                         dataloader_data['animes'])\n",
        "    print(f\"model_output: {model_output}, size: {model_output.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGHwpmpWGEzH",
        "outputId": "4f2fb494-fc47-4997-ef1b-2f8fa24e38ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([[-0.0230],\n",
            "        [-0.6325],\n",
            "        [-0.0508],\n",
            "        [ 0.0754]]), size: torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rating = dataloader_data['ratings']\n",
        "print(rating)\n",
        "print(rating.view(-1))\n",
        "print(model_output)\n",
        "\n",
        "print(rating.sum())\n",
        "\n",
        "print(model_output.sum() - rating.sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOFl1PbdIQOi",
        "outputId": "0a809cff-8ed4-4b77-f852-4c28fe68778d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8, 9, 8, 6])\n",
            "tensor([8, 9, 8, 6])\n",
            "tensor([[-0.0230],\n",
            "        [-0.6325],\n",
            "        [-0.0508],\n",
            "        [ 0.0754]])\n",
            "tensor(31)\n",
            "tensor(-31.6309)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "total_loss = 0\n",
        "plot_steps, print_steps = 5000, 5000\n",
        "step_cnt = 0\n",
        "all_losses_list = []\n",
        "\n",
        "model.train()\n",
        "for epoch_i in range(epochs):\n",
        "    for i, train_data in enumerate(train_loader):\n",
        "        output = model(train_data[\"users\"],\n",
        "                       train_data[\"animes\"]\n",
        "                      )\n",
        "\n",
        "        # .view(4, -1) is to reshape the rating to match the shape of model output which is 4x1\n",
        "        rating = train_data[\"ratings\"].view(4, -1).to(torch.float32)\n",
        "\n",
        "        loss = loss_func(output, rating)\n",
        "        total_loss = total_loss + loss.sum().item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step_cnt = step_cnt + len(train_data[\"users\"])\n",
        "\n",
        "\n",
        "        if(step_cnt % plot_steps == 0):\n",
        "            avg_loss = total_loss/(len(train_data[\"users\"]) * plot_steps)\n",
        "            print(f\"epoch {epoch_i} loss at step: {step_cnt} is {avg_loss}\")\n",
        "            all_losses_list.append(avg_loss)\n",
        "            total_loss = 0 # reset total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4-JppljI5P0",
        "outputId": "c2373f00-9adc-4952-afdb-15954113445b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 loss at step: 2000 is 1.6836917541697622\n",
            "epoch 0 loss at step: 4000 is 0.22381368218362332\n",
            "epoch 0 loss at step: 6000 is 0.1634518885728903\n",
            "epoch 0 loss at step: 8000 is 0.16391209224658088\n",
            "epoch 0 loss at step: 10000 is 0.15719036934431643\n",
            "epoch 0 loss at step: 12000 is 0.16123413025494665\n",
            "epoch 0 loss at step: 14000 is 0.1510040870271623\n",
            "epoch 0 loss at step: 16000 is 0.13615582848060875\n",
            "epoch 0 loss at step: 18000 is 0.14405542230885476\n",
            "epoch 0 loss at step: 20000 is 0.1510769514008425\n",
            "epoch 0 loss at step: 22000 is 0.14005491666169836\n",
            "epoch 0 loss at step: 24000 is 0.14351680117240176\n",
            "epoch 0 loss at step: 26000 is 0.14112303407862783\n",
            "epoch 0 loss at step: 28000 is 0.1347235747803934\n",
            "epoch 0 loss at step: 30000 is 0.14386956802196801\n",
            "epoch 0 loss at step: 32000 is 0.14322830475540832\n",
            "epoch 0 loss at step: 34000 is 0.13304953653458507\n",
            "epoch 0 loss at step: 36000 is 0.14134274826094043\n",
            "epoch 0 loss at step: 38000 is 0.13035025581205265\n",
            "epoch 0 loss at step: 40000 is 0.1307138898856938\n",
            "epoch 0 loss at step: 42000 is 0.14152527406066656\n",
            "epoch 1 loss at step: 44000 is 0.13892326516006143\n",
            "epoch 1 loss at step: 46000 is 0.1297649755824823\n",
            "epoch 1 loss at step: 48000 is 0.1203671597475186\n",
            "epoch 1 loss at step: 50000 is 0.12344334276067093\n",
            "epoch 1 loss at step: 52000 is 0.12106766734924167\n",
            "epoch 1 loss at step: 54000 is 0.1348106105113402\n",
            "epoch 1 loss at step: 56000 is 0.12562204835703597\n",
            "epoch 1 loss at step: 58000 is 0.1111031398260966\n",
            "epoch 1 loss at step: 60000 is 0.11801398770976812\n",
            "epoch 1 loss at step: 62000 is 0.12519567827135325\n",
            "epoch 1 loss at step: 64000 is 0.12747726452816277\n",
            "epoch 1 loss at step: 66000 is 0.11738193316850812\n",
            "epoch 1 loss at step: 68000 is 0.11770112902857363\n",
            "epoch 1 loss at step: 70000 is 0.12394219475565478\n",
            "epoch 1 loss at step: 72000 is 0.11879045723215677\n",
            "epoch 1 loss at step: 74000 is 0.12094688503723591\n",
            "epoch 1 loss at step: 76000 is 0.12249007119517773\n",
            "epoch 1 loss at step: 78000 is 0.11514094729349017\n",
            "epoch 1 loss at step: 80000 is 0.12260581943835132\n",
            "epoch 1 loss at step: 82000 is 0.11159523952798918\n",
            "epoch 1 loss at step: 84000 is 0.11912358948495239\n",
            "epoch 1 loss at step: 86000 is 0.12151089505851269\n",
            "epoch 2 loss at step: 88000 is 0.12275577818782767\n",
            "epoch 2 loss at step: 90000 is 0.1095280916702468\n",
            "epoch 2 loss at step: 92000 is 0.11064956451393664\n",
            "epoch 2 loss at step: 94000 is 0.10671691492106765\n",
            "epoch 2 loss at step: 96000 is 0.11191190799698233\n",
            "epoch 2 loss at step: 98000 is 0.11659295009518973\n",
            "epoch 2 loss at step: 100000 is 0.10907429588679224\n",
            "epoch 2 loss at step: 102000 is 0.10174390311632306\n",
            "epoch 2 loss at step: 104000 is 0.10677531656436622\n",
            "epoch 2 loss at step: 106000 is 0.11314939332706854\n",
            "epoch 2 loss at step: 108000 is 0.1111601725704968\n",
            "epoch 2 loss at step: 110000 is 0.11310246904846281\n",
            "epoch 2 loss at step: 112000 is 0.10060598908970132\n",
            "epoch 2 loss at step: 114000 is 0.1110786811648868\n",
            "epoch 2 loss at step: 116000 is 0.11011864280584269\n",
            "epoch 2 loss at step: 118000 is 0.1129274812634103\n",
            "epoch 2 loss at step: 120000 is 0.10849445847450988\n",
            "epoch 2 loss at step: 122000 is 0.10260870156390592\n",
            "epoch 2 loss at step: 124000 is 0.1102887868708931\n",
            "epoch 2 loss at step: 126000 is 0.10634727873140946\n",
            "epoch 2 loss at step: 128000 is 0.11143412929866463\n",
            "epoch 3 loss at step: 130000 is 0.11293873282871209\n",
            "epoch 3 loss at step: 132000 is 0.10756046511232853\n",
            "epoch 3 loss at step: 134000 is 0.10189158315374516\n",
            "epoch 3 loss at step: 136000 is 0.0978814637772739\n",
            "epoch 3 loss at step: 138000 is 0.09992576076241676\n",
            "epoch 3 loss at step: 140000 is 0.10254034729901468\n",
            "epoch 3 loss at step: 142000 is 0.10365071187174181\n",
            "epoch 3 loss at step: 144000 is 0.09957692789845168\n",
            "epoch 3 loss at step: 146000 is 0.0979238131120801\n",
            "epoch 3 loss at step: 148000 is 0.10195935009978711\n",
            "epoch 3 loss at step: 150000 is 0.10549049641401508\n",
            "epoch 3 loss at step: 152000 is 0.1004464015988633\n",
            "epoch 3 loss at step: 154000 is 0.1039334691055119\n",
            "epoch 3 loss at step: 156000 is 0.10171597281331196\n",
            "epoch 3 loss at step: 158000 is 0.09900921215233394\n",
            "epoch 3 loss at step: 160000 is 0.10538525164127349\n",
            "epoch 3 loss at step: 162000 is 0.10232946396782062\n",
            "epoch 3 loss at step: 164000 is 0.09897148286446464\n",
            "epoch 3 loss at step: 166000 is 0.1049257298191078\n",
            "epoch 3 loss at step: 168000 is 0.09546703274734318\n",
            "epoch 3 loss at step: 170000 is 0.09963045437214896\n",
            "epoch 3 loss at step: 172000 is 0.10878255693847314\n",
            "epoch 4 loss at step: 174000 is 0.1066289075280074\n",
            "epoch 4 loss at step: 176000 is 0.0993716204869561\n",
            "epoch 4 loss at step: 178000 is 0.09047264623967931\n",
            "epoch 4 loss at step: 180000 is 0.0925851032868959\n",
            "epoch 4 loss at step: 182000 is 0.09208385737182107\n",
            "epoch 4 loss at step: 184000 is 0.10472708858316765\n",
            "epoch 4 loss at step: 186000 is 0.09725008976855315\n",
            "epoch 4 loss at step: 188000 is 0.08651840719184838\n",
            "epoch 4 loss at step: 190000 is 0.09374926228402182\n",
            "epoch 4 loss at step: 192000 is 0.10088126075291075\n",
            "epoch 4 loss at step: 194000 is 0.1013767995549133\n",
            "epoch 4 loss at step: 196000 is 0.09082527575013227\n",
            "epoch 4 loss at step: 198000 is 0.096217030542437\n",
            "epoch 4 loss at step: 200000 is 0.09806131967762485\n",
            "epoch 4 loss at step: 202000 is 0.09656230672961101\n",
            "epoch 4 loss at step: 204000 is 0.09903886797651648\n",
            "epoch 4 loss at step: 206000 is 0.09743250652239657\n",
            "epoch 4 loss at step: 208000 is 0.09260401539260056\n",
            "epoch 4 loss at step: 210000 is 0.09828351833485068\n",
            "epoch 4 loss at step: 212000 is 0.09202182886516676\n",
            "epoch 4 loss at step: 214000 is 0.09862191548128613\n",
            "epoch 4 loss at step: 216000 is 0.10097224727319554\n",
            "epoch 5 loss at step: 218000 is 0.10001023764070123\n",
            "epoch 5 loss at step: 220000 is 0.09110204823664389\n",
            "epoch 5 loss at step: 222000 is 0.08759339776565321\n",
            "epoch 5 loss at step: 224000 is 0.08670861333888025\n",
            "epoch 5 loss at step: 226000 is 0.09234897651686333\n",
            "epoch 5 loss at step: 228000 is 0.09663065434980672\n",
            "epoch 5 loss at step: 230000 is 0.09172722067125141\n",
            "epoch 5 loss at step: 232000 is 0.08589607747492846\n",
            "epoch 5 loss at step: 234000 is 0.08953670695365873\n",
            "epoch 5 loss at step: 236000 is 0.09628223203634843\n",
            "epoch 5 loss at step: 238000 is 0.09245572763180826\n",
            "epoch 5 loss at step: 240000 is 0.09503353594592773\n",
            "epoch 5 loss at step: 242000 is 0.08627961539197714\n",
            "epoch 5 loss at step: 244000 is 0.09272749024652877\n",
            "epoch 5 loss at step: 246000 is 0.0944216057928279\n",
            "epoch 5 loss at step: 248000 is 0.095671570883831\n",
            "epoch 5 loss at step: 250000 is 0.09190304684778676\n",
            "epoch 5 loss at step: 252000 is 0.08821676916815341\n",
            "epoch 5 loss at step: 254000 is 0.09225081382971256\n",
            "epoch 5 loss at step: 256000 is 0.09140958860283717\n",
            "epoch 5 loss at step: 258000 is 0.0954702604552731\n",
            "epoch 6 loss at step: 260000 is 0.09666982064582408\n",
            "epoch 6 loss at step: 262000 is 0.09163098729716149\n",
            "epoch 6 loss at step: 264000 is 0.0864881644663401\n",
            "epoch 6 loss at step: 266000 is 0.08488594744168222\n",
            "epoch 6 loss at step: 268000 is 0.08202808260777965\n",
            "epoch 6 loss at step: 270000 is 0.09050428815418854\n",
            "epoch 6 loss at step: 272000 is 0.09054274656181224\n",
            "epoch 6 loss at step: 274000 is 0.0830683710060548\n",
            "epoch 6 loss at step: 276000 is 0.08621864604065195\n",
            "epoch 6 loss at step: 278000 is 0.09115144923725166\n",
            "epoch 6 loss at step: 280000 is 0.08894193764892407\n",
            "epoch 6 loss at step: 282000 is 0.08786642512399703\n",
            "epoch 6 loss at step: 284000 is 0.0906473195029539\n",
            "epoch 6 loss at step: 286000 is 0.08800099111162125\n",
            "epoch 6 loss at step: 288000 is 0.08972187499096618\n",
            "epoch 6 loss at step: 290000 is 0.08759237066656352\n",
            "epoch 6 loss at step: 292000 is 0.0908943214872852\n",
            "epoch 6 loss at step: 294000 is 0.08629134807235096\n",
            "epoch 6 loss at step: 296000 is 0.09289053162606432\n",
            "epoch 6 loss at step: 298000 is 0.08198002192692365\n",
            "epoch 6 loss at step: 300000 is 0.0876583528961055\n",
            "epoch 6 loss at step: 302000 is 0.09569399196119048\n",
            "epoch 7 loss at step: 304000 is 0.09174027742969337\n",
            "epoch 7 loss at step: 306000 is 0.087850124145858\n",
            "epoch 7 loss at step: 308000 is 0.07949339585565031\n",
            "epoch 7 loss at step: 310000 is 0.07972709197713994\n",
            "epoch 7 loss at step: 312000 is 0.08081107451347634\n",
            "epoch 7 loss at step: 314000 is 0.09466069474467076\n",
            "epoch 7 loss at step: 316000 is 0.08222427728632466\n",
            "epoch 7 loss at step: 318000 is 0.07757330476469361\n",
            "epoch 7 loss at step: 320000 is 0.08379873727061203\n",
            "epoch 7 loss at step: 322000 is 0.08944963563306374\n",
            "epoch 7 loss at step: 324000 is 0.08849487917416263\n",
            "epoch 7 loss at step: 326000 is 0.08372771744173951\n",
            "epoch 7 loss at step: 328000 is 0.08364629124390194\n",
            "epoch 7 loss at step: 330000 is 0.08636915973108261\n",
            "epoch 7 loss at step: 332000 is 0.08580896314769051\n",
            "epoch 7 loss at step: 334000 is 0.08925980443647132\n",
            "epoch 7 loss at step: 336000 is 0.08399744795699371\n",
            "epoch 7 loss at step: 338000 is 0.08150184401508886\n",
            "epoch 7 loss at step: 340000 is 0.08705751627823338\n",
            "epoch 7 loss at step: 342000 is 0.08312493041699054\n",
            "epoch 7 loss at step: 344000 is 0.08891573888715357\n",
            "epoch 7 loss at step: 346000 is 0.08871583000104874\n",
            "epoch 8 loss at step: 348000 is 0.08837913501332514\n",
            "epoch 8 loss at step: 350000 is 0.0820785117453779\n",
            "epoch 8 loss at step: 352000 is 0.07725217337720096\n",
            "epoch 8 loss at step: 354000 is 0.0760987083115615\n",
            "epoch 8 loss at step: 356000 is 0.0794145944135962\n",
            "epoch 8 loss at step: 358000 is 0.08696323132701218\n",
            "epoch 8 loss at step: 360000 is 0.0835276668118313\n",
            "epoch 8 loss at step: 362000 is 0.07861256487958598\n",
            "epoch 8 loss at step: 364000 is 0.07801618637595675\n",
            "epoch 8 loss at step: 366000 is 0.08744674940395634\n",
            "epoch 8 loss at step: 368000 is 0.0817812497682753\n",
            "epoch 8 loss at step: 370000 is 0.08617358676239383\n",
            "epoch 8 loss at step: 372000 is 0.0771188080125139\n",
            "epoch 8 loss at step: 374000 is 0.08028665195626672\n",
            "epoch 8 loss at step: 376000 is 0.08607391433534213\n",
            "epoch 8 loss at step: 378000 is 0.08572806194843724\n",
            "epoch 8 loss at step: 380000 is 0.08090040663268883\n",
            "epoch 8 loss at step: 382000 is 0.08046497964090668\n",
            "epoch 8 loss at step: 384000 is 0.08160101220392971\n",
            "epoch 8 loss at step: 386000 is 0.0827036856864579\n",
            "epoch 8 loss at step: 388000 is 0.08715808885591105\n",
            "epoch 9 loss at step: 390000 is 0.08406666736298939\n",
            "epoch 9 loss at step: 392000 is 0.08375769341969863\n",
            "epoch 9 loss at step: 394000 is 0.07790736057469622\n",
            "epoch 9 loss at step: 396000 is 0.07465464807813987\n",
            "epoch 9 loss at step: 398000 is 0.07333297798607964\n",
            "epoch 9 loss at step: 400000 is 0.0836347087486647\n",
            "epoch 9 loss at step: 402000 is 0.08098227224999573\n",
            "epoch 9 loss at step: 404000 is 0.07236079736822285\n",
            "epoch 9 loss at step: 406000 is 0.07817165267880773\n",
            "epoch 9 loss at step: 408000 is 0.08406294069206342\n",
            "epoch 9 loss at step: 410000 is 0.07842515357956291\n",
            "epoch 9 loss at step: 412000 is 0.07864252066100016\n",
            "epoch 9 loss at step: 414000 is 0.08084997307159938\n",
            "epoch 9 loss at step: 416000 is 0.07979085082327947\n",
            "epoch 9 loss at step: 418000 is 0.08165779341617599\n",
            "epoch 9 loss at step: 420000 is 0.07929645185510162\n",
            "epoch 9 loss at step: 422000 is 0.08123692778078839\n",
            "epoch 9 loss at step: 424000 is 0.07637567510432564\n",
            "epoch 9 loss at step: 426000 is 0.08472310929256491\n",
            "epoch 9 loss at step: 428000 is 0.07465984579730138\n",
            "epoch 9 loss at step: 430000 is 0.08064061422925442\n",
            "epoch 9 loss at step: 432000 is 0.0856125395714771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SI3Ve_GMgdYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(all_losses_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYhL8WHMI8DU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "03fa78fb-f8d4-4f07-f135-02453f6653a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "model_output_list = []\n",
        "target_rating_list = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(validation_loader):\n",
        "        model_output = model(batched_data['users'],\n",
        "                       batched_data[\"animes\"])\n",
        "\n",
        "        model_output_list.append(model_output.sum().item() / len(batched_data['users']) )\n",
        "\n",
        "        target_rating = batched_data[\"ratings\"]\n",
        "\n",
        "        target_rating_list.append(target_rating.sum().item() / len(batched_data['users']))\n",
        "\n",
        "        print(f\"model_output: {model_output}, target_rating: {target_rating}\")\n",
        "\n",
        "\n",
        "# squared If True returns MSE value, if False returns RMSE value.\n",
        "rms = mean_squared_error(target_rating_list, model_output_list, squared=False)\n",
        "print(f\"rms: {rms}\")"
      ],
      "metadata": {
        "id": "VxAwnT9ZJFt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f4af2c-2428-46f7-9533-461c05e695b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([[8.0639],\n",
            "        [8.3586],\n",
            "        [7.2712],\n",
            "        [7.7996]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[6.2089],\n",
            "        [7.9881],\n",
            "        [8.2631],\n",
            "        [6.4388]]), target_rating: tensor([7, 9, 9, 5])\n",
            "model_output: tensor([[6.5163],\n",
            "        [9.6383],\n",
            "        [6.7337],\n",
            "        [9.3097]]), target_rating: tensor([ 8, 10,  7,  6])\n",
            "model_output: tensor([[7.4150],\n",
            "        [6.4969],\n",
            "        [6.3768],\n",
            "        [6.3884]]), target_rating: tensor([7, 8, 7, 6])\n",
            "model_output: tensor([[7.2138],\n",
            "        [7.0576],\n",
            "        [7.5022],\n",
            "        [5.7916]]), target_rating: tensor([6, 8, 8, 5])\n",
            "model_output: tensor([[7.1222],\n",
            "        [6.7432],\n",
            "        [8.1469],\n",
            "        [9.2093]]), target_rating: tensor([8, 7, 8, 8])\n",
            "model_output: tensor([[6.0306],\n",
            "        [6.2956],\n",
            "        [7.5823],\n",
            "        [7.5592]]), target_rating: tensor([5, 7, 7, 6])\n",
            "model_output: tensor([[7.6745],\n",
            "        [5.7448],\n",
            "        [8.3251],\n",
            "        [7.5664]]), target_rating: tensor([ 7,  8, 10,  3])\n",
            "model_output: tensor([[5.8834],\n",
            "        [8.0526],\n",
            "        [7.8327],\n",
            "        [6.0318]]), target_rating: tensor([8, 8, 8, 6])\n",
            "model_output: tensor([[7.9396],\n",
            "        [9.2381],\n",
            "        [9.3809],\n",
            "        [5.9924]]), target_rating: tensor([9, 7, 8, 7])\n",
            "model_output: tensor([[9.6386],\n",
            "        [8.6886],\n",
            "        [8.4256],\n",
            "        [8.3019]]), target_rating: tensor([ 6, 10,  7,  8])\n",
            "model_output: tensor([[7.5189],\n",
            "        [7.2684],\n",
            "        [6.0752],\n",
            "        [8.0559]]), target_rating: tensor([8, 8, 4, 6])\n",
            "model_output: tensor([[6.6848],\n",
            "        [8.4089],\n",
            "        [4.4942],\n",
            "        [5.7122]]), target_rating: tensor([8, 7, 5, 6])\n",
            "model_output: tensor([[7.8012],\n",
            "        [6.2470],\n",
            "        [7.6254],\n",
            "        [8.6525]]), target_rating: tensor([ 6,  6,  7, 10])\n",
            "model_output: tensor([[5.9354],\n",
            "        [5.3912],\n",
            "        [9.6106],\n",
            "        [7.2812]]), target_rating: tensor([8, 1, 7, 7])\n",
            "model_output: tensor([[7.5924],\n",
            "        [6.7353],\n",
            "        [6.4513],\n",
            "        [7.2528]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[4.6522],\n",
            "        [7.4153],\n",
            "        [7.3657],\n",
            "        [8.7806]]), target_rating: tensor([2, 8, 6, 9])\n",
            "model_output: tensor([[6.0842],\n",
            "        [7.5892],\n",
            "        [6.8358],\n",
            "        [7.1646]]), target_rating: tensor([5, 8, 8, 6])\n",
            "model_output: tensor([[5.9468],\n",
            "        [7.8302],\n",
            "        [6.9250],\n",
            "        [7.8898]]), target_rating: tensor([ 8, 10,  7,  6])\n",
            "model_output: tensor([[7.2916],\n",
            "        [6.7858],\n",
            "        [7.7444],\n",
            "        [8.3590]]), target_rating: tensor([5, 8, 7, 8])\n",
            "model_output: tensor([[7.9494],\n",
            "        [7.8304],\n",
            "        [6.5284],\n",
            "        [5.2189]]), target_rating: tensor([10,  7,  7,  7])\n",
            "model_output: tensor([[6.9350],\n",
            "        [5.6929],\n",
            "        [5.4999],\n",
            "        [7.2824]]), target_rating: tensor([8, 3, 9, 7])\n",
            "model_output: tensor([[7.2970],\n",
            "        [5.1882],\n",
            "        [8.0951],\n",
            "        [7.9950]]), target_rating: tensor([6, 8, 8, 4])\n",
            "model_output: tensor([[7.8821],\n",
            "        [6.9299],\n",
            "        [5.1844],\n",
            "        [8.2652]]), target_rating: tensor([5, 7, 9, 9])\n",
            "model_output: tensor([[9.7693],\n",
            "        [6.8357],\n",
            "        [8.4138],\n",
            "        [8.2517]]), target_rating: tensor([10,  5,  8,  9])\n",
            "model_output: tensor([[5.5775],\n",
            "        [8.9588],\n",
            "        [7.7241],\n",
            "        [7.1988]]), target_rating: tensor([4, 9, 9, 8])\n",
            "model_output: tensor([[7.7429],\n",
            "        [7.5507],\n",
            "        [8.2910],\n",
            "        [7.6088]]), target_rating: tensor([9, 9, 5, 8])\n",
            "model_output: tensor([[5.8294],\n",
            "        [8.9565],\n",
            "        [8.7876],\n",
            "        [7.3533]]), target_rating: tensor([7, 9, 9, 8])\n",
            "model_output: tensor([[7.9676],\n",
            "        [8.2254],\n",
            "        [6.8839],\n",
            "        [7.0615]]), target_rating: tensor([7, 5, 5, 9])\n",
            "model_output: tensor([[7.1366],\n",
            "        [5.2421],\n",
            "        [9.3378],\n",
            "        [8.0753]]), target_rating: tensor([5, 6, 7, 8])\n",
            "model_output: tensor([[9.0832],\n",
            "        [7.8284],\n",
            "        [8.4422],\n",
            "        [7.8396]]), target_rating: tensor([ 9,  8,  7, 10])\n",
            "model_output: tensor([[5.3718],\n",
            "        [7.3956],\n",
            "        [7.7231],\n",
            "        [5.5650]]), target_rating: tensor([7, 7, 9, 6])\n",
            "model_output: tensor([[8.2131],\n",
            "        [8.3884],\n",
            "        [7.8926],\n",
            "        [6.9241]]), target_rating: tensor([8, 8, 7, 5])\n",
            "model_output: tensor([[7.0244],\n",
            "        [6.2064],\n",
            "        [8.0439],\n",
            "        [5.1177]]), target_rating: tensor([9, 6, 8, 7])\n",
            "model_output: tensor([[6.9883],\n",
            "        [6.6980],\n",
            "        [6.3094],\n",
            "        [8.0098]]), target_rating: tensor([7, 7, 5, 7])\n",
            "model_output: tensor([[6.6444],\n",
            "        [6.5701],\n",
            "        [8.7198],\n",
            "        [7.6071]]), target_rating: tensor([ 8,  6,  7, 10])\n",
            "model_output: tensor([[5.9994],\n",
            "        [6.5053],\n",
            "        [6.5835],\n",
            "        [7.5194]]), target_rating: tensor([5, 7, 8, 8])\n",
            "model_output: tensor([[8.4544],\n",
            "        [7.5202],\n",
            "        [7.1778],\n",
            "        [6.4395]]), target_rating: tensor([8, 7, 7, 7])\n",
            "model_output: tensor([[9.1874],\n",
            "        [7.7978],\n",
            "        [7.7330],\n",
            "        [7.1755]]), target_rating: tensor([9, 7, 8, 9])\n",
            "model_output: tensor([[8.2468],\n",
            "        [8.4478],\n",
            "        [8.2631],\n",
            "        [8.4243]]), target_rating: tensor([5, 7, 7, 7])\n",
            "model_output: tensor([[7.6824],\n",
            "        [7.1108],\n",
            "        [5.7608],\n",
            "        [7.3407]]), target_rating: tensor([8, 7, 3, 8])\n",
            "model_output: tensor([[6.9592],\n",
            "        [7.2364],\n",
            "        [6.4885],\n",
            "        [8.8606]]), target_rating: tensor([ 7,  7, 10,  8])\n",
            "model_output: tensor([[5.4130],\n",
            "        [7.2594],\n",
            "        [9.0935],\n",
            "        [7.0081]]), target_rating: tensor([4, 7, 7, 8])\n",
            "model_output: tensor([[7.4172],\n",
            "        [9.7168],\n",
            "        [8.2638],\n",
            "        [9.6747]]), target_rating: tensor([8, 8, 7, 9])\n",
            "model_output: tensor([[ 7.0799],\n",
            "        [ 8.5558],\n",
            "        [ 6.9163],\n",
            "        [10.3525]]), target_rating: tensor([ 8,  9,  6, 10])\n",
            "model_output: tensor([[6.9018],\n",
            "        [6.7534],\n",
            "        [7.0508],\n",
            "        [9.9396]]), target_rating: tensor([3, 7, 8, 9])\n",
            "model_output: tensor([[8.5133],\n",
            "        [6.0873],\n",
            "        [8.6242],\n",
            "        [7.9754]]), target_rating: tensor([9, 6, 9, 7])\n",
            "model_output: tensor([[8.1802],\n",
            "        [7.1690],\n",
            "        [6.3845],\n",
            "        [8.0927]]), target_rating: tensor([7, 7, 6, 8])\n",
            "model_output: tensor([[8.1833],\n",
            "        [5.0066],\n",
            "        [5.9294],\n",
            "        [9.8133]]), target_rating: tensor([10,  6,  5,  9])\n",
            "model_output: tensor([[5.6080],\n",
            "        [7.7788],\n",
            "        [9.2092],\n",
            "        [8.0882]]), target_rating: tensor([ 5,  8, 10,  7])\n",
            "model_output: tensor([[7.2624],\n",
            "        [6.8294],\n",
            "        [8.0288],\n",
            "        [6.4739]]), target_rating: tensor([ 9,  6, 10,  6])\n",
            "model_output: tensor([[5.4960],\n",
            "        [6.0346],\n",
            "        [4.9342],\n",
            "        [8.7355]]), target_rating: tensor([7, 6, 6, 9])\n",
            "model_output: tensor([[6.3376],\n",
            "        [8.8821],\n",
            "        [6.4121],\n",
            "        [7.6407]]), target_rating: tensor([6, 8, 9, 8])\n",
            "model_output: tensor([[5.9497],\n",
            "        [6.8301],\n",
            "        [7.7835],\n",
            "        [6.9084]]), target_rating: tensor([6, 8, 7, 5])\n",
            "model_output: tensor([[6.5840],\n",
            "        [6.5062],\n",
            "        [7.2064],\n",
            "        [8.4560]]), target_rating: tensor([7, 3, 7, 7])\n",
            "model_output: tensor([[6.9931],\n",
            "        [7.2560],\n",
            "        [8.7298],\n",
            "        [8.5606]]), target_rating: tensor([ 5,  7, 10,  7])\n",
            "model_output: tensor([[7.4629],\n",
            "        [7.9081],\n",
            "        [9.7078],\n",
            "        [7.9753]]), target_rating: tensor([8, 8, 9, 8])\n",
            "model_output: tensor([[6.6786],\n",
            "        [6.8129],\n",
            "        [7.3699],\n",
            "        [7.3685]]), target_rating: tensor([5, 9, 8, 9])\n",
            "model_output: tensor([[6.9734],\n",
            "        [5.1085],\n",
            "        [9.6108],\n",
            "        [6.8605]]), target_rating: tensor([9, 6, 9, 5])\n",
            "model_output: tensor([[7.1644],\n",
            "        [7.8618],\n",
            "        [9.3561],\n",
            "        [8.2298]]), target_rating: tensor([6, 8, 9, 7])\n",
            "model_output: tensor([[7.0806],\n",
            "        [6.1092],\n",
            "        [7.5999],\n",
            "        [9.0071]]), target_rating: tensor([8, 9, 8, 9])\n",
            "model_output: tensor([[8.3274],\n",
            "        [7.0272],\n",
            "        [6.9075],\n",
            "        [7.6535]]), target_rating: tensor([9, 7, 8, 7])\n",
            "model_output: tensor([[7.2211],\n",
            "        [6.0452],\n",
            "        [7.2235],\n",
            "        [7.9835]]), target_rating: tensor([7, 7, 9, 8])\n",
            "model_output: tensor([[5.5173],\n",
            "        [6.5412],\n",
            "        [7.1147],\n",
            "        [8.3714]]), target_rating: tensor([ 5,  8,  9, 10])\n",
            "model_output: tensor([[9.0404],\n",
            "        [7.4074],\n",
            "        [8.4129],\n",
            "        [6.4555]]), target_rating: tensor([10,  5,  7,  7])\n",
            "model_output: tensor([[8.6151],\n",
            "        [7.5549],\n",
            "        [8.4102],\n",
            "        [7.7326]]), target_rating: tensor([8, 7, 8, 8])\n",
            "model_output: tensor([[7.3336],\n",
            "        [8.8439],\n",
            "        [5.6079],\n",
            "        [7.3724]]), target_rating: tensor([ 7, 10,  6,  8])\n",
            "model_output: tensor([[6.7691],\n",
            "        [6.0224],\n",
            "        [5.7973],\n",
            "        [6.8764]]), target_rating: tensor([8, 5, 5, 8])\n",
            "model_output: tensor([[6.0592],\n",
            "        [7.8090],\n",
            "        [4.9613],\n",
            "        [8.4591]]), target_rating: tensor([7, 8, 5, 7])\n",
            "model_output: tensor([[7.6662],\n",
            "        [6.7424],\n",
            "        [9.9971],\n",
            "        [9.2046]]), target_rating: tensor([ 8, 10,  8,  9])\n",
            "model_output: tensor([[8.8238],\n",
            "        [7.5643],\n",
            "        [7.4192],\n",
            "        [6.6322]]), target_rating: tensor([10,  6,  7,  5])\n",
            "model_output: tensor([[5.4354],\n",
            "        [7.5244],\n",
            "        [8.0028],\n",
            "        [8.9139]]), target_rating: tensor([5, 6, 8, 7])\n",
            "model_output: tensor([[9.4218],\n",
            "        [9.4744],\n",
            "        [7.2055],\n",
            "        [7.2866]]), target_rating: tensor([10, 10,  8,  6])\n",
            "model_output: tensor([[6.9824],\n",
            "        [7.2271],\n",
            "        [4.4065],\n",
            "        [9.0285]]), target_rating: tensor([7, 9, 6, 8])\n",
            "model_output: tensor([[6.4910],\n",
            "        [6.4812],\n",
            "        [6.7075],\n",
            "        [5.5022]]), target_rating: tensor([7, 6, 5, 4])\n",
            "model_output: tensor([[7.6274],\n",
            "        [5.6523],\n",
            "        [7.9360],\n",
            "        [8.3026]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[6.4172],\n",
            "        [7.6281],\n",
            "        [6.8481],\n",
            "        [6.1572]]), target_rating: tensor([8, 6, 4, 7])\n",
            "model_output: tensor([[4.9790],\n",
            "        [6.3110],\n",
            "        [8.8560],\n",
            "        [7.7124]]), target_rating: tensor([7, 4, 9, 7])\n",
            "model_output: tensor([[6.6410],\n",
            "        [6.9798],\n",
            "        [7.1006],\n",
            "        [5.1692]]), target_rating: tensor([9, 7, 7, 8])\n",
            "model_output: tensor([[6.9900],\n",
            "        [8.5183],\n",
            "        [9.2149],\n",
            "        [7.2060]]), target_rating: tensor([ 6, 10,  7,  9])\n",
            "model_output: tensor([[5.0707],\n",
            "        [7.5961],\n",
            "        [6.6572],\n",
            "        [8.0614]]), target_rating: tensor([5, 6, 7, 8])\n",
            "model_output: tensor([[5.5625],\n",
            "        [8.2413],\n",
            "        [7.8565],\n",
            "        [7.7354]]), target_rating: tensor([5, 9, 9, 6])\n",
            "model_output: tensor([[8.4939],\n",
            "        [7.5900],\n",
            "        [7.2422],\n",
            "        [5.9854]]), target_rating: tensor([9, 9, 8, 6])\n",
            "model_output: tensor([[6.1550],\n",
            "        [8.7696],\n",
            "        [9.2266],\n",
            "        [7.8797]]), target_rating: tensor([8, 8, 9, 8])\n",
            "model_output: tensor([[7.5870],\n",
            "        [4.2013],\n",
            "        [6.4353],\n",
            "        [7.1862]]), target_rating: tensor([6, 3, 5, 8])\n",
            "model_output: tensor([[6.5409],\n",
            "        [8.9415],\n",
            "        [6.5264],\n",
            "        [9.5679]]), target_rating: tensor([4, 9, 7, 9])\n",
            "model_output: tensor([[6.4964],\n",
            "        [7.8947],\n",
            "        [8.6349],\n",
            "        [6.1074]]), target_rating: tensor([ 7, 10,  7,  5])\n",
            "model_output: tensor([[10.1051],\n",
            "        [ 8.1951],\n",
            "        [ 8.9553],\n",
            "        [ 6.9662]]), target_rating: tensor([ 7,  7,  9, 10])\n",
            "model_output: tensor([[7.9599],\n",
            "        [7.1790],\n",
            "        [6.8561],\n",
            "        [8.4518]]), target_rating: tensor([ 7,  7,  6, 10])\n",
            "model_output: tensor([[7.2076],\n",
            "        [7.2366],\n",
            "        [7.5260],\n",
            "        [7.2667]]), target_rating: tensor([ 7,  7,  7, 10])\n",
            "model_output: tensor([[6.8849],\n",
            "        [7.7210],\n",
            "        [5.3288],\n",
            "        [8.2100]]), target_rating: tensor([7, 8, 5, 9])\n",
            "model_output: tensor([[7.2190],\n",
            "        [8.6097],\n",
            "        [6.7347],\n",
            "        [9.6271]]), target_rating: tensor([ 7, 10,  8,  9])\n",
            "model_output: tensor([[7.5570],\n",
            "        [7.1550],\n",
            "        [4.9593],\n",
            "        [8.4264]]), target_rating: tensor([ 7,  8,  6, 10])\n",
            "model_output: tensor([[7.6700],\n",
            "        [6.3055],\n",
            "        [7.8301],\n",
            "        [7.1200]]), target_rating: tensor([7, 8, 6, 7])\n",
            "model_output: tensor([[ 6.2740],\n",
            "        [ 7.3998],\n",
            "        [ 7.4371],\n",
            "        [10.4611]]), target_rating: tensor([ 5,  8, 10, 10])\n",
            "model_output: tensor([[8.2393],\n",
            "        [6.1259],\n",
            "        [6.1888],\n",
            "        [9.7202]]), target_rating: tensor([8, 6, 6, 9])\n",
            "model_output: tensor([[6.8601],\n",
            "        [7.8606],\n",
            "        [7.9513],\n",
            "        [6.5483]]), target_rating: tensor([8, 7, 8, 8])\n",
            "model_output: tensor([[6.7796],\n",
            "        [7.5628],\n",
            "        [8.7354],\n",
            "        [6.2457]]), target_rating: tensor([6, 5, 9, 9])\n",
            "model_output: tensor([[5.7820],\n",
            "        [7.4923],\n",
            "        [5.8163],\n",
            "        [8.6583]]), target_rating: tensor([ 7,  7,  7, 10])\n",
            "model_output: tensor([[6.7472],\n",
            "        [7.6212],\n",
            "        [6.1748],\n",
            "        [5.8151]]), target_rating: tensor([9, 9, 8, 4])\n",
            "model_output: tensor([[5.6975],\n",
            "        [6.5419],\n",
            "        [6.8721],\n",
            "        [6.1389]]), target_rating: tensor([4, 5, 8, 5])\n",
            "model_output: tensor([[ 6.9978],\n",
            "        [ 6.9908],\n",
            "        [ 6.1718],\n",
            "        [10.0337]]), target_rating: tensor([6, 8, 6, 8])\n",
            "model_output: tensor([[8.5500],\n",
            "        [4.8171],\n",
            "        [8.1016],\n",
            "        [6.9744]]), target_rating: tensor([9, 6, 8, 8])\n",
            "model_output: tensor([[8.8418],\n",
            "        [7.0430],\n",
            "        [6.7883],\n",
            "        [5.4517]]), target_rating: tensor([9, 5, 7, 6])\n",
            "model_output: tensor([[8.6108],\n",
            "        [6.0582],\n",
            "        [7.5244],\n",
            "        [7.6185]]), target_rating: tensor([7, 9, 9, 9])\n",
            "model_output: tensor([[4.5858],\n",
            "        [6.0021],\n",
            "        [5.6937],\n",
            "        [8.1782]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[8.4103],\n",
            "        [7.4380],\n",
            "        [8.2135],\n",
            "        [7.9235]]), target_rating: tensor([ 7, 10, 10,  7])\n",
            "model_output: tensor([[ 8.3659],\n",
            "        [ 5.6290],\n",
            "        [10.2606],\n",
            "        [ 4.9673]]), target_rating: tensor([4, 4, 9, 5])\n",
            "model_output: tensor([[8.0259],\n",
            "        [8.0885],\n",
            "        [8.5532],\n",
            "        [7.2373]]), target_rating: tensor([ 5,  8, 10,  8])\n",
            "model_output: tensor([[11.2835],\n",
            "        [ 8.7140],\n",
            "        [ 8.9650],\n",
            "        [ 6.9070]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[7.6061],\n",
            "        [6.2471],\n",
            "        [6.5069],\n",
            "        [7.1408]]), target_rating: tensor([7, 6, 8, 7])\n",
            "model_output: tensor([[7.2759],\n",
            "        [5.7231],\n",
            "        [6.5455],\n",
            "        [6.8094]]), target_rating: tensor([9, 5, 5, 4])\n",
            "model_output: tensor([[9.4637],\n",
            "        [7.2979],\n",
            "        [7.8275],\n",
            "        [6.2099]]), target_rating: tensor([9, 7, 8, 6])\n",
            "model_output: tensor([[9.5728],\n",
            "        [7.4543],\n",
            "        [9.0920],\n",
            "        [9.0947]]), target_rating: tensor([10,  6,  9, 10])\n",
            "model_output: tensor([[8.2332],\n",
            "        [6.9961],\n",
            "        [6.0855],\n",
            "        [8.8483]]), target_rating: tensor([7, 6, 4, 9])\n",
            "model_output: tensor([[8.5346],\n",
            "        [6.9213],\n",
            "        [7.3663],\n",
            "        [8.4499]]), target_rating: tensor([6, 9, 9, 7])\n",
            "model_output: tensor([[6.9504],\n",
            "        [6.9614],\n",
            "        [7.6901],\n",
            "        [9.3787]]), target_rating: tensor([8, 7, 9, 9])\n",
            "model_output: tensor([[5.8279],\n",
            "        [5.8103],\n",
            "        [7.5271],\n",
            "        [7.4117]]), target_rating: tensor([6, 7, 7, 7])\n",
            "model_output: tensor([[7.1006],\n",
            "        [7.5828],\n",
            "        [8.4055],\n",
            "        [4.8937]]), target_rating: tensor([7, 7, 9, 4])\n",
            "model_output: tensor([[6.9708],\n",
            "        [7.2921],\n",
            "        [7.3228],\n",
            "        [6.7134]]), target_rating: tensor([6, 6, 8, 7])\n",
            "model_output: tensor([[6.8298],\n",
            "        [6.0537],\n",
            "        [8.3165],\n",
            "        [6.0286]]), target_rating: tensor([9, 7, 9, 7])\n",
            "model_output: tensor([[8.3413],\n",
            "        [7.1944],\n",
            "        [7.8563],\n",
            "        [8.7060]]), target_rating: tensor([ 9,  7,  7, 10])\n",
            "model_output: tensor([[8.1904],\n",
            "        [6.5953],\n",
            "        [7.8675],\n",
            "        [6.8285]]), target_rating: tensor([8, 5, 8, 6])\n",
            "model_output: tensor([[9.1396],\n",
            "        [7.6371],\n",
            "        [7.8580],\n",
            "        [6.2790]]), target_rating: tensor([7, 7, 6, 5])\n",
            "model_output: tensor([[6.6116],\n",
            "        [8.0089],\n",
            "        [9.1931],\n",
            "        [5.8344]]), target_rating: tensor([5, 9, 8, 7])\n",
            "model_output: tensor([[7.3708],\n",
            "        [6.1764],\n",
            "        [8.4048],\n",
            "        [8.2960]]), target_rating: tensor([9, 7, 7, 8])\n",
            "model_output: tensor([[8.4522],\n",
            "        [8.1233],\n",
            "        [5.4048],\n",
            "        [7.2564]]), target_rating: tensor([7, 8, 5, 7])\n",
            "model_output: tensor([[6.6156],\n",
            "        [7.4527],\n",
            "        [6.5484],\n",
            "        [7.3467]]), target_rating: tensor([ 5, 10,  9,  8])\n",
            "model_output: tensor([[4.9531],\n",
            "        [5.5985],\n",
            "        [8.2952],\n",
            "        [6.9648]]), target_rating: tensor([3, 5, 8, 8])\n",
            "model_output: tensor([[8.0015],\n",
            "        [6.9095],\n",
            "        [8.0262],\n",
            "        [8.0420]]), target_rating: tensor([ 9,  7, 10,  9])\n",
            "model_output: tensor([[7.5105],\n",
            "        [6.7981],\n",
            "        [6.1671],\n",
            "        [8.0561]]), target_rating: tensor([7, 6, 6, 7])\n",
            "model_output: tensor([[7.0694],\n",
            "        [5.4965],\n",
            "        [5.7323],\n",
            "        [9.3476]]), target_rating: tensor([6, 4, 6, 8])\n",
            "model_output: tensor([[7.0487],\n",
            "        [5.2556],\n",
            "        [7.3110],\n",
            "        [6.6048]]), target_rating: tensor([7, 6, 7, 7])\n",
            "model_output: tensor([[6.7670],\n",
            "        [7.3171],\n",
            "        [6.8293],\n",
            "        [9.0146]]), target_rating: tensor([ 6,  7,  7, 10])\n",
            "model_output: tensor([[6.0647],\n",
            "        [6.4057],\n",
            "        [9.3115],\n",
            "        [7.6734]]), target_rating: tensor([4, 6, 8, 9])\n",
            "model_output: tensor([[6.9354],\n",
            "        [6.7821],\n",
            "        [8.9745],\n",
            "        [7.5216]]), target_rating: tensor([7, 2, 8, 8])\n",
            "model_output: tensor([[4.7225],\n",
            "        [9.7930],\n",
            "        [6.9257],\n",
            "        [7.9353]]), target_rating: tensor([4, 9, 8, 8])\n",
            "model_output: tensor([[7.7854],\n",
            "        [7.4045],\n",
            "        [6.7409],\n",
            "        [5.9977]]), target_rating: tensor([6, 6, 5, 7])\n",
            "model_output: tensor([[7.6654],\n",
            "        [7.0750],\n",
            "        [6.5890],\n",
            "        [8.2596]]), target_rating: tensor([10,  8,  4,  8])\n",
            "model_output: tensor([[7.6530],\n",
            "        [6.3305],\n",
            "        [8.6136],\n",
            "        [5.9175]]), target_rating: tensor([9, 7, 6, 7])\n",
            "model_output: tensor([[7.4914],\n",
            "        [7.0911],\n",
            "        [6.6033],\n",
            "        [6.4654]]), target_rating: tensor([9, 5, 6, 6])\n",
            "model_output: tensor([[6.0931],\n",
            "        [8.3578],\n",
            "        [6.7471],\n",
            "        [7.0471]]), target_rating: tensor([7, 8, 7, 8])\n",
            "model_output: tensor([[9.0346],\n",
            "        [6.4062],\n",
            "        [8.1000],\n",
            "        [5.7060]]), target_rating: tensor([9, 7, 8, 6])\n",
            "model_output: tensor([[6.9811],\n",
            "        [6.3223],\n",
            "        [6.5374],\n",
            "        [8.8719]]), target_rating: tensor([8, 5, 7, 8])\n",
            "model_output: tensor([[6.5741],\n",
            "        [7.9815],\n",
            "        [7.3487],\n",
            "        [6.7154]]), target_rating: tensor([ 7, 10,  7,  8])\n",
            "model_output: tensor([[8.8379],\n",
            "        [6.8102],\n",
            "        [8.7429],\n",
            "        [9.2660]]), target_rating: tensor([ 9,  7, 10,  8])\n",
            "model_output: tensor([[8.4896],\n",
            "        [5.4117],\n",
            "        [6.3397],\n",
            "        [7.3720]]), target_rating: tensor([10,  2,  3,  7])\n",
            "model_output: tensor([[7.1040],\n",
            "        [6.3495],\n",
            "        [7.6628],\n",
            "        [7.7946]]), target_rating: tensor([7, 7, 7, 4])\n",
            "model_output: tensor([[ 5.9253],\n",
            "        [10.0470],\n",
            "        [ 8.7498],\n",
            "        [ 5.2476]]), target_rating: tensor([ 8, 10,  6,  6])\n",
            "model_output: tensor([[6.9398],\n",
            "        [7.6720],\n",
            "        [8.2758],\n",
            "        [7.7763]]), target_rating: tensor([10,  8,  6,  8])\n",
            "model_output: tensor([[7.7840],\n",
            "        [6.7912],\n",
            "        [7.3463],\n",
            "        [8.0001]]), target_rating: tensor([ 8, 10,  7,  6])\n",
            "model_output: tensor([[5.9494],\n",
            "        [8.1469],\n",
            "        [7.6673],\n",
            "        [4.9622]]), target_rating: tensor([6, 9, 6, 6])\n",
            "model_output: tensor([[8.8020],\n",
            "        [8.3740],\n",
            "        [8.7041],\n",
            "        [5.3132]]), target_rating: tensor([10,  9,  8,  7])\n",
            "model_output: tensor([[7.4810],\n",
            "        [7.3036],\n",
            "        [6.5047],\n",
            "        [5.3226]]), target_rating: tensor([ 7, 10,  6,  6])\n",
            "model_output: tensor([[6.2527],\n",
            "        [6.9962],\n",
            "        [7.3895],\n",
            "        [6.0197]]), target_rating: tensor([6, 6, 9, 8])\n",
            "model_output: tensor([[8.0097],\n",
            "        [7.7249],\n",
            "        [7.7518],\n",
            "        [6.7986]]), target_rating: tensor([8, 9, 9, 6])\n",
            "model_output: tensor([[8.4904],\n",
            "        [7.7245],\n",
            "        [8.2967],\n",
            "        [9.1907]]), target_rating: tensor([9, 9, 7, 8])\n",
            "model_output: tensor([[5.9456],\n",
            "        [6.6868],\n",
            "        [6.0157],\n",
            "        [8.1674]]), target_rating: tensor([6, 8, 7, 8])\n",
            "model_output: tensor([[6.5476],\n",
            "        [8.0716],\n",
            "        [5.9151],\n",
            "        [7.6801]]), target_rating: tensor([ 8,  9,  7, 10])\n",
            "model_output: tensor([[7.6837],\n",
            "        [8.9952],\n",
            "        [6.7686],\n",
            "        [8.4784]]), target_rating: tensor([ 9,  9,  9, 10])\n",
            "model_output: tensor([[6.5884],\n",
            "        [8.2779],\n",
            "        [5.2420],\n",
            "        [7.2303]]), target_rating: tensor([8, 9, 5, 7])\n",
            "model_output: tensor([[6.2499],\n",
            "        [8.7093],\n",
            "        [6.5229],\n",
            "        [8.3638]]), target_rating: tensor([7, 7, 4, 8])\n",
            "model_output: tensor([[4.5165],\n",
            "        [6.5054],\n",
            "        [7.0833],\n",
            "        [7.7208]]), target_rating: tensor([6, 9, 7, 5])\n",
            "model_output: tensor([[7.3833],\n",
            "        [7.2171],\n",
            "        [5.9032],\n",
            "        [8.6875]]), target_rating: tensor([8, 8, 6, 7])\n",
            "model_output: tensor([[5.3032],\n",
            "        [8.2866],\n",
            "        [6.5944],\n",
            "        [6.5190]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[5.0820],\n",
            "        [8.0350],\n",
            "        [5.4604],\n",
            "        [7.0456]]), target_rating: tensor([6, 9, 4, 8])\n",
            "model_output: tensor([[7.1531],\n",
            "        [7.1270],\n",
            "        [7.8403],\n",
            "        [6.9033]]), target_rating: tensor([9, 9, 9, 9])\n",
            "model_output: tensor([[7.2874],\n",
            "        [8.9789],\n",
            "        [7.1307],\n",
            "        [7.2019]]), target_rating: tensor([7, 9, 7, 5])\n",
            "model_output: tensor([[7.5773],\n",
            "        [5.9848],\n",
            "        [9.0959],\n",
            "        [6.5178]]), target_rating: tensor([6, 1, 8, 5])\n",
            "model_output: tensor([[9.1153],\n",
            "        [8.3676],\n",
            "        [5.2981],\n",
            "        [7.3539]]), target_rating: tensor([10,  9,  7,  9])\n",
            "model_output: tensor([[6.5806],\n",
            "        [5.1895],\n",
            "        [8.0442],\n",
            "        [7.1650]]), target_rating: tensor([5, 7, 7, 6])\n",
            "model_output: tensor([[7.3852],\n",
            "        [4.4754],\n",
            "        [7.1204],\n",
            "        [7.5075]]), target_rating: tensor([7, 6, 5, 8])\n",
            "model_output: tensor([[7.8386],\n",
            "        [8.8922],\n",
            "        [8.0952],\n",
            "        [9.4886]]), target_rating: tensor([7, 8, 8, 9])\n",
            "model_output: tensor([[6.8591],\n",
            "        [8.9812],\n",
            "        [6.6640],\n",
            "        [8.7772]]), target_rating: tensor([ 9, 10,  7,  9])\n",
            "model_output: tensor([[5.5100],\n",
            "        [5.3777],\n",
            "        [8.6906],\n",
            "        [9.0682]]), target_rating: tensor([ 3,  6,  9, 10])\n",
            "model_output: tensor([[8.0386],\n",
            "        [5.8788],\n",
            "        [6.6802],\n",
            "        [9.2057]]), target_rating: tensor([8, 5, 9, 9])\n",
            "model_output: tensor([[5.8697],\n",
            "        [6.5141],\n",
            "        [7.9398],\n",
            "        [9.0233]]), target_rating: tensor([ 4,  8,  7, 10])\n",
            "model_output: tensor([[7.6001],\n",
            "        [6.7072],\n",
            "        [6.6117],\n",
            "        [6.2422]]), target_rating: tensor([4, 9, 9, 7])\n",
            "model_output: tensor([[8.1689],\n",
            "        [6.5189],\n",
            "        [8.0412],\n",
            "        [9.8674]]), target_rating: tensor([8, 6, 8, 9])\n",
            "model_output: tensor([[8.4785],\n",
            "        [6.0900],\n",
            "        [8.7567],\n",
            "        [7.5139]]), target_rating: tensor([10,  7, 10,  5])\n",
            "model_output: tensor([[7.3222],\n",
            "        [5.7456],\n",
            "        [7.7872],\n",
            "        [7.8282]]), target_rating: tensor([4, 7, 8, 9])\n",
            "model_output: tensor([[8.3403],\n",
            "        [7.3946],\n",
            "        [6.8654],\n",
            "        [7.3383]]), target_rating: tensor([8, 8, 6, 7])\n",
            "model_output: tensor([[8.2054],\n",
            "        [7.8035],\n",
            "        [7.3558],\n",
            "        [9.3580]]), target_rating: tensor([ 9,  9, 10,  7])\n",
            "model_output: tensor([[9.0521],\n",
            "        [6.1282],\n",
            "        [9.7607],\n",
            "        [5.8586]]), target_rating: tensor([8, 5, 9, 6])\n",
            "model_output: tensor([[7.3818],\n",
            "        [6.9816],\n",
            "        [7.3503],\n",
            "        [7.5882]]), target_rating: tensor([8, 6, 6, 9])\n",
            "model_output: tensor([[6.9603],\n",
            "        [8.0844],\n",
            "        [8.1681],\n",
            "        [7.0567]]), target_rating: tensor([8, 7, 7, 8])\n",
            "model_output: tensor([[7.0476],\n",
            "        [5.5639],\n",
            "        [6.9896],\n",
            "        [8.5361]]), target_rating: tensor([9, 8, 6, 8])\n",
            "model_output: tensor([[8.7502],\n",
            "        [7.4062],\n",
            "        [6.7464],\n",
            "        [6.3331]]), target_rating: tensor([10,  8,  6,  5])\n",
            "model_output: tensor([[8.1991],\n",
            "        [8.1585],\n",
            "        [6.7573],\n",
            "        [7.1287]]), target_rating: tensor([ 7, 10,  6,  6])\n",
            "model_output: tensor([[5.3425],\n",
            "        [6.4332],\n",
            "        [8.2212],\n",
            "        [8.3280]]), target_rating: tensor([5, 8, 5, 8])\n",
            "model_output: tensor([[5.2348],\n",
            "        [5.5969],\n",
            "        [7.2793],\n",
            "        [5.8381]]), target_rating: tensor([4, 6, 6, 5])\n",
            "model_output: tensor([[6.0062],\n",
            "        [6.9213],\n",
            "        [9.6284],\n",
            "        [7.3709]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[6.5843],\n",
            "        [6.7848],\n",
            "        [7.2862],\n",
            "        [8.9588]]), target_rating: tensor([7, 7, 8, 8])\n",
            "model_output: tensor([[7.9725],\n",
            "        [7.8875],\n",
            "        [8.3000],\n",
            "        [8.7619]]), target_rating: tensor([7, 9, 9, 9])\n",
            "model_output: tensor([[6.8952],\n",
            "        [8.3337],\n",
            "        [8.3385],\n",
            "        [8.5960]]), target_rating: tensor([6, 9, 8, 9])\n",
            "model_output: tensor([[7.1717],\n",
            "        [8.6462],\n",
            "        [8.0903],\n",
            "        [8.2721]]), target_rating: tensor([9, 8, 8, 8])\n",
            "model_output: tensor([[7.6132],\n",
            "        [6.7448],\n",
            "        [5.7712],\n",
            "        [5.6489]]), target_rating: tensor([9, 7, 6, 6])\n",
            "model_output: tensor([[7.7135],\n",
            "        [7.4648],\n",
            "        [8.5551],\n",
            "        [7.3442]]), target_rating: tensor([7, 9, 7, 5])\n",
            "model_output: tensor([[6.0656],\n",
            "        [7.9233],\n",
            "        [7.1688],\n",
            "        [6.7642]]), target_rating: tensor([7, 8, 9, 7])\n",
            "model_output: tensor([[6.7894],\n",
            "        [7.5244],\n",
            "        [6.8056],\n",
            "        [9.2235]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[4.9257],\n",
            "        [7.9522],\n",
            "        [7.5188],\n",
            "        [6.1369]]), target_rating: tensor([7, 7, 4, 9])\n",
            "model_output: tensor([[6.7561],\n",
            "        [8.5001],\n",
            "        [6.3847],\n",
            "        [6.4229]]), target_rating: tensor([8, 6, 9, 8])\n",
            "model_output: tensor([[ 6.6370],\n",
            "        [ 8.6368],\n",
            "        [10.6072],\n",
            "        [ 9.0228]]), target_rating: tensor([ 6,  9,  7, 10])\n",
            "model_output: tensor([[5.9029],\n",
            "        [8.6815],\n",
            "        [5.5034],\n",
            "        [5.5893]]), target_rating: tensor([6, 9, 7, 6])\n",
            "model_output: tensor([[7.5535],\n",
            "        [7.3231],\n",
            "        [6.9748],\n",
            "        [7.6956]]), target_rating: tensor([10,  6,  8,  6])\n",
            "model_output: tensor([[6.8443],\n",
            "        [6.7555],\n",
            "        [4.5742],\n",
            "        [7.6176]]), target_rating: tensor([8, 6, 7, 8])\n",
            "model_output: tensor([[8.4101],\n",
            "        [6.7696],\n",
            "        [6.1070],\n",
            "        [7.3799]]), target_rating: tensor([9, 7, 6, 7])\n",
            "model_output: tensor([[ 5.4750],\n",
            "        [ 8.1558],\n",
            "        [ 8.8702],\n",
            "        [10.1198]]), target_rating: tensor([5, 6, 8, 9])\n",
            "model_output: tensor([[8.6065],\n",
            "        [7.1915],\n",
            "        [7.8806],\n",
            "        [8.3681]]), target_rating: tensor([9, 9, 8, 8])\n",
            "model_output: tensor([[7.1668],\n",
            "        [5.4114],\n",
            "        [6.6620],\n",
            "        [5.7214]]), target_rating: tensor([8, 6, 6, 5])\n",
            "model_output: tensor([[4.5600],\n",
            "        [5.5987],\n",
            "        [6.1549],\n",
            "        [6.7070]]), target_rating: tensor([5, 7, 5, 7])\n",
            "model_output: tensor([[7.4910],\n",
            "        [8.0043],\n",
            "        [7.8863],\n",
            "        [7.2970]]), target_rating: tensor([6, 7, 6, 7])\n",
            "model_output: tensor([[7.6378],\n",
            "        [6.4141],\n",
            "        [6.2322],\n",
            "        [7.0777]]), target_rating: tensor([6, 7, 8, 8])\n",
            "model_output: tensor([[6.4417],\n",
            "        [6.2071],\n",
            "        [7.3305],\n",
            "        [7.1084]]), target_rating: tensor([6, 6, 7, 7])\n",
            "model_output: tensor([[8.8176],\n",
            "        [6.8680],\n",
            "        [6.9560],\n",
            "        [7.0343]]), target_rating: tensor([7, 9, 8, 6])\n",
            "model_output: tensor([[7.7792],\n",
            "        [7.2423],\n",
            "        [6.2628],\n",
            "        [7.3721]]), target_rating: tensor([8, 7, 5, 6])\n",
            "model_output: tensor([[7.3779],\n",
            "        [6.2816],\n",
            "        [7.2754],\n",
            "        [6.0378]]), target_rating: tensor([8, 6, 7, 2])\n",
            "model_output: tensor([[7.5469],\n",
            "        [6.3191],\n",
            "        [9.0227],\n",
            "        [4.9229]]), target_rating: tensor([8, 8, 8, 6])\n",
            "model_output: tensor([[5.2910],\n",
            "        [7.2668],\n",
            "        [7.1276],\n",
            "        [6.1697]]), target_rating: tensor([8, 7, 9, 8])\n",
            "model_output: tensor([[7.0537],\n",
            "        [8.2991],\n",
            "        [8.0379],\n",
            "        [7.5621]]), target_rating: tensor([6, 8, 9, 9])\n",
            "model_output: tensor([[7.1993],\n",
            "        [4.9906],\n",
            "        [6.7582],\n",
            "        [8.5338]]), target_rating: tensor([6, 4, 9, 7])\n",
            "model_output: tensor([[6.9885],\n",
            "        [8.3894],\n",
            "        [5.7413],\n",
            "        [8.2271]]), target_rating: tensor([9, 8, 8, 5])\n",
            "model_output: tensor([[9.2276],\n",
            "        [5.1516],\n",
            "        [7.4452],\n",
            "        [9.2827]]), target_rating: tensor([ 8,  6,  8, 10])\n",
            "model_output: tensor([[7.8673],\n",
            "        [5.6406],\n",
            "        [6.4247],\n",
            "        [7.6269]]), target_rating: tensor([9, 8, 4, 7])\n",
            "model_output: tensor([[8.3820],\n",
            "        [7.5576],\n",
            "        [6.3401],\n",
            "        [8.3717]]), target_rating: tensor([7, 4, 8, 7])\n",
            "model_output: tensor([[9.3565],\n",
            "        [7.3901],\n",
            "        [7.1404],\n",
            "        [7.7881]]), target_rating: tensor([10,  6,  7,  9])\n",
            "model_output: tensor([[6.8190],\n",
            "        [8.0550],\n",
            "        [6.1562],\n",
            "        [8.0148]]), target_rating: tensor([8, 7, 6, 7])\n",
            "model_output: tensor([[8.6552],\n",
            "        [8.4416],\n",
            "        [7.4169],\n",
            "        [6.8407]]), target_rating: tensor([7, 8, 9, 7])\n",
            "model_output: tensor([[5.9526],\n",
            "        [6.7891],\n",
            "        [9.3434],\n",
            "        [8.4672]]), target_rating: tensor([8, 7, 9, 8])\n",
            "model_output: tensor([[7.8214],\n",
            "        [4.6453],\n",
            "        [5.8775],\n",
            "        [6.2789]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[5.7890],\n",
            "        [9.0624],\n",
            "        [8.5413],\n",
            "        [7.2611]]), target_rating: tensor([8, 9, 8, 4])\n",
            "model_output: tensor([[8.5375],\n",
            "        [7.6414],\n",
            "        [5.9545],\n",
            "        [8.1095]]), target_rating: tensor([8, 9, 7, 9])\n",
            "model_output: tensor([[10.1177],\n",
            "        [ 7.4698],\n",
            "        [ 7.6229],\n",
            "        [ 7.1750]]), target_rating: tensor([5, 8, 6, 7])\n",
            "model_output: tensor([[8.2855],\n",
            "        [6.9002],\n",
            "        [6.4143],\n",
            "        [8.0904]]), target_rating: tensor([8, 8, 8, 5])\n",
            "model_output: tensor([[6.3608],\n",
            "        [6.8710],\n",
            "        [7.5640],\n",
            "        [6.9578]]), target_rating: tensor([6, 6, 8, 7])\n",
            "model_output: tensor([[8.5003],\n",
            "        [7.8752],\n",
            "        [7.2197],\n",
            "        [5.9805]]), target_rating: tensor([10,  7,  9,  4])\n",
            "model_output: tensor([[9.4083],\n",
            "        [5.3953],\n",
            "        [7.7269],\n",
            "        [7.9004]]), target_rating: tensor([8, 7, 7, 8])\n",
            "model_output: tensor([[7.8315],\n",
            "        [6.9704],\n",
            "        [6.1467],\n",
            "        [7.1938]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[5.4971],\n",
            "        [8.3584],\n",
            "        [7.6913],\n",
            "        [8.3508]]), target_rating: tensor([6, 9, 7, 8])\n",
            "model_output: tensor([[7.2649],\n",
            "        [9.1501],\n",
            "        [8.2381],\n",
            "        [7.0196]]), target_rating: tensor([8, 9, 9, 7])\n",
            "model_output: tensor([[8.9523],\n",
            "        [7.9511],\n",
            "        [7.7397],\n",
            "        [8.7479]]), target_rating: tensor([9, 7, 9, 9])\n",
            "model_output: tensor([[8.4002],\n",
            "        [5.7865],\n",
            "        [7.3645],\n",
            "        [7.7661]]), target_rating: tensor([10,  4,  7,  6])\n",
            "model_output: tensor([[9.2290],\n",
            "        [8.0255],\n",
            "        [8.7623],\n",
            "        [7.5229]]), target_rating: tensor([8, 7, 9, 7])\n",
            "model_output: tensor([[9.2983],\n",
            "        [7.1192],\n",
            "        [5.8933],\n",
            "        [5.6329]]), target_rating: tensor([9, 8, 7, 5])\n",
            "model_output: tensor([[6.4479],\n",
            "        [7.1933],\n",
            "        [9.0919],\n",
            "        [8.2521]]), target_rating: tensor([ 6,  7, 10,  8])\n",
            "model_output: tensor([[7.7282],\n",
            "        [7.9807],\n",
            "        [6.7435],\n",
            "        [5.3144]]), target_rating: tensor([ 9, 10,  7,  5])\n",
            "model_output: tensor([[8.5412],\n",
            "        [7.4839],\n",
            "        [8.4552],\n",
            "        [7.7075]]), target_rating: tensor([8, 5, 9, 7])\n",
            "model_output: tensor([[8.9289],\n",
            "        [7.5172],\n",
            "        [7.3337],\n",
            "        [7.0612]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[7.4854],\n",
            "        [7.0887],\n",
            "        [7.1203],\n",
            "        [6.0150]]), target_rating: tensor([8, 6, 9, 4])\n",
            "model_output: tensor([[6.8642],\n",
            "        [7.7693],\n",
            "        [7.0715],\n",
            "        [8.9979]]), target_rating: tensor([9, 9, 7, 8])\n",
            "model_output: tensor([[5.0218],\n",
            "        [7.4746],\n",
            "        [5.9560],\n",
            "        [8.2490]]), target_rating: tensor([6, 8, 7, 9])\n",
            "model_output: tensor([[7.3829],\n",
            "        [5.7654],\n",
            "        [7.3910],\n",
            "        [6.0357]]), target_rating: tensor([8, 7, 7, 6])\n",
            "model_output: tensor([[5.3226],\n",
            "        [7.8514],\n",
            "        [7.8761],\n",
            "        [8.3739]]), target_rating: tensor([3, 7, 8, 7])\n",
            "model_output: tensor([[8.5106],\n",
            "        [8.0690],\n",
            "        [4.5862],\n",
            "        [7.6046]]), target_rating: tensor([7, 6, 5, 6])\n",
            "model_output: tensor([[7.9511],\n",
            "        [7.0699],\n",
            "        [8.9060],\n",
            "        [7.8975]]), target_rating: tensor([ 7,  6, 10,  8])\n",
            "model_output: tensor([[7.0803],\n",
            "        [6.0255],\n",
            "        [5.9485],\n",
            "        [7.9102]]), target_rating: tensor([8, 8, 7, 9])\n",
            "model_output: tensor([[8.1155],\n",
            "        [5.7454],\n",
            "        [8.2172],\n",
            "        [7.4077]]), target_rating: tensor([9, 8, 9, 7])\n",
            "model_output: tensor([[9.7791],\n",
            "        [8.9487],\n",
            "        [8.8057],\n",
            "        [8.0564]]), target_rating: tensor([10,  9,  9,  8])\n",
            "model_output: tensor([[6.9775],\n",
            "        [6.6725],\n",
            "        [6.4000],\n",
            "        [8.4574]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[7.6784],\n",
            "        [8.0354],\n",
            "        [6.4562],\n",
            "        [7.1230]]), target_rating: tensor([7, 9, 7, 9])\n",
            "model_output: tensor([[4.7769],\n",
            "        [7.1899],\n",
            "        [7.0865],\n",
            "        [6.4407]]), target_rating: tensor([1, 8, 8, 7])\n",
            "model_output: tensor([[7.2180],\n",
            "        [7.4577],\n",
            "        [9.0756],\n",
            "        [8.5767]]), target_rating: tensor([ 8,  7, 10,  8])\n",
            "model_output: tensor([[7.7063],\n",
            "        [8.3609],\n",
            "        [8.4049],\n",
            "        [8.4042]]), target_rating: tensor([ 6, 10,  7,  8])\n",
            "model_output: tensor([[5.2736],\n",
            "        [6.5710],\n",
            "        [7.0023],\n",
            "        [7.5755]]), target_rating: tensor([8, 7, 9, 7])\n",
            "model_output: tensor([[7.7368],\n",
            "        [7.1690],\n",
            "        [6.2443],\n",
            "        [7.1977]]), target_rating: tensor([10,  7,  6,  7])\n",
            "model_output: tensor([[6.6480],\n",
            "        [6.5995],\n",
            "        [7.1613],\n",
            "        [7.0246]]), target_rating: tensor([6, 6, 8, 7])\n",
            "model_output: tensor([[7.2298],\n",
            "        [7.9202],\n",
            "        [6.8155],\n",
            "        [5.5413]]), target_rating: tensor([7, 7, 6, 7])\n",
            "model_output: tensor([[7.1892],\n",
            "        [7.6309],\n",
            "        [7.5348],\n",
            "        [6.1403]]), target_rating: tensor([9, 4, 7, 7])\n",
            "model_output: tensor([[8.3892],\n",
            "        [8.9697],\n",
            "        [9.3112],\n",
            "        [6.9556]]), target_rating: tensor([9, 7, 8, 7])\n",
            "model_output: tensor([[ 5.4676],\n",
            "        [ 6.9081],\n",
            "        [10.1108],\n",
            "        [ 6.8559]]), target_rating: tensor([ 8,  7, 10,  9])\n",
            "model_output: tensor([[8.6981],\n",
            "        [7.3587],\n",
            "        [7.9210],\n",
            "        [7.6456]]), target_rating: tensor([8, 7, 7, 9])\n",
            "model_output: tensor([[6.8095],\n",
            "        [8.1361],\n",
            "        [7.5211],\n",
            "        [9.2233]]), target_rating: tensor([ 7,  9, 10,  8])\n",
            "model_output: tensor([[8.9930],\n",
            "        [6.6926],\n",
            "        [6.1373],\n",
            "        [5.7318]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[7.5481],\n",
            "        [8.3817],\n",
            "        [6.8373],\n",
            "        [9.0289]]), target_rating: tensor([7, 5, 7, 9])\n",
            "model_output: tensor([[9.1033],\n",
            "        [5.3412],\n",
            "        [6.6677],\n",
            "        [8.8322]]), target_rating: tensor([8, 5, 7, 8])\n",
            "model_output: tensor([[6.5996],\n",
            "        [7.3975],\n",
            "        [6.2250],\n",
            "        [8.3157]]), target_rating: tensor([5, 7, 7, 6])\n",
            "model_output: tensor([[6.8794],\n",
            "        [7.0214],\n",
            "        [7.8053],\n",
            "        [6.8158]]), target_rating: tensor([8, 7, 5, 9])\n",
            "model_output: tensor([[9.1154],\n",
            "        [6.2645],\n",
            "        [7.3710],\n",
            "        [6.7075]]), target_rating: tensor([8, 6, 8, 8])\n",
            "model_output: tensor([[ 8.9586],\n",
            "        [ 7.9734],\n",
            "        [ 5.9635],\n",
            "        [11.7688]]), target_rating: tensor([10,  8,  6, 10])\n",
            "model_output: tensor([[10.2766],\n",
            "        [ 6.3853],\n",
            "        [ 6.4256],\n",
            "        [ 8.1261]]), target_rating: tensor([10,  6,  9,  9])\n",
            "model_output: tensor([[9.3899],\n",
            "        [9.2402],\n",
            "        [5.6385],\n",
            "        [7.8424]]), target_rating: tensor([8, 9, 5, 8])\n",
            "model_output: tensor([[7.2757],\n",
            "        [6.6007],\n",
            "        [8.1636],\n",
            "        [8.5958]]), target_rating: tensor([8, 2, 7, 9])\n",
            "model_output: tensor([[7.7777],\n",
            "        [6.8412],\n",
            "        [7.7417],\n",
            "        [8.3141]]), target_rating: tensor([8, 5, 6, 8])\n",
            "model_output: tensor([[8.0243],\n",
            "        [6.3729],\n",
            "        [8.1571],\n",
            "        [6.1970]]), target_rating: tensor([9, 6, 9, 8])\n",
            "model_output: tensor([[5.7329],\n",
            "        [6.2180],\n",
            "        [6.2927],\n",
            "        [8.0183]]), target_rating: tensor([8, 8, 6, 7])\n",
            "model_output: tensor([[8.9930],\n",
            "        [7.2468],\n",
            "        [7.2432],\n",
            "        [5.1684]]), target_rating: tensor([10,  7,  9,  7])\n",
            "model_output: tensor([[9.2149],\n",
            "        [6.7037],\n",
            "        [6.6306],\n",
            "        [6.4411]]), target_rating: tensor([3, 6, 7, 7])\n",
            "model_output: tensor([[7.9882],\n",
            "        [7.1470],\n",
            "        [6.6090],\n",
            "        [8.9547]]), target_rating: tensor([9, 6, 8, 6])\n",
            "model_output: tensor([[ 7.1082],\n",
            "        [10.0821],\n",
            "        [ 8.0291],\n",
            "        [ 7.1986]]), target_rating: tensor([ 7, 10,  8,  6])\n",
            "model_output: tensor([[6.9590],\n",
            "        [8.2126],\n",
            "        [6.2191],\n",
            "        [8.5406]]), target_rating: tensor([10,  9,  8,  7])\n",
            "model_output: tensor([[9.8371],\n",
            "        [6.6234],\n",
            "        [3.6844],\n",
            "        [6.0322]]), target_rating: tensor([10,  8,  3,  6])\n",
            "model_output: tensor([[8.0304],\n",
            "        [9.1356],\n",
            "        [7.9820],\n",
            "        [7.6947]]), target_rating: tensor([7, 8, 6, 8])\n",
            "model_output: tensor([[8.7563],\n",
            "        [8.2796],\n",
            "        [6.9808],\n",
            "        [8.0747]]), target_rating: tensor([ 9, 10,  6,  8])\n",
            "model_output: tensor([[8.0966],\n",
            "        [7.3823],\n",
            "        [6.9487],\n",
            "        [8.1656]]), target_rating: tensor([9, 7, 7, 8])\n",
            "model_output: tensor([[6.7882],\n",
            "        [7.9377],\n",
            "        [7.6608],\n",
            "        [6.4282]]), target_rating: tensor([6, 6, 9, 6])\n",
            "model_output: tensor([[7.8217],\n",
            "        [7.0535],\n",
            "        [4.4134],\n",
            "        [8.4676]]), target_rating: tensor([8, 6, 6, 8])\n",
            "model_output: tensor([[8.5883],\n",
            "        [8.0927],\n",
            "        [6.7306],\n",
            "        [8.0832]]), target_rating: tensor([8, 8, 6, 6])\n",
            "model_output: tensor([[8.0507],\n",
            "        [8.7369],\n",
            "        [6.5162],\n",
            "        [7.7808]]), target_rating: tensor([9, 8, 6, 9])\n",
            "model_output: tensor([[7.7182],\n",
            "        [6.3958],\n",
            "        [9.1559],\n",
            "        [8.2480]]), target_rating: tensor([6, 5, 9, 6])\n",
            "model_output: tensor([[8.5411],\n",
            "        [8.5834],\n",
            "        [9.7265],\n",
            "        [7.2890]]), target_rating: tensor([10,  9,  7,  8])\n",
            "model_output: tensor([[5.6017],\n",
            "        [8.1373],\n",
            "        [6.3652],\n",
            "        [8.8455]]), target_rating: tensor([ 7,  8,  9, 10])\n",
            "model_output: tensor([[5.1566],\n",
            "        [7.5524],\n",
            "        [6.3603],\n",
            "        [8.2787]]), target_rating: tensor([8, 8, 6, 7])\n",
            "model_output: tensor([[7.1931],\n",
            "        [8.0419],\n",
            "        [9.1978],\n",
            "        [7.9295]]), target_rating: tensor([6, 8, 8, 7])\n",
            "model_output: tensor([[6.3820],\n",
            "        [9.0049],\n",
            "        [8.1200],\n",
            "        [7.8045]]), target_rating: tensor([ 7, 10,  7,  8])\n",
            "model_output: tensor([[6.4045],\n",
            "        [8.5257],\n",
            "        [4.1704],\n",
            "        [6.7064]]), target_rating: tensor([4, 8, 6, 6])\n",
            "model_output: tensor([[9.2983],\n",
            "        [7.1468],\n",
            "        [7.8841],\n",
            "        [5.3541]]), target_rating: tensor([8, 7, 7, 7])\n",
            "model_output: tensor([[5.7152],\n",
            "        [7.9700],\n",
            "        [7.7794],\n",
            "        [7.8423]]), target_rating: tensor([ 6,  9, 10,  7])\n",
            "model_output: tensor([[7.0747],\n",
            "        [8.9856],\n",
            "        [4.7981],\n",
            "        [6.7182]]), target_rating: tensor([ 9, 10,  2,  6])\n",
            "model_output: tensor([[8.6725],\n",
            "        [8.7794],\n",
            "        [9.1511],\n",
            "        [5.3741]]), target_rating: tensor([10, 10,  9,  6])\n",
            "model_output: tensor([[ 7.7255],\n",
            "        [ 7.8562],\n",
            "        [ 6.3316],\n",
            "        [10.2841]]), target_rating: tensor([ 9,  6,  5, 10])\n",
            "model_output: tensor([[7.2241],\n",
            "        [5.7769],\n",
            "        [7.0143],\n",
            "        [7.3862]]), target_rating: tensor([ 8,  7,  7, 10])\n",
            "model_output: tensor([[7.5574],\n",
            "        [5.3077],\n",
            "        [8.1220],\n",
            "        [5.5837]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[7.5401],\n",
            "        [9.2153],\n",
            "        [8.9341],\n",
            "        [7.0410]]), target_rating: tensor([8, 9, 9, 8])\n",
            "model_output: tensor([[7.7070],\n",
            "        [6.1020],\n",
            "        [8.5302],\n",
            "        [8.9695]]), target_rating: tensor([7, 7, 8, 8])\n",
            "model_output: tensor([[7.2386],\n",
            "        [6.7517],\n",
            "        [6.7418],\n",
            "        [6.6971]]), target_rating: tensor([9, 7, 8, 7])\n",
            "model_output: tensor([[6.6729],\n",
            "        [7.2902],\n",
            "        [8.7696],\n",
            "        [7.7169]]), target_rating: tensor([9, 7, 9, 9])\n",
            "model_output: tensor([[6.1222],\n",
            "        [7.5310],\n",
            "        [8.6640],\n",
            "        [5.7410]]), target_rating: tensor([6, 8, 8, 7])\n",
            "model_output: tensor([[6.7763],\n",
            "        [7.2234],\n",
            "        [8.0115],\n",
            "        [6.7100]]), target_rating: tensor([4, 7, 6, 7])\n",
            "model_output: tensor([[7.7963],\n",
            "        [8.9253],\n",
            "        [7.8844],\n",
            "        [7.4395]]), target_rating: tensor([7, 8, 6, 8])\n",
            "model_output: tensor([[8.3846],\n",
            "        [7.7670],\n",
            "        [7.6080],\n",
            "        [7.9874]]), target_rating: tensor([8, 7, 7, 9])\n",
            "model_output: tensor([[7.4982],\n",
            "        [5.9372],\n",
            "        [8.2909],\n",
            "        [9.2426]]), target_rating: tensor([ 8,  9, 10, 10])\n",
            "model_output: tensor([[6.8683],\n",
            "        [7.3654],\n",
            "        [7.4860],\n",
            "        [6.5301]]), target_rating: tensor([ 9, 10,  6,  2])\n",
            "model_output: tensor([[6.2642],\n",
            "        [8.9383],\n",
            "        [5.2497],\n",
            "        [7.5070]]), target_rating: tensor([ 6, 10,  7,  7])\n",
            "model_output: tensor([[8.0899],\n",
            "        [6.6187],\n",
            "        [8.6891],\n",
            "        [8.2248]]), target_rating: tensor([9, 8, 8, 6])\n",
            "model_output: tensor([[7.1472],\n",
            "        [6.4940],\n",
            "        [8.1168],\n",
            "        [7.5951]]), target_rating: tensor([7, 8, 9, 7])\n",
            "model_output: tensor([[8.0667],\n",
            "        [6.2279],\n",
            "        [9.6067],\n",
            "        [9.3716]]), target_rating: tensor([ 8,  7, 10, 10])\n",
            "model_output: tensor([[7.6989],\n",
            "        [7.0049],\n",
            "        [7.1763],\n",
            "        [6.5523]]), target_rating: tensor([ 7, 10,  5,  7])\n",
            "model_output: tensor([[7.2391],\n",
            "        [7.1491],\n",
            "        [8.8469],\n",
            "        [8.2754]]), target_rating: tensor([ 5,  6,  9, 10])\n",
            "model_output: tensor([[7.8149],\n",
            "        [5.7598],\n",
            "        [7.6339],\n",
            "        [6.9130]]), target_rating: tensor([10,  6,  8,  7])\n",
            "model_output: tensor([[9.3923],\n",
            "        [8.2050],\n",
            "        [6.5576],\n",
            "        [8.4450]]), target_rating: tensor([8, 7, 8, 7])\n",
            "model_output: tensor([[6.8125],\n",
            "        [6.2157],\n",
            "        [8.9090],\n",
            "        [8.6319]]), target_rating: tensor([5, 6, 6, 8])\n",
            "model_output: tensor([[7.2238],\n",
            "        [7.6094],\n",
            "        [7.3898],\n",
            "        [6.7867]]), target_rating: tensor([ 7, 10,  7,  4])\n",
            "model_output: tensor([[9.5103],\n",
            "        [8.4161],\n",
            "        [5.8657],\n",
            "        [8.2852]]), target_rating: tensor([9, 9, 6, 8])\n",
            "model_output: tensor([[8.0810],\n",
            "        [9.1205],\n",
            "        [6.8025],\n",
            "        [7.1450]]), target_rating: tensor([8, 9, 6, 7])\n",
            "model_output: tensor([[6.7687],\n",
            "        [7.7424],\n",
            "        [6.8687],\n",
            "        [8.5355]]), target_rating: tensor([ 8,  7, 10,  7])\n",
            "model_output: tensor([[7.3318],\n",
            "        [5.4776],\n",
            "        [7.6563],\n",
            "        [6.6536]]), target_rating: tensor([9, 6, 6, 5])\n",
            "model_output: tensor([[6.7034],\n",
            "        [8.6753],\n",
            "        [5.0555],\n",
            "        [7.3148]]), target_rating: tensor([5, 9, 6, 6])\n",
            "model_output: tensor([[8.3006],\n",
            "        [6.2928],\n",
            "        [7.3897],\n",
            "        [6.9387]]), target_rating: tensor([10,  8, 10,  8])\n",
            "model_output: tensor([[6.8712],\n",
            "        [7.8833],\n",
            "        [7.1922],\n",
            "        [8.6213]]), target_rating: tensor([8, 2, 7, 8])\n",
            "model_output: tensor([[7.8371],\n",
            "        [6.5399],\n",
            "        [8.4838],\n",
            "        [6.1578]]), target_rating: tensor([5, 7, 9, 4])\n",
            "model_output: tensor([[8.4078],\n",
            "        [7.2238],\n",
            "        [6.4562],\n",
            "        [6.7142]]), target_rating: tensor([10,  5, 10,  7])\n",
            "model_output: tensor([[6.7577],\n",
            "        [8.3006],\n",
            "        [7.1073],\n",
            "        [8.7905]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[7.7518],\n",
            "        [6.4602],\n",
            "        [7.0339],\n",
            "        [8.7216]]), target_rating: tensor([9, 6, 5, 8])\n",
            "model_output: tensor([[7.4330],\n",
            "        [9.1789],\n",
            "        [7.2630],\n",
            "        [7.2671]]), target_rating: tensor([6, 7, 5, 9])\n",
            "model_output: tensor([[8.1955],\n",
            "        [6.2196],\n",
            "        [8.8495],\n",
            "        [8.5189]]), target_rating: tensor([ 8,  4, 10,  8])\n",
            "model_output: tensor([[6.7483],\n",
            "        [7.3161],\n",
            "        [8.8727],\n",
            "        [7.8326]]), target_rating: tensor([6, 7, 9, 9])\n",
            "model_output: tensor([[8.9064],\n",
            "        [6.0835],\n",
            "        [6.8364],\n",
            "        [7.8333]]), target_rating: tensor([8, 8, 8, 9])\n",
            "model_output: tensor([[6.1664],\n",
            "        [7.1166],\n",
            "        [8.0842],\n",
            "        [8.8572]]), target_rating: tensor([ 7,  8,  7, 10])\n",
            "model_output: tensor([[7.5995],\n",
            "        [7.2266],\n",
            "        [5.6648],\n",
            "        [6.1742]]), target_rating: tensor([5, 9, 5, 5])\n",
            "model_output: tensor([[ 7.9958],\n",
            "        [10.3228],\n",
            "        [ 6.1901],\n",
            "        [ 9.4374]]), target_rating: tensor([7, 9, 6, 9])\n",
            "model_output: tensor([[6.7715],\n",
            "        [7.2324],\n",
            "        [7.7820],\n",
            "        [6.3369]]), target_rating: tensor([9, 6, 7, 5])\n",
            "model_output: tensor([[7.9691],\n",
            "        [9.6717],\n",
            "        [7.9530],\n",
            "        [5.4288]]), target_rating: tensor([10,  7,  9,  8])\n",
            "model_output: tensor([[11.1878],\n",
            "        [ 9.2954],\n",
            "        [10.3798],\n",
            "        [ 5.3019]]), target_rating: tensor([10,  8, 10,  8])\n",
            "model_output: tensor([[ 8.8374],\n",
            "        [11.1643],\n",
            "        [ 8.6496],\n",
            "        [ 9.2782]]), target_rating: tensor([ 9, 10,  8,  8])\n",
            "model_output: tensor([[8.6954],\n",
            "        [8.3902],\n",
            "        [6.1880],\n",
            "        [8.5599]]), target_rating: tensor([10,  7,  6,  9])\n",
            "model_output: tensor([[7.7122],\n",
            "        [6.9918],\n",
            "        [8.4113],\n",
            "        [7.4614]]), target_rating: tensor([8, 8, 7, 8])\n",
            "model_output: tensor([[7.0528],\n",
            "        [5.7165],\n",
            "        [5.6704],\n",
            "        [6.8039]]), target_rating: tensor([6, 5, 7, 9])\n",
            "model_output: tensor([[7.3755],\n",
            "        [6.3850],\n",
            "        [5.8357],\n",
            "        [8.3967]]), target_rating: tensor([7, 6, 7, 9])\n",
            "model_output: tensor([[7.9359],\n",
            "        [8.0569],\n",
            "        [7.2137],\n",
            "        [8.2309]]), target_rating: tensor([8, 9, 8, 7])\n",
            "model_output: tensor([[7.3729],\n",
            "        [7.5982],\n",
            "        [8.1300],\n",
            "        [6.8864]]), target_rating: tensor([8, 7, 5, 8])\n",
            "model_output: tensor([[6.7685],\n",
            "        [6.8689],\n",
            "        [7.2277],\n",
            "        [6.9226]]), target_rating: tensor([ 7,  7, 10,  9])\n",
            "model_output: tensor([[6.5804],\n",
            "        [6.0002],\n",
            "        [9.0056],\n",
            "        [8.2746]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[7.1765],\n",
            "        [6.0918],\n",
            "        [9.0344],\n",
            "        [7.0466]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[10.2081],\n",
            "        [ 6.2921],\n",
            "        [ 7.3289],\n",
            "        [ 5.6470]]), target_rating: tensor([10,  5,  7,  4])\n",
            "model_output: tensor([[7.1313],\n",
            "        [7.6246],\n",
            "        [6.2594],\n",
            "        [7.8807]]), target_rating: tensor([9, 9, 6, 6])\n",
            "model_output: tensor([[6.3688],\n",
            "        [6.0728],\n",
            "        [6.1181],\n",
            "        [5.9382]]), target_rating: tensor([7, 7, 6, 6])\n",
            "model_output: tensor([[6.1110],\n",
            "        [8.8053],\n",
            "        [7.4543],\n",
            "        [7.1161]]), target_rating: tensor([ 7,  8, 10,  6])\n",
            "model_output: tensor([[8.7046],\n",
            "        [7.2521],\n",
            "        [6.3221],\n",
            "        [6.6244]]), target_rating: tensor([8, 7, 7, 9])\n",
            "model_output: tensor([[7.2558],\n",
            "        [8.4210],\n",
            "        [7.6747],\n",
            "        [6.0015]]), target_rating: tensor([5, 8, 9, 8])\n",
            "model_output: tensor([[6.4061],\n",
            "        [8.0114],\n",
            "        [7.8201],\n",
            "        [7.8155]]), target_rating: tensor([8, 8, 9, 6])\n",
            "model_output: tensor([[6.4269],\n",
            "        [7.8412],\n",
            "        [7.7997],\n",
            "        [6.9464]]), target_rating: tensor([6, 8, 6, 7])\n",
            "model_output: tensor([[8.0524],\n",
            "        [6.1743],\n",
            "        [6.6379],\n",
            "        [6.8944]]), target_rating: tensor([7, 5, 6, 8])\n",
            "model_output: tensor([[7.2517],\n",
            "        [7.4934],\n",
            "        [8.1557],\n",
            "        [7.5609]]), target_rating: tensor([4, 4, 9, 7])\n",
            "model_output: tensor([[6.8700],\n",
            "        [7.7514],\n",
            "        [6.6572],\n",
            "        [5.1453]]), target_rating: tensor([7, 7, 8, 6])\n",
            "model_output: tensor([[8.6274],\n",
            "        [7.1525],\n",
            "        [6.3869],\n",
            "        [7.4731]]), target_rating: tensor([9, 7, 9, 8])\n",
            "model_output: tensor([[7.4015],\n",
            "        [6.9875],\n",
            "        [7.3654],\n",
            "        [8.4310]]), target_rating: tensor([8, 8, 9, 7])\n",
            "model_output: tensor([[5.2172],\n",
            "        [7.4912],\n",
            "        [5.8585],\n",
            "        [9.0719]]), target_rating: tensor([7, 7, 7, 9])\n",
            "model_output: tensor([[6.3827],\n",
            "        [6.3455],\n",
            "        [8.5884],\n",
            "        [8.6547]]), target_rating: tensor([7, 7, 9, 9])\n",
            "model_output: tensor([[6.9862],\n",
            "        [8.2582],\n",
            "        [7.2360],\n",
            "        [7.0564]]), target_rating: tensor([9, 8, 7, 5])\n",
            "model_output: tensor([[5.9044],\n",
            "        [7.0665],\n",
            "        [6.9355],\n",
            "        [8.1697]]), target_rating: tensor([9, 8, 7, 9])\n",
            "model_output: tensor([[ 7.6422],\n",
            "        [ 8.1752],\n",
            "        [10.1269],\n",
            "        [ 7.3582]]), target_rating: tensor([8, 7, 9, 8])\n",
            "model_output: tensor([[7.1455],\n",
            "        [7.0091],\n",
            "        [7.9673],\n",
            "        [9.1625]]), target_rating: tensor([9, 6, 9, 8])\n",
            "model_output: tensor([[6.9774],\n",
            "        [6.2976],\n",
            "        [7.3386],\n",
            "        [7.4010]]), target_rating: tensor([ 7,  7,  8, 10])\n",
            "model_output: tensor([[7.6372],\n",
            "        [6.7578],\n",
            "        [6.1643],\n",
            "        [8.2757]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[7.8881],\n",
            "        [6.1414],\n",
            "        [4.9259],\n",
            "        [5.2730]]), target_rating: tensor([8, 7, 7, 6])\n",
            "model_output: tensor([[6.8852],\n",
            "        [7.9908],\n",
            "        [8.2649],\n",
            "        [6.7012]]), target_rating: tensor([7, 9, 8, 5])\n",
            "model_output: tensor([[6.0508],\n",
            "        [6.2031],\n",
            "        [6.4642],\n",
            "        [5.9858]]), target_rating: tensor([6, 6, 7, 6])\n",
            "model_output: tensor([[7.4638],\n",
            "        [7.4394],\n",
            "        [7.9195],\n",
            "        [7.3730]]), target_rating: tensor([9, 7, 6, 8])\n",
            "model_output: tensor([[8.9605],\n",
            "        [7.8462],\n",
            "        [7.6641],\n",
            "        [5.3811]]), target_rating: tensor([9, 6, 6, 5])\n",
            "model_output: tensor([[7.9845],\n",
            "        [7.8110],\n",
            "        [5.6922],\n",
            "        [8.2308]]), target_rating: tensor([8, 9, 6, 7])\n",
            "model_output: tensor([[6.6497],\n",
            "        [7.3350],\n",
            "        [7.8431],\n",
            "        [5.6400]]), target_rating: tensor([8, 8, 5, 2])\n",
            "model_output: tensor([[5.5670],\n",
            "        [5.4625],\n",
            "        [7.0597],\n",
            "        [6.4613]]), target_rating: tensor([5, 7, 5, 6])\n",
            "model_output: tensor([[6.9157],\n",
            "        [8.8229],\n",
            "        [8.2578],\n",
            "        [6.1620]]), target_rating: tensor([7, 7, 7, 5])\n",
            "model_output: tensor([[8.2279],\n",
            "        [8.6009],\n",
            "        [6.9741],\n",
            "        [7.8572]]), target_rating: tensor([8, 7, 7, 9])\n",
            "model_output: tensor([[6.6073],\n",
            "        [7.1684],\n",
            "        [6.3881],\n",
            "        [8.1499]]), target_rating: tensor([6, 6, 5, 8])\n",
            "model_output: tensor([[7.9758],\n",
            "        [7.6339],\n",
            "        [4.5993],\n",
            "        [6.9421]]), target_rating: tensor([8, 9, 2, 8])\n",
            "model_output: tensor([[7.0641],\n",
            "        [8.0822],\n",
            "        [7.1365],\n",
            "        [9.7349]]), target_rating: tensor([10, 10,  7,  9])\n",
            "model_output: tensor([[9.6361],\n",
            "        [6.8639],\n",
            "        [7.5315],\n",
            "        [5.8647]]), target_rating: tensor([8, 5, 8, 6])\n",
            "model_output: tensor([[6.3573],\n",
            "        [8.4194],\n",
            "        [9.0488],\n",
            "        [7.7880]]), target_rating: tensor([8, 7, 9, 7])\n",
            "model_output: tensor([[5.6231],\n",
            "        [5.6294],\n",
            "        [6.8084],\n",
            "        [6.0896]]), target_rating: tensor([7, 7, 6, 8])\n",
            "model_output: tensor([[7.1482],\n",
            "        [6.4144],\n",
            "        [8.5107],\n",
            "        [6.2948]]), target_rating: tensor([ 7,  6, 10,  6])\n",
            "model_output: tensor([[7.8969],\n",
            "        [8.6696],\n",
            "        [6.6557],\n",
            "        [6.9389]]), target_rating: tensor([8, 8, 6, 8])\n",
            "model_output: tensor([[8.0234],\n",
            "        [8.7065],\n",
            "        [6.0135],\n",
            "        [9.1123]]), target_rating: tensor([9, 9, 8, 8])\n",
            "model_output: tensor([[9.7601],\n",
            "        [7.6758],\n",
            "        [6.9317],\n",
            "        [7.8510]]), target_rating: tensor([7, 7, 7, 7])\n",
            "model_output: tensor([[5.7308],\n",
            "        [7.9411],\n",
            "        [8.5692],\n",
            "        [6.6058]]), target_rating: tensor([5, 9, 8, 8])\n",
            "model_output: tensor([[6.1138],\n",
            "        [6.0013],\n",
            "        [7.2762],\n",
            "        [7.5770]]), target_rating: tensor([3, 7, 7, 9])\n",
            "model_output: tensor([[6.3718],\n",
            "        [8.4610],\n",
            "        [8.0384],\n",
            "        [8.7934]]), target_rating: tensor([7, 8, 7, 8])\n",
            "model_output: tensor([[9.5922],\n",
            "        [6.6970],\n",
            "        [9.1371],\n",
            "        [7.2670]]), target_rating: tensor([8, 5, 9, 8])\n",
            "model_output: tensor([[6.5247],\n",
            "        [7.9517],\n",
            "        [9.4937],\n",
            "        [6.0925]]), target_rating: tensor([7, 9, 9, 7])\n",
            "model_output: tensor([[7.5180],\n",
            "        [5.7593],\n",
            "        [8.1494],\n",
            "        [8.1911]]), target_rating: tensor([ 7,  6,  6, 10])\n",
            "model_output: tensor([[8.4783],\n",
            "        [4.6692],\n",
            "        [6.0649],\n",
            "        [7.1103]]), target_rating: tensor([10,  5,  7,  5])\n",
            "model_output: tensor([[5.7853],\n",
            "        [7.8598],\n",
            "        [7.2739],\n",
            "        [7.1002]]), target_rating: tensor([9, 7, 5, 5])\n",
            "model_output: tensor([[8.7983],\n",
            "        [7.3400],\n",
            "        [7.4834],\n",
            "        [7.2183]]), target_rating: tensor([10,  6,  6,  7])\n",
            "model_output: tensor([[8.8377],\n",
            "        [7.1411],\n",
            "        [3.9237],\n",
            "        [7.4664]]), target_rating: tensor([8, 6, 1, 6])\n",
            "model_output: tensor([[9.3300],\n",
            "        [8.8790],\n",
            "        [6.7832],\n",
            "        [6.7537]]), target_rating: tensor([8, 9, 7, 6])\n",
            "model_output: tensor([[7.5030],\n",
            "        [5.7108],\n",
            "        [9.7350],\n",
            "        [7.7004]]), target_rating: tensor([9, 5, 9, 8])\n",
            "model_output: tensor([[7.9647],\n",
            "        [5.0234],\n",
            "        [4.7944],\n",
            "        [7.5546]]), target_rating: tensor([10,  6,  4,  8])\n",
            "model_output: tensor([[8.4534],\n",
            "        [6.1401],\n",
            "        [4.5058],\n",
            "        [8.2710]]), target_rating: tensor([8, 5, 5, 9])\n",
            "model_output: tensor([[5.2723],\n",
            "        [6.2260],\n",
            "        [8.0347],\n",
            "        [8.3358]]), target_rating: tensor([6, 6, 6, 9])\n",
            "model_output: tensor([[7.5292],\n",
            "        [9.2134],\n",
            "        [6.9276],\n",
            "        [5.9721]]), target_rating: tensor([8, 9, 7, 5])\n",
            "model_output: tensor([[7.8241],\n",
            "        [9.9623],\n",
            "        [7.9726],\n",
            "        [7.2042]]), target_rating: tensor([8, 8, 8, 9])\n",
            "model_output: tensor([[9.2679],\n",
            "        [7.3008],\n",
            "        [7.6479],\n",
            "        [6.9164]]), target_rating: tensor([10,  8,  5,  8])\n",
            "model_output: tensor([[8.8395],\n",
            "        [7.3622],\n",
            "        [9.6488],\n",
            "        [6.4551]]), target_rating: tensor([ 9, 10, 10,  3])\n",
            "model_output: tensor([[6.8320],\n",
            "        [7.2673],\n",
            "        [5.4324],\n",
            "        [8.0206]]), target_rating: tensor([7, 8, 4, 9])\n",
            "model_output: tensor([[6.2646],\n",
            "        [6.4372],\n",
            "        [8.5374],\n",
            "        [6.3012]]), target_rating: tensor([7, 7, 8, 5])\n",
            "model_output: tensor([[7.9393],\n",
            "        [8.3865],\n",
            "        [7.3059],\n",
            "        [7.7031]]), target_rating: tensor([8, 8, 8, 7])\n",
            "model_output: tensor([[6.9998],\n",
            "        [7.4060],\n",
            "        [7.5694],\n",
            "        [8.4496]]), target_rating: tensor([7, 6, 7, 7])\n",
            "model_output: tensor([[7.7752],\n",
            "        [7.8069],\n",
            "        [7.6181],\n",
            "        [5.9588]]), target_rating: tensor([8, 7, 8, 9])\n",
            "model_output: tensor([[8.0185],\n",
            "        [8.4059],\n",
            "        [6.7003],\n",
            "        [7.8111]]), target_rating: tensor([6, 8, 6, 8])\n",
            "model_output: tensor([[6.2343],\n",
            "        [9.2771],\n",
            "        [8.9047],\n",
            "        [5.2224]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[7.6931],\n",
            "        [7.3034],\n",
            "        [7.4935],\n",
            "        [7.1187]]), target_rating: tensor([9, 6, 7, 6])\n",
            "model_output: tensor([[6.3642],\n",
            "        [6.1239],\n",
            "        [5.0348],\n",
            "        [6.5371]]), target_rating: tensor([5, 7, 6, 9])\n",
            "model_output: tensor([[7.4283],\n",
            "        [5.3177],\n",
            "        [6.1509],\n",
            "        [6.5921]]), target_rating: tensor([5, 4, 8, 8])\n",
            "model_output: tensor([[5.6303],\n",
            "        [8.3360],\n",
            "        [5.8968],\n",
            "        [7.3444]]), target_rating: tensor([7, 8, 6, 8])\n",
            "model_output: tensor([[7.0037],\n",
            "        [7.9141],\n",
            "        [6.1103],\n",
            "        [7.8187]]), target_rating: tensor([ 6,  7,  6, 10])\n",
            "model_output: tensor([[6.3779],\n",
            "        [5.7857],\n",
            "        [8.5548],\n",
            "        [7.3407]]), target_rating: tensor([5, 5, 7, 8])\n",
            "model_output: tensor([[8.1434],\n",
            "        [6.8941],\n",
            "        [4.4038],\n",
            "        [7.0823]]), target_rating: tensor([8, 8, 8, 8])\n",
            "model_output: tensor([[8.2726],\n",
            "        [4.6828],\n",
            "        [8.1359],\n",
            "        [7.6180]]), target_rating: tensor([9, 5, 6, 7])\n",
            "model_output: tensor([[6.6450],\n",
            "        [8.2711],\n",
            "        [7.9628],\n",
            "        [8.7620]]), target_rating: tensor([4, 9, 7, 8])\n",
            "model_output: tensor([[7.8757],\n",
            "        [7.2299],\n",
            "        [7.6658],\n",
            "        [6.2651]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[7.7525],\n",
            "        [6.9520],\n",
            "        [6.9231],\n",
            "        [5.6332]]), target_rating: tensor([4, 7, 8, 6])\n",
            "model_output: tensor([[6.8022],\n",
            "        [7.4734],\n",
            "        [4.2207],\n",
            "        [7.2554]]), target_rating: tensor([8, 9, 1, 7])\n",
            "model_output: tensor([[6.0209],\n",
            "        [7.5367],\n",
            "        [8.9201],\n",
            "        [7.0028]]), target_rating: tensor([ 3,  8, 10,  8])\n",
            "model_output: tensor([[6.3515],\n",
            "        [6.0158],\n",
            "        [9.1121],\n",
            "        [7.0011]]), target_rating: tensor([5, 7, 9, 6])\n",
            "model_output: tensor([[8.6130],\n",
            "        [7.2752],\n",
            "        [8.4792],\n",
            "        [7.8118]]), target_rating: tensor([9, 7, 4, 9])\n",
            "model_output: tensor([[5.1371],\n",
            "        [7.1608],\n",
            "        [7.6831],\n",
            "        [8.2635]]), target_rating: tensor([6, 5, 8, 8])\n",
            "model_output: tensor([[7.9195],\n",
            "        [5.5184],\n",
            "        [5.5420],\n",
            "        [5.0004]]), target_rating: tensor([10,  5,  5,  2])\n",
            "model_output: tensor([[6.4151],\n",
            "        [5.7245],\n",
            "        [7.7052],\n",
            "        [5.6814]]), target_rating: tensor([7, 4, 6, 7])\n",
            "model_output: tensor([[8.0869],\n",
            "        [6.9071],\n",
            "        [5.5627],\n",
            "        [7.0159]]), target_rating: tensor([10,  4,  7,  6])\n",
            "model_output: tensor([[7.9012],\n",
            "        [7.3413],\n",
            "        [6.1472],\n",
            "        [6.4557]]), target_rating: tensor([7, 7, 6, 8])\n",
            "model_output: tensor([[6.3390],\n",
            "        [8.5215],\n",
            "        [6.6568],\n",
            "        [7.3605]]), target_rating: tensor([7, 9, 6, 5])\n",
            "model_output: tensor([[8.3034],\n",
            "        [4.7564],\n",
            "        [7.7983],\n",
            "        [9.3495]]), target_rating: tensor([ 9,  6, 10,  9])\n",
            "model_output: tensor([[5.0127],\n",
            "        [7.9933],\n",
            "        [8.3709],\n",
            "        [7.4800]]), target_rating: tensor([ 7,  7, 10,  7])\n",
            "model_output: tensor([[6.7866],\n",
            "        [8.5697],\n",
            "        [7.1992],\n",
            "        [6.8718]]), target_rating: tensor([10, 10,  7,  6])\n",
            "model_output: tensor([[8.7757],\n",
            "        [7.4412],\n",
            "        [8.7388],\n",
            "        [6.1688]]), target_rating: tensor([10,  9,  9,  6])\n",
            "model_output: tensor([[7.8333],\n",
            "        [8.2095],\n",
            "        [5.5947],\n",
            "        [7.2720]]), target_rating: tensor([9, 6, 8, 7])\n",
            "model_output: tensor([[8.0146],\n",
            "        [5.7542],\n",
            "        [6.8058],\n",
            "        [7.7963]]), target_rating: tensor([ 7,  6,  6, 10])\n",
            "model_output: tensor([[6.8624],\n",
            "        [9.5334],\n",
            "        [6.8674],\n",
            "        [7.7850]]), target_rating: tensor([ 7, 10,  6,  7])\n",
            "model_output: tensor([[6.9529],\n",
            "        [5.8185],\n",
            "        [7.7712],\n",
            "        [7.4588]]), target_rating: tensor([8, 8, 8, 9])\n",
            "model_output: tensor([[7.4939],\n",
            "        [8.0081],\n",
            "        [7.5554],\n",
            "        [7.2525]]), target_rating: tensor([6, 8, 8, 8])\n",
            "model_output: tensor([[8.0847],\n",
            "        [7.3240],\n",
            "        [8.6985],\n",
            "        [8.6954]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[7.5648],\n",
            "        [7.3145],\n",
            "        [8.5788],\n",
            "        [8.6897]]), target_rating: tensor([ 9,  5,  8, 10])\n",
            "model_output: tensor([[7.7269],\n",
            "        [7.7781],\n",
            "        [6.9153],\n",
            "        [8.5372]]), target_rating: tensor([9, 8, 8, 8])\n",
            "model_output: tensor([[7.2298],\n",
            "        [6.1289],\n",
            "        [8.3058],\n",
            "        [7.0779]]), target_rating: tensor([7, 7, 6, 7])\n",
            "model_output: tensor([[7.6060],\n",
            "        [6.7677],\n",
            "        [7.0503],\n",
            "        [6.8113]]), target_rating: tensor([7, 5, 7, 7])\n",
            "model_output: tensor([[7.9605],\n",
            "        [8.6126],\n",
            "        [7.4910],\n",
            "        [8.2741]]), target_rating: tensor([8, 8, 9, 9])\n",
            "model_output: tensor([[6.2928],\n",
            "        [7.1186],\n",
            "        [8.2380],\n",
            "        [7.1984]]), target_rating: tensor([9, 7, 9, 7])\n",
            "model_output: tensor([[8.5456],\n",
            "        [9.2689],\n",
            "        [7.8947],\n",
            "        [5.5506]]), target_rating: tensor([ 9, 10,  4,  7])\n",
            "model_output: tensor([[5.8049],\n",
            "        [7.4566],\n",
            "        [8.5314],\n",
            "        [6.8781]]), target_rating: tensor([ 7,  8, 10,  8])\n",
            "model_output: tensor([[6.2931],\n",
            "        [7.8105],\n",
            "        [7.4170],\n",
            "        [8.0832]]), target_rating: tensor([7, 7, 7, 7])\n",
            "model_output: tensor([[9.6195],\n",
            "        [8.5892],\n",
            "        [8.3122],\n",
            "        [7.0982]]), target_rating: tensor([ 9, 10,  9,  6])\n",
            "model_output: tensor([[8.3202],\n",
            "        [8.3237],\n",
            "        [6.9202],\n",
            "        [8.2627]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[6.4103],\n",
            "        [6.7057],\n",
            "        [8.9095],\n",
            "        [4.2861]]), target_rating: tensor([ 8, 10, 10,  5])\n",
            "model_output: tensor([[5.4243],\n",
            "        [8.9785],\n",
            "        [6.3703],\n",
            "        [8.7232]]), target_rating: tensor([ 5, 10, 10,  9])\n",
            "model_output: tensor([[8.4602],\n",
            "        [8.6364],\n",
            "        [8.0115],\n",
            "        [9.4760]]), target_rating: tensor([ 6,  7, 10,  8])\n",
            "model_output: tensor([[5.5618],\n",
            "        [5.2698],\n",
            "        [7.1923],\n",
            "        [6.9379]]), target_rating: tensor([4, 5, 6, 7])\n",
            "model_output: tensor([[6.7307],\n",
            "        [6.7480],\n",
            "        [6.4011],\n",
            "        [6.1358]]), target_rating: tensor([6, 7, 6, 7])\n",
            "model_output: tensor([[8.1583],\n",
            "        [8.6182],\n",
            "        [6.2963],\n",
            "        [7.4712]]), target_rating: tensor([10,  8,  6,  7])\n",
            "model_output: tensor([[8.1287],\n",
            "        [7.0791],\n",
            "        [6.1913],\n",
            "        [5.8032]]), target_rating: tensor([10,  7, 10,  9])\n",
            "model_output: tensor([[8.8839],\n",
            "        [8.4632],\n",
            "        [9.4802],\n",
            "        [7.6187]]), target_rating: tensor([10,  9,  9,  7])\n",
            "model_output: tensor([[7.7469],\n",
            "        [8.8649],\n",
            "        [7.1230],\n",
            "        [7.1780]]), target_rating: tensor([6, 9, 8, 7])\n",
            "model_output: tensor([[7.3233],\n",
            "        [6.8519],\n",
            "        [6.2615],\n",
            "        [9.1605]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[7.6388],\n",
            "        [6.7451],\n",
            "        [6.3311],\n",
            "        [8.1256]]), target_rating: tensor([7, 2, 7, 7])\n",
            "model_output: tensor([[6.5722],\n",
            "        [7.6250],\n",
            "        [7.5001],\n",
            "        [7.1554]]), target_rating: tensor([10,  8,  5,  8])\n",
            "model_output: tensor([[6.4911],\n",
            "        [6.0260],\n",
            "        [7.8425],\n",
            "        [6.7176]]), target_rating: tensor([6, 6, 7, 7])\n",
            "model_output: tensor([[4.6746],\n",
            "        [7.2270],\n",
            "        [9.1653],\n",
            "        [7.4280]]), target_rating: tensor([4, 7, 8, 9])\n",
            "model_output: tensor([[7.8091],\n",
            "        [5.7874],\n",
            "        [8.6983],\n",
            "        [7.7574]]), target_rating: tensor([9, 7, 8, 7])\n",
            "model_output: tensor([[8.8117],\n",
            "        [6.9010],\n",
            "        [8.7451],\n",
            "        [8.4800]]), target_rating: tensor([7, 6, 6, 8])\n",
            "model_output: tensor([[6.2369],\n",
            "        [6.7639],\n",
            "        [5.4059],\n",
            "        [6.3637]]), target_rating: tensor([5, 9, 7, 5])\n",
            "model_output: tensor([[5.4323],\n",
            "        [7.1523],\n",
            "        [7.2179],\n",
            "        [8.1703]]), target_rating: tensor([5, 7, 7, 8])\n",
            "model_output: tensor([[7.9011],\n",
            "        [8.0450],\n",
            "        [8.3347],\n",
            "        [8.7167]]), target_rating: tensor([ 8, 10,  7,  7])\n",
            "model_output: tensor([[6.7050],\n",
            "        [8.5834],\n",
            "        [8.1609],\n",
            "        [7.5561]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[ 5.3170],\n",
            "        [ 7.6468],\n",
            "        [10.5169],\n",
            "        [ 6.3096]]), target_rating: tensor([ 6,  8, 10,  3])\n",
            "model_output: tensor([[5.6786],\n",
            "        [5.4696],\n",
            "        [6.2422],\n",
            "        [8.3796]]), target_rating: tensor([8, 4, 6, 8])\n",
            "model_output: tensor([[5.8099],\n",
            "        [7.3905],\n",
            "        [5.3410],\n",
            "        [6.8238]]), target_rating: tensor([5, 8, 8, 9])\n",
            "model_output: tensor([[6.7897],\n",
            "        [8.9292],\n",
            "        [6.4795],\n",
            "        [6.8308]]), target_rating: tensor([5, 6, 6, 5])\n",
            "model_output: tensor([[8.1826],\n",
            "        [9.3161],\n",
            "        [9.2278],\n",
            "        [7.3441]]), target_rating: tensor([ 8, 10,  9,  6])\n",
            "model_output: tensor([[7.2659],\n",
            "        [7.6313],\n",
            "        [5.6356],\n",
            "        [7.9487]]), target_rating: tensor([ 7, 10,  5, 10])\n",
            "model_output: tensor([[6.8781],\n",
            "        [8.9940],\n",
            "        [8.5761],\n",
            "        [7.0768]]), target_rating: tensor([ 6, 10,  8,  9])\n",
            "model_output: tensor([[6.1860],\n",
            "        [8.1046],\n",
            "        [5.0899],\n",
            "        [6.3907]]), target_rating: tensor([8, 9, 5, 6])\n",
            "model_output: tensor([[7.9223],\n",
            "        [7.2643],\n",
            "        [5.7386],\n",
            "        [6.7286]]), target_rating: tensor([6, 8, 7, 7])\n",
            "model_output: tensor([[8.4524],\n",
            "        [8.2244],\n",
            "        [5.9998],\n",
            "        [6.8816]]), target_rating: tensor([8, 8, 5, 9])\n",
            "model_output: tensor([[6.8878],\n",
            "        [7.6996],\n",
            "        [7.1397],\n",
            "        [6.6565]]), target_rating: tensor([5, 8, 9, 5])\n",
            "model_output: tensor([[6.0977],\n",
            "        [6.8790],\n",
            "        [6.5443],\n",
            "        [6.3633]]), target_rating: tensor([5, 9, 7, 8])\n",
            "model_output: tensor([[6.7495],\n",
            "        [7.7976],\n",
            "        [8.4962],\n",
            "        [6.3600]]), target_rating: tensor([ 8,  9, 10,  6])\n",
            "model_output: tensor([[8.2296],\n",
            "        [7.0357],\n",
            "        [7.8857],\n",
            "        [7.0635]]), target_rating: tensor([10,  8,  9, 10])\n",
            "model_output: tensor([[6.3542],\n",
            "        [5.3250],\n",
            "        [6.4108],\n",
            "        [9.4423]]), target_rating: tensor([ 6,  5,  7, 10])\n",
            "model_output: tensor([[7.1958],\n",
            "        [7.5195],\n",
            "        [8.2063],\n",
            "        [8.2942]]), target_rating: tensor([3, 9, 9, 9])\n",
            "model_output: tensor([[6.9827],\n",
            "        [8.4284],\n",
            "        [8.6256],\n",
            "        [7.5189]]), target_rating: tensor([ 9,  9, 10,  9])\n",
            "model_output: tensor([[9.2563],\n",
            "        [7.1179],\n",
            "        [6.5914],\n",
            "        [8.3809]]), target_rating: tensor([10,  8,  7, 10])\n",
            "model_output: tensor([[6.2343],\n",
            "        [7.4907],\n",
            "        [7.6530],\n",
            "        [5.3993]]), target_rating: tensor([6, 7, 8, 6])\n",
            "model_output: tensor([[6.3585],\n",
            "        [6.4833],\n",
            "        [5.2152],\n",
            "        [8.4631]]), target_rating: tensor([6, 6, 6, 9])\n",
            "model_output: tensor([[5.0995],\n",
            "        [6.1705],\n",
            "        [6.7973],\n",
            "        [5.8713]]), target_rating: tensor([6, 6, 7, 6])\n",
            "model_output: tensor([[5.7774],\n",
            "        [5.3018],\n",
            "        [5.4975],\n",
            "        [7.8247]]), target_rating: tensor([5, 6, 6, 8])\n",
            "model_output: tensor([[9.7978],\n",
            "        [7.1729],\n",
            "        [6.0439],\n",
            "        [7.3869]]), target_rating: tensor([8, 7, 5, 8])\n",
            "model_output: tensor([[8.6546],\n",
            "        [7.0595],\n",
            "        [6.8460],\n",
            "        [8.2678]]), target_rating: tensor([7, 7, 8, 8])\n",
            "model_output: tensor([[8.5235],\n",
            "        [7.1382],\n",
            "        [5.3741],\n",
            "        [6.2706]]), target_rating: tensor([ 9, 10,  7,  9])\n",
            "model_output: tensor([[10.5148],\n",
            "        [ 6.7781],\n",
            "        [ 8.0374],\n",
            "        [ 6.9717]]), target_rating: tensor([10,  8, 10,  9])\n",
            "model_output: tensor([[7.5179],\n",
            "        [6.2974],\n",
            "        [7.9736],\n",
            "        [7.0925]]), target_rating: tensor([6, 5, 9, 6])\n",
            "model_output: tensor([[6.5663],\n",
            "        [8.8277],\n",
            "        [6.4656],\n",
            "        [7.1133]]), target_rating: tensor([ 7, 10,  7,  9])\n",
            "model_output: tensor([[8.7202],\n",
            "        [6.5970],\n",
            "        [6.7093],\n",
            "        [5.9774]]), target_rating: tensor([ 7,  7,  5, 10])\n",
            "model_output: tensor([[6.8842],\n",
            "        [7.6739],\n",
            "        [6.4305],\n",
            "        [7.8973]]), target_rating: tensor([ 4, 10,  9,  7])\n",
            "model_output: tensor([[5.8777],\n",
            "        [7.7843],\n",
            "        [8.1498],\n",
            "        [9.0074]]), target_rating: tensor([6, 8, 7, 8])\n",
            "model_output: tensor([[6.6944],\n",
            "        [8.6590],\n",
            "        [6.4390],\n",
            "        [7.2342]]), target_rating: tensor([ 6, 10,  6,  7])\n",
            "model_output: tensor([[6.3475],\n",
            "        [7.5210],\n",
            "        [8.5914],\n",
            "        [8.1582]]), target_rating: tensor([ 8,  7, 10, 10])\n",
            "model_output: tensor([[7.8193],\n",
            "        [7.8846],\n",
            "        [7.6345],\n",
            "        [8.8151]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[8.3087],\n",
            "        [7.1978],\n",
            "        [6.2656],\n",
            "        [7.1706]]), target_rating: tensor([7, 6, 6, 7])\n",
            "model_output: tensor([[8.1955],\n",
            "        [8.7652],\n",
            "        [6.5056],\n",
            "        [5.7667]]), target_rating: tensor([7, 9, 6, 8])\n",
            "model_output: tensor([[8.6048],\n",
            "        [8.6375],\n",
            "        [6.2292],\n",
            "        [6.4714]]), target_rating: tensor([ 9,  5,  8, 10])\n",
            "model_output: tensor([[6.8876],\n",
            "        [8.1319],\n",
            "        [7.1143],\n",
            "        [9.2243]]), target_rating: tensor([8, 5, 8, 6])\n",
            "model_output: tensor([[8.9980],\n",
            "        [9.8680],\n",
            "        [7.2996],\n",
            "        [9.3746]]), target_rating: tensor([ 6, 10, 10,  8])\n",
            "model_output: tensor([[6.8104],\n",
            "        [7.1371],\n",
            "        [7.4274],\n",
            "        [9.1684]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[8.6474],\n",
            "        [6.4651],\n",
            "        [7.7603],\n",
            "        [6.3359]]), target_rating: tensor([ 8,  5, 10,  9])\n",
            "model_output: tensor([[ 6.2330],\n",
            "        [ 5.7967],\n",
            "        [ 6.7287],\n",
            "        [10.5870]]), target_rating: tensor([ 7,  9,  7, 10])\n",
            "model_output: tensor([[8.4857],\n",
            "        [8.7163],\n",
            "        [7.9788],\n",
            "        [8.0622]]), target_rating: tensor([9, 8, 9, 9])\n",
            "model_output: tensor([[5.9660],\n",
            "        [5.6763],\n",
            "        [8.0590],\n",
            "        [6.8995]]), target_rating: tensor([7, 7, 7, 7])\n",
            "model_output: tensor([[7.9532],\n",
            "        [6.2807],\n",
            "        [6.4415],\n",
            "        [5.1387]]), target_rating: tensor([8, 6, 6, 4])\n",
            "model_output: tensor([[6.7102],\n",
            "        [7.2832],\n",
            "        [7.8033],\n",
            "        [8.3404]]), target_rating: tensor([7, 8, 9, 9])\n",
            "model_output: tensor([[6.2195],\n",
            "        [7.1856],\n",
            "        [7.7547],\n",
            "        [8.7729]]), target_rating: tensor([5, 6, 6, 8])\n",
            "model_output: tensor([[6.9861],\n",
            "        [8.1583],\n",
            "        [8.2657],\n",
            "        [7.3562]]), target_rating: tensor([4, 8, 9, 7])\n",
            "model_output: tensor([[7.7031],\n",
            "        [9.1903],\n",
            "        [7.1791],\n",
            "        [7.8170]]), target_rating: tensor([7, 8, 9, 6])\n",
            "model_output: tensor([[8.4664],\n",
            "        [8.7306],\n",
            "        [4.4887],\n",
            "        [6.9752]]), target_rating: tensor([10,  9,  6,  9])\n",
            "model_output: tensor([[8.0405],\n",
            "        [7.5371],\n",
            "        [7.9577],\n",
            "        [6.5513]]), target_rating: tensor([7, 9, 8, 6])\n",
            "model_output: tensor([[8.7509],\n",
            "        [6.0074],\n",
            "        [7.6359],\n",
            "        [6.8019]]), target_rating: tensor([7, 7, 8, 8])\n",
            "model_output: tensor([[8.1339],\n",
            "        [6.4403],\n",
            "        [6.3612],\n",
            "        [8.8868]]), target_rating: tensor([9, 5, 8, 7])\n",
            "model_output: tensor([[7.6558],\n",
            "        [9.2892],\n",
            "        [5.5755],\n",
            "        [7.9621]]), target_rating: tensor([10,  9,  6,  6])\n",
            "model_output: tensor([[6.0281],\n",
            "        [7.2845],\n",
            "        [5.9173],\n",
            "        [8.1786]]), target_rating: tensor([6, 8, 6, 8])\n",
            "model_output: tensor([[7.8834],\n",
            "        [5.3774],\n",
            "        [6.5413],\n",
            "        [6.7246]]), target_rating: tensor([8, 5, 2, 6])\n",
            "model_output: tensor([[9.3083],\n",
            "        [8.3633],\n",
            "        [7.0679],\n",
            "        [6.9748]]), target_rating: tensor([ 9, 10,  7,  7])\n",
            "model_output: tensor([[7.8677],\n",
            "        [7.5752],\n",
            "        [5.2777],\n",
            "        [7.6552]]), target_rating: tensor([7, 7, 4, 7])\n",
            "model_output: tensor([[6.2468],\n",
            "        [7.3338],\n",
            "        [6.1759],\n",
            "        [9.1007]]), target_rating: tensor([6, 8, 8, 9])\n",
            "model_output: tensor([[7.3068],\n",
            "        [6.9527],\n",
            "        [7.7985],\n",
            "        [9.1342]]), target_rating: tensor([5, 9, 7, 9])\n",
            "model_output: tensor([[5.0160],\n",
            "        [7.9134],\n",
            "        [7.2872],\n",
            "        [6.4356]]), target_rating: tensor([4, 7, 7, 7])\n",
            "model_output: tensor([[7.2719],\n",
            "        [7.5939],\n",
            "        [6.8588],\n",
            "        [7.2790]]), target_rating: tensor([5, 5, 6, 6])\n",
            "model_output: tensor([[6.6241],\n",
            "        [6.5022],\n",
            "        [7.3122],\n",
            "        [7.1232]]), target_rating: tensor([7, 5, 8, 8])\n",
            "model_output: tensor([[8.3109],\n",
            "        [6.6050],\n",
            "        [7.0140],\n",
            "        [8.5197]]), target_rating: tensor([5, 7, 7, 8])\n",
            "model_output: tensor([[8.0281],\n",
            "        [6.6542],\n",
            "        [6.0492],\n",
            "        [8.3264]]), target_rating: tensor([8, 5, 7, 7])\n",
            "model_output: tensor([[7.3874],\n",
            "        [9.7361],\n",
            "        [7.2709],\n",
            "        [8.5361]]), target_rating: tensor([ 2,  7,  8, 10])\n",
            "model_output: tensor([[9.2462],\n",
            "        [7.8643],\n",
            "        [7.9932],\n",
            "        [8.0130]]), target_rating: tensor([10,  9,  8,  9])\n",
            "model_output: tensor([[8.3707],\n",
            "        [4.6712],\n",
            "        [7.5899],\n",
            "        [6.9419]]), target_rating: tensor([7, 2, 8, 8])\n",
            "model_output: tensor([[8.6750],\n",
            "        [5.3831],\n",
            "        [8.6895],\n",
            "        [5.9138]]), target_rating: tensor([9, 4, 9, 7])\n",
            "model_output: tensor([[7.8417],\n",
            "        [5.6107],\n",
            "        [7.1864],\n",
            "        [6.0425]]), target_rating: tensor([9, 5, 6, 8])\n",
            "model_output: tensor([[7.2240],\n",
            "        [6.9051],\n",
            "        [7.1187],\n",
            "        [7.1086]]), target_rating: tensor([1, 6, 6, 8])\n",
            "model_output: tensor([[5.1210],\n",
            "        [6.6129],\n",
            "        [8.4182],\n",
            "        [8.9124]]), target_rating: tensor([7, 4, 6, 9])\n",
            "model_output: tensor([[9.2631],\n",
            "        [6.5555],\n",
            "        [8.2442],\n",
            "        [6.9639]]), target_rating: tensor([6, 8, 7, 8])\n",
            "model_output: tensor([[7.6924],\n",
            "        [9.3227],\n",
            "        [8.5243],\n",
            "        [7.4738]]), target_rating: tensor([ 8, 10,  7,  7])\n",
            "model_output: tensor([[6.5066],\n",
            "        [7.2672],\n",
            "        [8.1081],\n",
            "        [6.9827]]), target_rating: tensor([3, 6, 7, 5])\n",
            "model_output: tensor([[7.4515],\n",
            "        [6.6507],\n",
            "        [6.0016],\n",
            "        [8.1950]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[5.7637],\n",
            "        [7.5694],\n",
            "        [8.6153],\n",
            "        [7.1555]]), target_rating: tensor([5, 6, 7, 8])\n",
            "model_output: tensor([[6.8848],\n",
            "        [5.3736],\n",
            "        [7.8321],\n",
            "        [6.5642]]), target_rating: tensor([3, 6, 5, 8])\n",
            "model_output: tensor([[5.9811],\n",
            "        [5.3393],\n",
            "        [7.5637],\n",
            "        [7.5392]]), target_rating: tensor([ 6,  6,  2, 10])\n",
            "model_output: tensor([[8.5669],\n",
            "        [9.4894],\n",
            "        [8.0523],\n",
            "        [6.6209]]), target_rating: tensor([9, 8, 8, 7])\n",
            "model_output: tensor([[9.5650],\n",
            "        [7.5693],\n",
            "        [8.6616],\n",
            "        [8.2521]]), target_rating: tensor([ 9,  8,  9, 10])\n",
            "model_output: tensor([[7.6301],\n",
            "        [8.4505],\n",
            "        [6.6843],\n",
            "        [8.5539]]), target_rating: tensor([ 9, 10,  6,  9])\n",
            "model_output: tensor([[7.7964],\n",
            "        [6.4715],\n",
            "        [7.3923],\n",
            "        [5.5230]]), target_rating: tensor([8, 5, 7, 6])\n",
            "model_output: tensor([[5.2850],\n",
            "        [8.7511],\n",
            "        [6.9505],\n",
            "        [5.9206]]), target_rating: tensor([2, 8, 9, 9])\n",
            "model_output: tensor([[6.9893],\n",
            "        [7.6380],\n",
            "        [6.3887],\n",
            "        [7.7938]]), target_rating: tensor([ 6,  8, 10,  4])\n",
            "model_output: tensor([[6.1813],\n",
            "        [6.8254],\n",
            "        [8.3897],\n",
            "        [7.8793]]), target_rating: tensor([7, 8, 7, 8])\n",
            "model_output: tensor([[8.8813],\n",
            "        [5.8168],\n",
            "        [8.3108],\n",
            "        [8.0668]]), target_rating: tensor([10,  6,  9,  9])\n",
            "model_output: tensor([[7.6158],\n",
            "        [6.7150],\n",
            "        [6.5685],\n",
            "        [8.4330]]), target_rating: tensor([10,  5,  5,  7])\n",
            "model_output: tensor([[6.4980],\n",
            "        [7.5458],\n",
            "        [4.8458],\n",
            "        [8.0179]]), target_rating: tensor([7, 7, 6, 6])\n",
            "model_output: tensor([[6.5534],\n",
            "        [6.6343],\n",
            "        [4.0323],\n",
            "        [7.9082]]), target_rating: tensor([5, 8, 6, 7])\n",
            "model_output: tensor([[6.8727],\n",
            "        [8.0331],\n",
            "        [7.8138],\n",
            "        [4.9221]]), target_rating: tensor([ 6, 10,  8,  5])\n",
            "model_output: tensor([[7.5368],\n",
            "        [6.3083],\n",
            "        [7.3415],\n",
            "        [4.9003]]), target_rating: tensor([ 7, 10,  6,  6])\n",
            "model_output: tensor([[8.6813],\n",
            "        [9.1499],\n",
            "        [5.3226],\n",
            "        [7.8987]]), target_rating: tensor([8, 8, 7, 8])\n",
            "model_output: tensor([[7.3250],\n",
            "        [8.4772],\n",
            "        [9.5464],\n",
            "        [6.4736]]), target_rating: tensor([8, 9, 9, 7])\n",
            "model_output: tensor([[6.8016],\n",
            "        [6.6651],\n",
            "        [8.4645],\n",
            "        [8.3804]]), target_rating: tensor([7, 8, 9, 7])\n",
            "model_output: tensor([[8.0988],\n",
            "        [8.4787],\n",
            "        [7.8809],\n",
            "        [8.6307]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[7.4850],\n",
            "        [7.2312],\n",
            "        [7.3522],\n",
            "        [7.3046]]), target_rating: tensor([6, 8, 7, 7])\n",
            "model_output: tensor([[7.0449],\n",
            "        [7.4240],\n",
            "        [7.0684],\n",
            "        [8.9546]]), target_rating: tensor([5, 7, 8, 9])\n",
            "model_output: tensor([[7.6663],\n",
            "        [6.9496],\n",
            "        [6.5915],\n",
            "        [7.7951]]), target_rating: tensor([8, 7, 8, 5])\n",
            "model_output: tensor([[7.5786],\n",
            "        [5.5375],\n",
            "        [6.9380],\n",
            "        [7.6938]]), target_rating: tensor([8, 5, 4, 8])\n",
            "model_output: tensor([[6.6340],\n",
            "        [7.7896],\n",
            "        [8.8681],\n",
            "        [7.6173]]), target_rating: tensor([ 6,  9, 10,  8])\n",
            "model_output: tensor([[4.7199],\n",
            "        [6.5241],\n",
            "        [6.4939],\n",
            "        [8.4247]]), target_rating: tensor([7, 8, 7, 9])\n",
            "model_output: tensor([[8.2425],\n",
            "        [8.3239],\n",
            "        [7.6056],\n",
            "        [5.9619]]), target_rating: tensor([7, 9, 9, 7])\n",
            "model_output: tensor([[6.9089],\n",
            "        [6.3667],\n",
            "        [6.7990],\n",
            "        [8.2115]]), target_rating: tensor([6, 5, 7, 7])\n",
            "model_output: tensor([[7.0028],\n",
            "        [8.2058],\n",
            "        [8.3212],\n",
            "        [6.9672]]), target_rating: tensor([10,  7, 10,  4])\n",
            "model_output: tensor([[7.0022],\n",
            "        [8.4786],\n",
            "        [8.0040],\n",
            "        [6.7290]]), target_rating: tensor([7, 6, 6, 7])\n",
            "model_output: tensor([[7.4530],\n",
            "        [8.3825],\n",
            "        [5.0921],\n",
            "        [8.0656]]), target_rating: tensor([7, 7, 5, 8])\n",
            "model_output: tensor([[8.6094],\n",
            "        [8.6027],\n",
            "        [6.8069],\n",
            "        [7.5856]]), target_rating: tensor([10,  9,  9,  6])\n",
            "model_output: tensor([[7.4048],\n",
            "        [5.9503],\n",
            "        [7.8345],\n",
            "        [6.9143]]), target_rating: tensor([7, 8, 8, 7])\n",
            "model_output: tensor([[8.7334],\n",
            "        [7.1791],\n",
            "        [7.0827],\n",
            "        [8.3342]]), target_rating: tensor([9, 6, 6, 8])\n",
            "model_output: tensor([[7.7801],\n",
            "        [7.1829],\n",
            "        [9.5422],\n",
            "        [7.4930]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[8.0849],\n",
            "        [7.4903],\n",
            "        [6.8852],\n",
            "        [4.6726]]), target_rating: tensor([9, 9, 5, 4])\n",
            "model_output: tensor([[8.8640],\n",
            "        [6.3520],\n",
            "        [7.8719],\n",
            "        [9.3817]]), target_rating: tensor([10,  6,  8,  6])\n",
            "model_output: tensor([[7.7294],\n",
            "        [8.5902],\n",
            "        [5.6751],\n",
            "        [8.0788]]), target_rating: tensor([10,  8,  3, 10])\n",
            "model_output: tensor([[7.6431],\n",
            "        [5.8843],\n",
            "        [9.1795],\n",
            "        [6.5022]]), target_rating: tensor([8, 6, 9, 4])\n",
            "model_output: tensor([[6.1328],\n",
            "        [6.5245],\n",
            "        [6.2673],\n",
            "        [7.5353]]), target_rating: tensor([ 7,  7, 10,  5])\n",
            "model_output: tensor([[9.3165],\n",
            "        [5.5878],\n",
            "        [8.4457],\n",
            "        [6.0949]]), target_rating: tensor([10,  5, 10,  5])\n",
            "model_output: tensor([[9.2431],\n",
            "        [8.5813],\n",
            "        [8.3513],\n",
            "        [8.0501]]), target_rating: tensor([8, 8, 9, 8])\n",
            "model_output: tensor([[6.0246],\n",
            "        [8.6789],\n",
            "        [6.8205],\n",
            "        [9.0905]]), target_rating: tensor([ 5,  8,  6, 10])\n",
            "model_output: tensor([[6.2339],\n",
            "        [6.7884],\n",
            "        [8.1747],\n",
            "        [7.9277]]), target_rating: tensor([9, 8, 7, 6])\n",
            "model_output: tensor([[6.9714],\n",
            "        [6.8386],\n",
            "        [8.1228],\n",
            "        [9.0682]]), target_rating: tensor([ 5,  7, 10,  9])\n",
            "model_output: tensor([[8.3656],\n",
            "        [8.5932],\n",
            "        [7.6684],\n",
            "        [7.5283]]), target_rating: tensor([ 8,  9,  3, 10])\n",
            "model_output: tensor([[7.5028],\n",
            "        [6.5753],\n",
            "        [5.1939],\n",
            "        [8.4372]]), target_rating: tensor([7, 7, 5, 9])\n",
            "model_output: tensor([[7.3632],\n",
            "        [8.8143],\n",
            "        [7.5040],\n",
            "        [8.5233]]), target_rating: tensor([ 4,  4,  8, 10])\n",
            "model_output: tensor([[6.2928],\n",
            "        [6.7834],\n",
            "        [7.8229],\n",
            "        [5.8080]]), target_rating: tensor([8, 7, 7, 9])\n",
            "model_output: tensor([[7.0783],\n",
            "        [9.1406],\n",
            "        [6.5072],\n",
            "        [6.5752]]), target_rating: tensor([6, 2, 5, 8])\n",
            "model_output: tensor([[6.1379],\n",
            "        [8.4264],\n",
            "        [7.7444],\n",
            "        [9.3185]]), target_rating: tensor([7, 7, 8, 9])\n",
            "model_output: tensor([[7.3870],\n",
            "        [8.0974],\n",
            "        [3.2065],\n",
            "        [6.3825]]), target_rating: tensor([7, 7, 3, 7])\n",
            "model_output: tensor([[6.5217],\n",
            "        [6.6346],\n",
            "        [6.4976],\n",
            "        [9.0467]]), target_rating: tensor([ 6,  7,  6, 10])\n",
            "model_output: tensor([[8.4526],\n",
            "        [6.6765],\n",
            "        [9.1742],\n",
            "        [6.2758]]), target_rating: tensor([8, 7, 9, 8])\n",
            "model_output: tensor([[8.1421],\n",
            "        [7.3756],\n",
            "        [5.5128],\n",
            "        [7.1838]]), target_rating: tensor([9, 7, 6, 5])\n",
            "model_output: tensor([[8.8470],\n",
            "        [6.7805],\n",
            "        [6.8633],\n",
            "        [7.8475]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[8.8791],\n",
            "        [7.6244],\n",
            "        [9.5565],\n",
            "        [6.7470]]), target_rating: tensor([10,  6,  7,  5])\n",
            "model_output: tensor([[6.4255],\n",
            "        [6.6388],\n",
            "        [7.9478],\n",
            "        [7.6153]]), target_rating: tensor([7, 7, 8, 9])\n",
            "model_output: tensor([[7.7302],\n",
            "        [6.0656],\n",
            "        [6.8502],\n",
            "        [8.2772]]), target_rating: tensor([6, 7, 8, 7])\n",
            "model_output: tensor([[6.9494],\n",
            "        [5.7732],\n",
            "        [6.9066],\n",
            "        [6.7980]]), target_rating: tensor([5, 6, 5, 8])\n",
            "model_output: tensor([[7.6391],\n",
            "        [5.8525],\n",
            "        [6.5782],\n",
            "        [6.7073]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[7.5449],\n",
            "        [4.0199],\n",
            "        [8.2221],\n",
            "        [8.7267]]), target_rating: tensor([5, 4, 9, 9])\n",
            "model_output: tensor([[9.1743],\n",
            "        [7.3307],\n",
            "        [4.3896],\n",
            "        [8.8383]]), target_rating: tensor([8, 5, 4, 9])\n",
            "model_output: tensor([[9.2156],\n",
            "        [8.7480],\n",
            "        [7.6718],\n",
            "        [9.7797]]), target_rating: tensor([ 7,  9,  8, 10])\n",
            "model_output: tensor([[5.6008],\n",
            "        [6.5476],\n",
            "        [7.3501],\n",
            "        [5.6132]]), target_rating: tensor([6, 6, 8, 5])\n",
            "model_output: tensor([[6.5219],\n",
            "        [7.8785],\n",
            "        [7.3481],\n",
            "        [6.9854]]), target_rating: tensor([9, 9, 6, 7])\n",
            "model_output: tensor([[7.2335],\n",
            "        [6.9500],\n",
            "        [5.1183],\n",
            "        [7.1947]]), target_rating: tensor([6, 8, 7, 5])\n",
            "model_output: tensor([[5.8781],\n",
            "        [6.3964],\n",
            "        [8.8913],\n",
            "        [5.0418]]), target_rating: tensor([7, 8, 6, 5])\n",
            "model_output: tensor([[8.6418],\n",
            "        [7.2640],\n",
            "        [7.7199],\n",
            "        [7.0177]]), target_rating: tensor([ 6,  7, 10,  7])\n",
            "model_output: tensor([[7.7850],\n",
            "        [6.5484],\n",
            "        [9.0561],\n",
            "        [6.9135]]), target_rating: tensor([7, 6, 6, 6])\n",
            "model_output: tensor([[7.5910],\n",
            "        [6.4415],\n",
            "        [7.5586],\n",
            "        [6.2942]]), target_rating: tensor([7, 7, 6, 6])\n",
            "model_output: tensor([[8.3499],\n",
            "        [7.6128],\n",
            "        [6.7734],\n",
            "        [8.4114]]), target_rating: tensor([10,  5,  8,  5])\n",
            "model_output: tensor([[6.8012],\n",
            "        [8.1233],\n",
            "        [8.7328],\n",
            "        [7.6409]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[8.3795],\n",
            "        [7.0970],\n",
            "        [6.5729],\n",
            "        [9.0170]]), target_rating: tensor([ 9,  8,  6, 10])\n",
            "model_output: tensor([[7.5143],\n",
            "        [9.7020],\n",
            "        [8.5845],\n",
            "        [9.1396]]), target_rating: tensor([7, 9, 9, 9])\n",
            "model_output: tensor([[6.2440],\n",
            "        [7.3713],\n",
            "        [7.2089],\n",
            "        [7.8703]]), target_rating: tensor([7, 6, 8, 9])\n",
            "model_output: tensor([[7.3771],\n",
            "        [6.7333],\n",
            "        [8.1381],\n",
            "        [7.1953]]), target_rating: tensor([10,  6,  9,  8])\n",
            "model_output: tensor([[7.5320],\n",
            "        [8.3660],\n",
            "        [6.9381],\n",
            "        [8.0648]]), target_rating: tensor([4, 7, 7, 9])\n",
            "model_output: tensor([[6.2948],\n",
            "        [6.6771],\n",
            "        [8.3667],\n",
            "        [4.7529]]), target_rating: tensor([ 7,  9, 10,  7])\n",
            "model_output: tensor([[6.2759],\n",
            "        [6.1374],\n",
            "        [7.4805],\n",
            "        [6.9684]]), target_rating: tensor([8, 5, 8, 5])\n",
            "model_output: tensor([[7.9627],\n",
            "        [5.5233],\n",
            "        [6.6686],\n",
            "        [6.6955]]), target_rating: tensor([7, 5, 7, 8])\n",
            "model_output: tensor([[5.8127],\n",
            "        [7.3982],\n",
            "        [6.0797],\n",
            "        [7.5888]]), target_rating: tensor([7, 6, 5, 9])\n",
            "model_output: tensor([[7.2123],\n",
            "        [6.7334],\n",
            "        [8.2162],\n",
            "        [5.0424]]), target_rating: tensor([9, 7, 6, 3])\n",
            "model_output: tensor([[5.5693],\n",
            "        [8.9631],\n",
            "        [7.3934],\n",
            "        [5.9668]]), target_rating: tensor([6, 8, 8, 1])\n",
            "model_output: tensor([[6.7075],\n",
            "        [5.6705],\n",
            "        [7.7370],\n",
            "        [6.8138]]), target_rating: tensor([8, 7, 8, 8])\n",
            "model_output: tensor([[6.7961],\n",
            "        [8.8500],\n",
            "        [7.8646],\n",
            "        [7.9641]]), target_rating: tensor([6, 7, 6, 7])\n",
            "model_output: tensor([[7.3859],\n",
            "        [9.1556],\n",
            "        [8.2335],\n",
            "        [7.5733]]), target_rating: tensor([7, 9, 9, 5])\n",
            "model_output: tensor([[8.0910],\n",
            "        [9.1525],\n",
            "        [8.3510],\n",
            "        [5.5765]]), target_rating: tensor([7, 9, 9, 4])\n",
            "model_output: tensor([[6.0598],\n",
            "        [7.2558],\n",
            "        [6.4455],\n",
            "        [7.2018]]), target_rating: tensor([ 7, 10,  8,  8])\n",
            "model_output: tensor([[5.4292],\n",
            "        [7.8435],\n",
            "        [8.3026],\n",
            "        [6.7852]]), target_rating: tensor([4, 7, 7, 8])\n",
            "model_output: tensor([[6.6673],\n",
            "        [9.0464],\n",
            "        [8.0297],\n",
            "        [7.9156]]), target_rating: tensor([ 7, 10,  6, 10])\n",
            "model_output: tensor([[5.6371],\n",
            "        [7.4876],\n",
            "        [8.0720],\n",
            "        [7.7670]]), target_rating: tensor([5, 6, 8, 7])\n",
            "model_output: tensor([[7.7265],\n",
            "        [9.0633],\n",
            "        [6.4894],\n",
            "        [8.8770]]), target_rating: tensor([7, 7, 3, 7])\n",
            "model_output: tensor([[7.3897],\n",
            "        [8.6549],\n",
            "        [8.8908],\n",
            "        [7.7694]]), target_rating: tensor([ 7, 10,  9,  7])\n",
            "model_output: tensor([[7.0378],\n",
            "        [8.2676],\n",
            "        [7.2145],\n",
            "        [8.6399]]), target_rating: tensor([5, 8, 8, 7])\n",
            "model_output: tensor([[8.9570],\n",
            "        [7.6072],\n",
            "        [4.7302],\n",
            "        [7.6008]]), target_rating: tensor([7, 8, 7, 4])\n",
            "model_output: tensor([[7.9092],\n",
            "        [7.6593],\n",
            "        [9.0393],\n",
            "        [7.0887]]), target_rating: tensor([8, 7, 7, 6])\n",
            "model_output: tensor([[6.0608],\n",
            "        [7.0292],\n",
            "        [8.5947],\n",
            "        [8.6442]]), target_rating: tensor([ 6,  5,  9, 10])\n",
            "model_output: tensor([[7.7971],\n",
            "        [7.0304],\n",
            "        [7.3611],\n",
            "        [8.5410]]), target_rating: tensor([9, 7, 9, 7])\n",
            "model_output: tensor([[7.8437],\n",
            "        [6.8938],\n",
            "        [8.1833],\n",
            "        [5.0971]]), target_rating: tensor([ 7,  7, 10,  5])\n",
            "model_output: tensor([[6.9914],\n",
            "        [9.6068],\n",
            "        [9.9137],\n",
            "        [7.0122]]), target_rating: tensor([ 8, 10,  9,  6])\n",
            "model_output: tensor([[7.2538],\n",
            "        [9.2828],\n",
            "        [8.7436],\n",
            "        [5.7276]]), target_rating: tensor([ 7,  7, 10,  5])\n",
            "model_output: tensor([[7.1836],\n",
            "        [6.8483],\n",
            "        [9.2424],\n",
            "        [7.5375]]), target_rating: tensor([7, 6, 6, 6])\n",
            "model_output: tensor([[9.7281],\n",
            "        [6.7059],\n",
            "        [7.9785],\n",
            "        [8.4052]]), target_rating: tensor([7, 8, 8, 6])\n",
            "model_output: tensor([[7.3228],\n",
            "        [6.7021],\n",
            "        [6.1652],\n",
            "        [8.9637]]), target_rating: tensor([7, 9, 5, 9])\n",
            "model_output: tensor([[7.6371],\n",
            "        [7.6336],\n",
            "        [9.3151],\n",
            "        [8.1179]]), target_rating: tensor([ 9,  9, 10,  9])\n",
            "model_output: tensor([[5.8472],\n",
            "        [7.1631],\n",
            "        [6.6278],\n",
            "        [8.2126]]), target_rating: tensor([5, 7, 5, 7])\n",
            "model_output: tensor([[6.7230],\n",
            "        [6.6017],\n",
            "        [5.6499],\n",
            "        [7.0624]]), target_rating: tensor([6, 8, 6, 8])\n",
            "model_output: tensor([[7.4734],\n",
            "        [6.6811],\n",
            "        [8.8639],\n",
            "        [5.8422]]), target_rating: tensor([6, 5, 8, 9])\n",
            "model_output: tensor([[ 7.2657],\n",
            "        [10.2091],\n",
            "        [ 6.6550],\n",
            "        [ 8.0325]]), target_rating: tensor([ 6, 10,  6,  7])\n",
            "model_output: tensor([[7.4296],\n",
            "        [6.8304],\n",
            "        [7.0545],\n",
            "        [9.6372]]), target_rating: tensor([5, 8, 8, 4])\n",
            "model_output: tensor([[7.6910],\n",
            "        [5.9256],\n",
            "        [5.4105],\n",
            "        [6.6016]]), target_rating: tensor([7, 3, 6, 6])\n",
            "model_output: tensor([[6.4631],\n",
            "        [6.4702],\n",
            "        [8.7798],\n",
            "        [6.0784]]), target_rating: tensor([ 8,  6, 10,  8])\n",
            "model_output: tensor([[6.4113],\n",
            "        [7.3020],\n",
            "        [6.4253],\n",
            "        [5.4570]]), target_rating: tensor([5, 4, 7, 6])\n",
            "model_output: tensor([[7.5896],\n",
            "        [6.6464],\n",
            "        [8.2185],\n",
            "        [7.5366]]), target_rating: tensor([8, 7, 6, 8])\n",
            "model_output: tensor([[6.5716],\n",
            "        [9.3439],\n",
            "        [7.8845],\n",
            "        [7.2796]]), target_rating: tensor([5, 8, 9, 7])\n",
            "model_output: tensor([[5.4660],\n",
            "        [7.2364],\n",
            "        [8.8178],\n",
            "        [5.0577]]), target_rating: tensor([6, 8, 9, 5])\n",
            "model_output: tensor([[9.4645],\n",
            "        [8.1698],\n",
            "        [6.7590],\n",
            "        [7.0018]]), target_rating: tensor([10,  9,  7,  8])\n",
            "model_output: tensor([[7.2029],\n",
            "        [6.3487],\n",
            "        [7.9022],\n",
            "        [6.5794]]), target_rating: tensor([8, 5, 6, 9])\n",
            "model_output: tensor([[8.0303],\n",
            "        [7.3062],\n",
            "        [8.2539],\n",
            "        [7.4115]]), target_rating: tensor([ 7,  9,  9, 10])\n",
            "model_output: tensor([[8.6828],\n",
            "        [7.2818],\n",
            "        [5.9750],\n",
            "        [6.9924]]), target_rating: tensor([9, 9, 7, 6])\n",
            "model_output: tensor([[6.9787],\n",
            "        [8.3462],\n",
            "        [6.6028],\n",
            "        [5.1942]]), target_rating: tensor([7, 9, 7, 7])\n",
            "model_output: tensor([[5.1443],\n",
            "        [6.5318],\n",
            "        [7.9191],\n",
            "        [8.2220]]), target_rating: tensor([6, 9, 8, 7])\n",
            "model_output: tensor([[6.1035],\n",
            "        [6.3877],\n",
            "        [6.8857],\n",
            "        [6.5832]]), target_rating: tensor([9, 8, 6, 7])\n",
            "model_output: tensor([[7.3646],\n",
            "        [7.6042],\n",
            "        [7.2357],\n",
            "        [7.1355]]), target_rating: tensor([9, 9, 8, 6])\n",
            "model_output: tensor([[6.9375],\n",
            "        [7.2390],\n",
            "        [7.4870],\n",
            "        [7.1601]]), target_rating: tensor([5, 8, 8, 8])\n",
            "model_output: tensor([[7.0163],\n",
            "        [5.6486],\n",
            "        [7.4492],\n",
            "        [7.5277]]), target_rating: tensor([6, 6, 7, 7])\n",
            "model_output: tensor([[9.0724],\n",
            "        [6.6858],\n",
            "        [7.9160],\n",
            "        [6.9649]]), target_rating: tensor([9, 8, 8, 9])\n",
            "model_output: tensor([[7.3914],\n",
            "        [7.9401],\n",
            "        [8.0505],\n",
            "        [6.0627]]), target_rating: tensor([9, 7, 8, 6])\n",
            "model_output: tensor([[8.6866],\n",
            "        [8.4862],\n",
            "        [6.4765],\n",
            "        [8.5462]]), target_rating: tensor([6, 9, 3, 8])\n",
            "model_output: tensor([[6.1860],\n",
            "        [7.1802],\n",
            "        [7.4062],\n",
            "        [5.4548]]), target_rating: tensor([8, 7, 6, 8])\n",
            "model_output: tensor([[8.6525],\n",
            "        [5.4369],\n",
            "        [5.5509],\n",
            "        [7.6750]]), target_rating: tensor([10,  6,  1, 10])\n",
            "model_output: tensor([[ 7.7079],\n",
            "        [10.2744],\n",
            "        [ 6.6971],\n",
            "        [ 8.6103]]), target_rating: tensor([ 9, 10,  7, 10])\n",
            "model_output: tensor([[5.6834],\n",
            "        [7.4671],\n",
            "        [6.1457],\n",
            "        [8.5957]]), target_rating: tensor([8, 5, 4, 8])\n",
            "model_output: tensor([[9.4978],\n",
            "        [7.5068],\n",
            "        [6.9024],\n",
            "        [7.8618]]), target_rating: tensor([ 8, 10,  7,  5])\n",
            "model_output: tensor([[7.2220],\n",
            "        [7.4232],\n",
            "        [8.0477],\n",
            "        [7.5044]]), target_rating: tensor([9, 7, 8, 8])\n",
            "model_output: tensor([[8.2143],\n",
            "        [7.7023],\n",
            "        [8.6111],\n",
            "        [9.2291]]), target_rating: tensor([10,  8,  9, 10])\n",
            "model_output: tensor([[6.2288],\n",
            "        [6.9405],\n",
            "        [8.0828],\n",
            "        [6.3110]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[6.1280],\n",
            "        [8.6659],\n",
            "        [6.0656],\n",
            "        [8.1705]]), target_rating: tensor([5, 8, 7, 8])\n",
            "model_output: tensor([[6.0809],\n",
            "        [7.1612],\n",
            "        [5.3104],\n",
            "        [9.4153]]), target_rating: tensor([ 7,  6,  8, 10])\n",
            "model_output: tensor([[8.7165],\n",
            "        [7.8695],\n",
            "        [8.4688],\n",
            "        [4.4686]]), target_rating: tensor([7, 8, 8, 5])\n",
            "model_output: tensor([[9.1565],\n",
            "        [6.2551],\n",
            "        [6.7370],\n",
            "        [8.3774]]), target_rating: tensor([ 7,  6,  7, 10])\n",
            "model_output: tensor([[7.5458],\n",
            "        [7.0485],\n",
            "        [9.3455],\n",
            "        [9.2741]]), target_rating: tensor([ 7,  8, 10,  4])\n",
            "model_output: tensor([[4.9643],\n",
            "        [9.4099],\n",
            "        [4.6156],\n",
            "        [7.7371]]), target_rating: tensor([5, 9, 2, 9])\n",
            "model_output: tensor([[7.4907],\n",
            "        [5.7468],\n",
            "        [5.8883],\n",
            "        [6.0105]]), target_rating: tensor([9, 4, 7, 5])\n",
            "model_output: tensor([[7.3247],\n",
            "        [9.0763],\n",
            "        [6.9398],\n",
            "        [8.3501]]), target_rating: tensor([ 8, 10,  7, 10])\n",
            "model_output: tensor([[7.2777],\n",
            "        [8.9421],\n",
            "        [9.0615],\n",
            "        [7.8872]]), target_rating: tensor([6, 8, 8, 8])\n",
            "model_output: tensor([[5.6186],\n",
            "        [7.5625],\n",
            "        [7.7932],\n",
            "        [6.9698]]), target_rating: tensor([ 4,  8, 10,  7])\n",
            "model_output: tensor([[7.9742],\n",
            "        [7.7219],\n",
            "        [9.4694],\n",
            "        [8.2569]]), target_rating: tensor([8, 8, 9, 9])\n",
            "model_output: tensor([[6.6250],\n",
            "        [7.6805],\n",
            "        [7.6217],\n",
            "        [7.5904]]), target_rating: tensor([ 9,  9, 10,  6])\n",
            "model_output: tensor([[7.7213],\n",
            "        [8.2376],\n",
            "        [9.0801],\n",
            "        [7.7019]]), target_rating: tensor([7, 8, 9, 8])\n",
            "model_output: tensor([[9.0094],\n",
            "        [6.3645],\n",
            "        [7.5444],\n",
            "        [6.3944]]), target_rating: tensor([10,  5,  7,  8])\n",
            "model_output: tensor([[7.0532],\n",
            "        [6.6276],\n",
            "        [6.5118],\n",
            "        [7.2868]]), target_rating: tensor([4, 9, 6, 5])\n",
            "model_output: tensor([[6.5241],\n",
            "        [7.9091],\n",
            "        [6.1230],\n",
            "        [7.0407]]), target_rating: tensor([6, 7, 8, 8])\n",
            "model_output: tensor([[7.4221],\n",
            "        [6.9202],\n",
            "        [7.5613],\n",
            "        [6.4918]]), target_rating: tensor([8, 8, 8, 5])\n",
            "model_output: tensor([[6.7396],\n",
            "        [6.6593],\n",
            "        [6.4013],\n",
            "        [6.9796]]), target_rating: tensor([8, 8, 6, 8])\n",
            "model_output: tensor([[5.9257],\n",
            "        [3.6902],\n",
            "        [7.0378],\n",
            "        [7.1773]]), target_rating: tensor([2, 6, 7, 8])\n",
            "model_output: tensor([[7.4398],\n",
            "        [5.3695],\n",
            "        [7.6448],\n",
            "        [7.0379]]), target_rating: tensor([7, 6, 6, 9])\n",
            "model_output: tensor([[6.1391],\n",
            "        [6.1702],\n",
            "        [6.7395],\n",
            "        [8.6202]]), target_rating: tensor([6, 5, 6, 5])\n",
            "model_output: tensor([[6.4069],\n",
            "        [9.4187],\n",
            "        [8.0533],\n",
            "        [8.8419]]), target_rating: tensor([ 7,  7, 10, 10])\n",
            "model_output: tensor([[7.4739],\n",
            "        [6.3623],\n",
            "        [7.7188],\n",
            "        [8.6208]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[5.7897],\n",
            "        [8.3806],\n",
            "        [5.8244],\n",
            "        [7.0547]]), target_rating: tensor([4, 7, 4, 9])\n",
            "model_output: tensor([[8.4129],\n",
            "        [7.4330],\n",
            "        [6.9748],\n",
            "        [5.9249]]), target_rating: tensor([5, 9, 6, 6])\n",
            "model_output: tensor([[5.4174],\n",
            "        [7.2307],\n",
            "        [6.3547],\n",
            "        [8.7919]]), target_rating: tensor([ 8,  7,  7, 10])\n",
            "model_output: tensor([[7.9910],\n",
            "        [7.3002],\n",
            "        [5.6120],\n",
            "        [7.1348]]), target_rating: tensor([9, 7, 6, 8])\n",
            "model_output: tensor([[6.8487],\n",
            "        [6.7816],\n",
            "        [8.2087],\n",
            "        [5.5703]]), target_rating: tensor([ 7,  6, 10,  7])\n",
            "model_output: tensor([[7.8507],\n",
            "        [6.8041],\n",
            "        [8.0084],\n",
            "        [8.9419]]), target_rating: tensor([7, 8, 5, 8])\n",
            "model_output: tensor([[7.9045],\n",
            "        [5.9836],\n",
            "        [7.4701],\n",
            "        [7.5260]]), target_rating: tensor([9, 4, 8, 5])\n",
            "model_output: tensor([[9.5834],\n",
            "        [8.2063],\n",
            "        [8.5301],\n",
            "        [4.8189]]), target_rating: tensor([9, 6, 7, 7])\n",
            "model_output: tensor([[8.6995],\n",
            "        [6.7083],\n",
            "        [6.9064],\n",
            "        [7.5373]]), target_rating: tensor([ 8,  8,  5, 10])\n",
            "model_output: tensor([[8.2492],\n",
            "        [7.0817],\n",
            "        [5.9967],\n",
            "        [6.5004]]), target_rating: tensor([6, 6, 4, 6])\n",
            "model_output: tensor([[5.7393],\n",
            "        [7.9968],\n",
            "        [8.3018],\n",
            "        [6.1196]]), target_rating: tensor([7, 9, 7, 4])\n",
            "model_output: tensor([[8.4526],\n",
            "        [5.8105],\n",
            "        [5.8127],\n",
            "        [6.6300]]), target_rating: tensor([ 8, 10,  7,  9])\n",
            "model_output: tensor([[7.4349],\n",
            "        [6.5913],\n",
            "        [7.8516],\n",
            "        [8.7349]]), target_rating: tensor([ 5,  8, 10, 10])\n",
            "model_output: tensor([[7.8015],\n",
            "        [6.4200],\n",
            "        [5.1662],\n",
            "        [7.5029]]), target_rating: tensor([9, 7, 6, 7])\n",
            "model_output: tensor([[8.6819],\n",
            "        [7.0543],\n",
            "        [8.0457],\n",
            "        [6.5675]]), target_rating: tensor([9, 8, 9, 8])\n",
            "model_output: tensor([[6.4692],\n",
            "        [7.5306],\n",
            "        [8.5331],\n",
            "        [6.0593]]), target_rating: tensor([7, 8, 8, 7])\n",
            "model_output: tensor([[7.4525],\n",
            "        [5.4716],\n",
            "        [8.6571],\n",
            "        [7.6891]]), target_rating: tensor([7, 3, 7, 8])\n",
            "model_output: tensor([[6.2012],\n",
            "        [8.3221],\n",
            "        [6.1014],\n",
            "        [6.6688]]), target_rating: tensor([4, 9, 6, 7])\n",
            "model_output: tensor([[6.9857],\n",
            "        [8.1749],\n",
            "        [7.1280],\n",
            "        [8.1752]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[6.5661],\n",
            "        [6.6033],\n",
            "        [6.9436],\n",
            "        [9.2003]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[7.4995],\n",
            "        [7.1998],\n",
            "        [5.1944],\n",
            "        [8.2004]]), target_rating: tensor([9, 7, 5, 9])\n",
            "model_output: tensor([[9.5270],\n",
            "        [8.2311],\n",
            "        [7.6399],\n",
            "        [8.2334]]), target_rating: tensor([ 7, 10,  7, 10])\n",
            "model_output: tensor([[7.8658],\n",
            "        [7.5662],\n",
            "        [7.0601],\n",
            "        [7.5676]]), target_rating: tensor([5, 7, 9, 6])\n",
            "model_output: tensor([[4.8428],\n",
            "        [8.2308],\n",
            "        [7.5476],\n",
            "        [8.9022]]), target_rating: tensor([6, 7, 8, 8])\n",
            "model_output: tensor([[8.1169],\n",
            "        [7.7265],\n",
            "        [7.9633],\n",
            "        [5.9486]]), target_rating: tensor([9, 9, 9, 5])\n",
            "model_output: tensor([[9.4842],\n",
            "        [6.9478],\n",
            "        [6.8037],\n",
            "        [6.6855]]), target_rating: tensor([10,  6,  6,  7])\n",
            "model_output: tensor([[8.6775],\n",
            "        [7.0341],\n",
            "        [7.9538],\n",
            "        [6.8592]]), target_rating: tensor([10,  7,  7,  7])\n",
            "model_output: tensor([[7.7870],\n",
            "        [7.0161],\n",
            "        [7.6297],\n",
            "        [7.1359]]), target_rating: tensor([ 5,  7,  2, 10])\n",
            "model_output: tensor([[8.1495],\n",
            "        [7.2413],\n",
            "        [7.8686],\n",
            "        [7.1159]]), target_rating: tensor([7, 6, 9, 7])\n",
            "model_output: tensor([[6.8542],\n",
            "        [6.6488],\n",
            "        [6.6314],\n",
            "        [7.1929]]), target_rating: tensor([7, 8, 5, 7])\n",
            "model_output: tensor([[7.3798],\n",
            "        [8.0750],\n",
            "        [7.9865],\n",
            "        [6.5491]]), target_rating: tensor([3, 8, 8, 6])\n",
            "model_output: tensor([[8.0453],\n",
            "        [6.9329],\n",
            "        [8.6425],\n",
            "        [5.1175]]), target_rating: tensor([4, 5, 9, 7])\n",
            "model_output: tensor([[9.2819],\n",
            "        [6.3783],\n",
            "        [8.3392],\n",
            "        [6.9191]]), target_rating: tensor([10,  6,  7,  8])\n",
            "model_output: tensor([[9.6410],\n",
            "        [6.0179],\n",
            "        [7.2950],\n",
            "        [4.8525]]), target_rating: tensor([9, 7, 9, 5])\n",
            "model_output: tensor([[7.5046],\n",
            "        [7.4374],\n",
            "        [6.7509],\n",
            "        [7.6321]]), target_rating: tensor([8, 9, 5, 8])\n",
            "model_output: tensor([[8.0493],\n",
            "        [7.8774],\n",
            "        [8.9146],\n",
            "        [7.2186]]), target_rating: tensor([9, 8, 7, 9])\n",
            "model_output: tensor([[7.4429],\n",
            "        [7.1356],\n",
            "        [6.9679],\n",
            "        [5.2751]]), target_rating: tensor([7, 6, 7, 5])\n",
            "model_output: tensor([[6.4483],\n",
            "        [7.3092],\n",
            "        [6.0811],\n",
            "        [6.8721]]), target_rating: tensor([9, 8, 7, 7])\n",
            "model_output: tensor([[5.8310],\n",
            "        [8.3977],\n",
            "        [7.4706],\n",
            "        [7.1732]]), target_rating: tensor([9, 8, 7, 7])\n",
            "model_output: tensor([[6.7309],\n",
            "        [6.9817],\n",
            "        [6.2054],\n",
            "        [8.1106]]), target_rating: tensor([7, 9, 7, 9])\n",
            "model_output: tensor([[6.5384],\n",
            "        [7.2449],\n",
            "        [6.3663],\n",
            "        [4.4133]]), target_rating: tensor([8, 6, 6, 3])\n",
            "model_output: tensor([[8.2617],\n",
            "        [5.9715],\n",
            "        [6.9455],\n",
            "        [8.3158]]), target_rating: tensor([ 9,  5,  8, 10])\n",
            "model_output: tensor([[7.7808],\n",
            "        [6.5148],\n",
            "        [7.4651],\n",
            "        [7.4936]]), target_rating: tensor([5, 8, 9, 6])\n",
            "model_output: tensor([[7.3245],\n",
            "        [7.8136],\n",
            "        [7.4805],\n",
            "        [5.1529]]), target_rating: tensor([6, 8, 1, 5])\n",
            "model_output: tensor([[7.8855],\n",
            "        [6.5058],\n",
            "        [8.9047],\n",
            "        [5.4937]]), target_rating: tensor([9, 4, 8, 4])\n",
            "model_output: tensor([[6.0753],\n",
            "        [6.7010],\n",
            "        [6.6931],\n",
            "        [7.8298]]), target_rating: tensor([7, 8, 4, 7])\n",
            "model_output: tensor([[8.2108],\n",
            "        [7.1494],\n",
            "        [6.6800],\n",
            "        [6.8239]]), target_rating: tensor([8, 8, 7, 6])\n",
            "model_output: tensor([[7.9844],\n",
            "        [8.0502],\n",
            "        [8.2024],\n",
            "        [6.7711]]), target_rating: tensor([6, 9, 8, 7])\n",
            "model_output: tensor([[7.3685],\n",
            "        [7.6297],\n",
            "        [8.2000],\n",
            "        [5.1876]]), target_rating: tensor([8, 9, 9, 5])\n",
            "model_output: tensor([[6.2973],\n",
            "        [6.4368],\n",
            "        [7.6389],\n",
            "        [7.0036]]), target_rating: tensor([8, 6, 8, 8])\n",
            "model_output: tensor([[6.1277],\n",
            "        [7.1477],\n",
            "        [7.4071],\n",
            "        [7.8669]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[6.8894],\n",
            "        [5.4958],\n",
            "        [5.7212],\n",
            "        [8.0401]]), target_rating: tensor([7, 6, 6, 8])\n",
            "model_output: tensor([[7.6295],\n",
            "        [7.1267],\n",
            "        [6.0593],\n",
            "        [6.8520]]), target_rating: tensor([8, 7, 6, 6])\n",
            "model_output: tensor([[7.6060],\n",
            "        [4.4686],\n",
            "        [5.3517],\n",
            "        [7.8280]]), target_rating: tensor([10,  5,  8,  8])\n",
            "model_output: tensor([[5.9284],\n",
            "        [5.8662],\n",
            "        [5.7944],\n",
            "        [8.5192]]), target_rating: tensor([7, 6, 7, 8])\n",
            "model_output: tensor([[7.3836],\n",
            "        [8.2774],\n",
            "        [6.7370],\n",
            "        [8.6071]]), target_rating: tensor([8, 8, 4, 8])\n",
            "model_output: tensor([[ 5.0395],\n",
            "        [ 8.3107],\n",
            "        [10.3253],\n",
            "        [ 7.9936]]), target_rating: tensor([7, 7, 9, 8])\n",
            "model_output: tensor([[8.5794],\n",
            "        [8.5998],\n",
            "        [6.0875],\n",
            "        [8.6252]]), target_rating: tensor([8, 8, 1, 6])\n",
            "model_output: tensor([[8.2024],\n",
            "        [8.2373],\n",
            "        [4.8472],\n",
            "        [7.5993]]), target_rating: tensor([10,  7,  6,  8])\n",
            "model_output: tensor([[6.1256],\n",
            "        [6.6494],\n",
            "        [9.2478],\n",
            "        [6.5070]]), target_rating: tensor([ 5,  7, 10,  6])\n",
            "model_output: tensor([[ 7.6029],\n",
            "        [ 8.4758],\n",
            "        [ 6.7719],\n",
            "        [10.3446]]), target_rating: tensor([9, 9, 8, 6])\n",
            "model_output: tensor([[7.6318],\n",
            "        [7.2850],\n",
            "        [7.3939],\n",
            "        [7.8876]]), target_rating: tensor([ 5, 10,  8,  7])\n",
            "model_output: tensor([[8.8368],\n",
            "        [5.9956],\n",
            "        [6.6982],\n",
            "        [7.1769]]), target_rating: tensor([8, 6, 6, 9])\n",
            "model_output: tensor([[6.0357],\n",
            "        [5.7418],\n",
            "        [9.2457],\n",
            "        [7.9012]]), target_rating: tensor([ 7,  5, 10,  8])\n",
            "model_output: tensor([[8.0970],\n",
            "        [7.9235],\n",
            "        [7.2602],\n",
            "        [7.8767]]), target_rating: tensor([ 8,  8,  8, 10])\n",
            "model_output: tensor([[8.0790],\n",
            "        [5.7099],\n",
            "        [5.5961],\n",
            "        [8.1514]]), target_rating: tensor([9, 5, 6, 5])\n",
            "model_output: tensor([[5.9212],\n",
            "        [7.2531],\n",
            "        [7.8260],\n",
            "        [6.8317]]), target_rating: tensor([ 7, 10,  8,  8])\n",
            "model_output: tensor([[6.7590],\n",
            "        [7.5378],\n",
            "        [7.3591],\n",
            "        [7.9564]]), target_rating: tensor([7, 7, 6, 8])\n",
            "model_output: tensor([[7.7401],\n",
            "        [9.0031],\n",
            "        [9.8316],\n",
            "        [6.2677]]), target_rating: tensor([ 8,  9, 10,  9])\n",
            "model_output: tensor([[6.0324],\n",
            "        [7.5216],\n",
            "        [9.0886],\n",
            "        [7.6601]]), target_rating: tensor([6, 6, 5, 8])\n",
            "model_output: tensor([[5.7411],\n",
            "        [8.3368],\n",
            "        [8.9029],\n",
            "        [7.5414]]), target_rating: tensor([7, 8, 9, 5])\n",
            "model_output: tensor([[6.9133],\n",
            "        [7.3013],\n",
            "        [8.9854],\n",
            "        [7.6787]]), target_rating: tensor([ 7,  9, 10,  7])\n",
            "model_output: tensor([[8.8348],\n",
            "        [8.4691],\n",
            "        [8.1282],\n",
            "        [8.7109]]), target_rating: tensor([10, 10,  8,  9])\n",
            "model_output: tensor([[7.3421],\n",
            "        [5.8827],\n",
            "        [6.9189],\n",
            "        [7.8172]]), target_rating: tensor([9, 2, 9, 8])\n",
            "model_output: tensor([[6.2686],\n",
            "        [6.7335],\n",
            "        [6.2541],\n",
            "        [5.9986]]), target_rating: tensor([5, 8, 7, 6])\n",
            "model_output: tensor([[9.4262],\n",
            "        [6.4390],\n",
            "        [6.3124],\n",
            "        [6.0479]]), target_rating: tensor([10,  7,  7,  7])\n",
            "model_output: tensor([[7.1402],\n",
            "        [8.2101],\n",
            "        [7.2383],\n",
            "        [6.9694]]), target_rating: tensor([7, 4, 8, 6])\n",
            "model_output: tensor([[6.8057],\n",
            "        [8.2758],\n",
            "        [7.3660],\n",
            "        [8.6254]]), target_rating: tensor([ 7,  8,  7, 10])\n",
            "model_output: tensor([[8.2951],\n",
            "        [7.4841],\n",
            "        [5.8617],\n",
            "        [7.5131]]), target_rating: tensor([ 6, 10,  7,  9])\n",
            "model_output: tensor([[ 6.6799],\n",
            "        [10.1234],\n",
            "        [ 8.6008],\n",
            "        [10.3235]]), target_rating: tensor([ 7, 10,  9,  9])\n",
            "model_output: tensor([[6.2704],\n",
            "        [8.4381],\n",
            "        [7.6445],\n",
            "        [6.8844]]), target_rating: tensor([ 6, 10,  7,  8])\n",
            "model_output: tensor([[8.9587],\n",
            "        [7.7748],\n",
            "        [8.1956],\n",
            "        [5.9152]]), target_rating: tensor([10, 10, 10,  7])\n",
            "model_output: tensor([[6.1846],\n",
            "        [6.7150],\n",
            "        [8.2169],\n",
            "        [7.6871]]), target_rating: tensor([ 6,  7,  7, 10])\n",
            "model_output: tensor([[9.4658],\n",
            "        [7.7808],\n",
            "        [7.7618],\n",
            "        [9.0128]]), target_rating: tensor([10,  6,  8, 10])\n",
            "model_output: tensor([[7.8958],\n",
            "        [7.2729],\n",
            "        [6.9528],\n",
            "        [7.9539]]), target_rating: tensor([ 8,  9,  8, 10])\n",
            "model_output: tensor([[7.6472],\n",
            "        [9.1556],\n",
            "        [7.7144],\n",
            "        [8.7560]]), target_rating: tensor([ 8, 10,  9, 10])\n",
            "model_output: tensor([[7.9786],\n",
            "        [7.2300],\n",
            "        [6.8162],\n",
            "        [8.2631]]), target_rating: tensor([10,  6,  7,  8])\n",
            "model_output: tensor([[7.6359],\n",
            "        [8.4270],\n",
            "        [7.8056],\n",
            "        [6.0683]]), target_rating: tensor([8, 8, 8, 5])\n",
            "model_output: tensor([[7.4517],\n",
            "        [6.8650],\n",
            "        [6.3042],\n",
            "        [5.9633]]), target_rating: tensor([7, 6, 6, 7])\n",
            "model_output: tensor([[6.0374],\n",
            "        [5.7390],\n",
            "        [8.0536],\n",
            "        [7.0210]]), target_rating: tensor([4, 8, 9, 7])\n",
            "model_output: tensor([[7.0553],\n",
            "        [5.7617],\n",
            "        [7.3316],\n",
            "        [6.6816]]), target_rating: tensor([6, 7, 6, 8])\n",
            "model_output: tensor([[6.2099],\n",
            "        [7.4500],\n",
            "        [5.8585],\n",
            "        [9.6043]]), target_rating: tensor([8, 7, 6, 9])\n",
            "model_output: tensor([[7.4075],\n",
            "        [6.2028],\n",
            "        [6.8063],\n",
            "        [9.8364]]), target_rating: tensor([ 7,  7,  6, 10])\n",
            "model_output: tensor([[5.6196],\n",
            "        [7.4915],\n",
            "        [8.4795],\n",
            "        [8.4131]]), target_rating: tensor([ 5,  8, 10,  7])\n",
            "model_output: tensor([[7.0332],\n",
            "        [7.0545],\n",
            "        [8.5163],\n",
            "        [8.2960]]), target_rating: tensor([ 7,  7,  9, 10])\n",
            "model_output: tensor([[7.2849],\n",
            "        [7.6700],\n",
            "        [8.0084],\n",
            "        [7.1345]]), target_rating: tensor([ 6,  9, 10,  6])\n",
            "model_output: tensor([[7.4454],\n",
            "        [5.2328],\n",
            "        [6.3378],\n",
            "        [9.7715]]), target_rating: tensor([6, 4, 8, 8])\n",
            "model_output: tensor([[6.0840],\n",
            "        [8.1551],\n",
            "        [7.8030],\n",
            "        [8.1680]]), target_rating: tensor([ 6,  7, 10,  8])\n",
            "model_output: tensor([[7.5955],\n",
            "        [9.0553],\n",
            "        [5.3696],\n",
            "        [7.4022]]), target_rating: tensor([9, 8, 6, 8])\n",
            "model_output: tensor([[5.7283],\n",
            "        [9.8257],\n",
            "        [6.1722],\n",
            "        [6.3549]]), target_rating: tensor([6, 9, 7, 8])\n",
            "model_output: tensor([[9.3589],\n",
            "        [8.2156],\n",
            "        [7.6278],\n",
            "        [8.3516]]), target_rating: tensor([10,  6,  8, 10])\n",
            "model_output: tensor([[7.9938],\n",
            "        [6.3758],\n",
            "        [7.5729],\n",
            "        [8.2162]]), target_rating: tensor([8, 9, 5, 7])\n",
            "model_output: tensor([[7.0085],\n",
            "        [7.6606],\n",
            "        [8.6075],\n",
            "        [5.6910]]), target_rating: tensor([ 7,  9, 10,  7])\n",
            "model_output: tensor([[7.3269],\n",
            "        [6.1603],\n",
            "        [7.6806],\n",
            "        [7.5407]]), target_rating: tensor([9, 6, 8, 8])\n",
            "model_output: tensor([[6.6298],\n",
            "        [8.5920],\n",
            "        [9.5242],\n",
            "        [8.4171]]), target_rating: tensor([5, 7, 3, 9])\n",
            "model_output: tensor([[6.6841],\n",
            "        [7.1065],\n",
            "        [7.7185],\n",
            "        [6.3302]]), target_rating: tensor([5, 8, 9, 6])\n",
            "model_output: tensor([[8.1464],\n",
            "        [8.1981],\n",
            "        [7.1536],\n",
            "        [6.6783]]), target_rating: tensor([8, 7, 8, 7])\n",
            "model_output: tensor([[9.3609],\n",
            "        [8.6048],\n",
            "        [7.9669],\n",
            "        [8.0835]]), target_rating: tensor([9, 9, 7, 6])\n",
            "model_output: tensor([[7.0223],\n",
            "        [5.3989],\n",
            "        [6.9698],\n",
            "        [8.0690]]), target_rating: tensor([8, 6, 4, 8])\n",
            "model_output: tensor([[5.7258],\n",
            "        [8.3829],\n",
            "        [7.9167],\n",
            "        [6.7069]]), target_rating: tensor([3, 9, 9, 7])\n",
            "model_output: tensor([[ 8.5503],\n",
            "        [ 7.4919],\n",
            "        [ 8.8256],\n",
            "        [10.2734]]), target_rating: tensor([ 7,  5,  8, 10])\n",
            "model_output: tensor([[6.1203],\n",
            "        [7.9459],\n",
            "        [6.5856],\n",
            "        [8.5903]]), target_rating: tensor([5, 7, 6, 7])\n",
            "model_output: tensor([[6.9646],\n",
            "        [6.8991],\n",
            "        [7.8473],\n",
            "        [7.2751]]), target_rating: tensor([7, 8, 9, 6])\n",
            "model_output: tensor([[6.3537],\n",
            "        [5.9012],\n",
            "        [5.8322],\n",
            "        [7.9292]]), target_rating: tensor([7, 1, 7, 9])\n",
            "model_output: tensor([[7.1426],\n",
            "        [6.8422],\n",
            "        [7.1357],\n",
            "        [9.0265]]), target_rating: tensor([6, 6, 7, 9])\n",
            "model_output: tensor([[5.0440],\n",
            "        [7.5484],\n",
            "        [9.0551],\n",
            "        [9.8049]]), target_rating: tensor([ 6,  6, 10,  9])\n",
            "model_output: tensor([[7.8427],\n",
            "        [7.4108],\n",
            "        [7.7805],\n",
            "        [7.1940]]), target_rating: tensor([7, 9, 8, 9])\n",
            "model_output: tensor([[7.7764],\n",
            "        [9.4170],\n",
            "        [7.3648],\n",
            "        [7.2030]]), target_rating: tensor([ 9, 10,  8,  4])\n",
            "model_output: tensor([[7.4578],\n",
            "        [9.4161],\n",
            "        [5.7524],\n",
            "        [6.8620]]), target_rating: tensor([ 5, 10,  7,  4])\n",
            "model_output: tensor([[6.7168],\n",
            "        [7.7157],\n",
            "        [5.7130],\n",
            "        [7.0834]]), target_rating: tensor([6, 6, 8, 6])\n",
            "model_output: tensor([[8.2772],\n",
            "        [7.6406],\n",
            "        [7.1537],\n",
            "        [7.0249]]), target_rating: tensor([9, 7, 6, 7])\n",
            "model_output: tensor([[6.2315],\n",
            "        [7.8933],\n",
            "        [7.4591],\n",
            "        [8.6877]]), target_rating: tensor([6, 7, 8, 6])\n",
            "model_output: tensor([[7.2806],\n",
            "        [9.1324],\n",
            "        [7.2333],\n",
            "        [8.1959]]), target_rating: tensor([8, 7, 8, 9])\n",
            "model_output: tensor([[7.2929],\n",
            "        [6.7613],\n",
            "        [6.8441],\n",
            "        [6.4020]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[7.4217],\n",
            "        [9.2939],\n",
            "        [8.5157],\n",
            "        [6.4539]]), target_rating: tensor([9, 9, 7, 9])\n",
            "model_output: tensor([[6.3676],\n",
            "        [4.9844],\n",
            "        [8.9069],\n",
            "        [6.1898]]), target_rating: tensor([ 5,  8, 10,  6])\n",
            "model_output: tensor([[9.9663],\n",
            "        [7.0635],\n",
            "        [7.7049],\n",
            "        [7.1719]]), target_rating: tensor([8, 9, 8, 8])\n",
            "model_output: tensor([[10.1231],\n",
            "        [ 8.7345],\n",
            "        [ 8.7000],\n",
            "        [ 5.6085]]), target_rating: tensor([ 9, 10,  9,  6])\n",
            "model_output: tensor([[8.9416],\n",
            "        [8.4450],\n",
            "        [7.9104],\n",
            "        [6.1101]]), target_rating: tensor([8, 6, 8, 5])\n",
            "model_output: tensor([[8.5187],\n",
            "        [7.2547],\n",
            "        [9.0619],\n",
            "        [7.8706]]), target_rating: tensor([9, 8, 9, 8])\n",
            "model_output: tensor([[6.9803],\n",
            "        [7.4762],\n",
            "        [7.7094],\n",
            "        [8.4273]]), target_rating: tensor([8, 7, 7, 8])\n",
            "model_output: tensor([[6.0089],\n",
            "        [8.2101],\n",
            "        [8.5224],\n",
            "        [7.4673]]), target_rating: tensor([6, 6, 8, 6])\n",
            "model_output: tensor([[ 6.3879],\n",
            "        [ 9.8565],\n",
            "        [ 8.7319],\n",
            "        [10.6519]]), target_rating: tensor([ 6,  8,  4, 10])\n",
            "model_output: tensor([[7.0001],\n",
            "        [7.3861],\n",
            "        [6.5064],\n",
            "        [7.2401]]), target_rating: tensor([8, 7, 4, 7])\n",
            "model_output: tensor([[7.3008],\n",
            "        [8.5761],\n",
            "        [7.0623],\n",
            "        [8.4205]]), target_rating: tensor([10,  8,  8,  8])\n",
            "model_output: tensor([[5.4350],\n",
            "        [7.0365],\n",
            "        [6.4336],\n",
            "        [8.7489]]), target_rating: tensor([ 5, 10,  6, 10])\n",
            "model_output: tensor([[8.3991],\n",
            "        [4.8234],\n",
            "        [6.9013],\n",
            "        [6.7021]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[9.3213],\n",
            "        [6.3802],\n",
            "        [6.7261],\n",
            "        [5.4981]]), target_rating: tensor([9, 5, 8, 8])\n",
            "model_output: tensor([[6.9452],\n",
            "        [7.4488],\n",
            "        [5.8127],\n",
            "        [7.4276]]), target_rating: tensor([7, 7, 6, 9])\n",
            "model_output: tensor([[7.0146],\n",
            "        [9.0959],\n",
            "        [7.1473],\n",
            "        [7.6631]]), target_rating: tensor([10, 10,  8,  7])\n",
            "model_output: tensor([[7.2219],\n",
            "        [6.6999],\n",
            "        [5.9381],\n",
            "        [8.4574]]), target_rating: tensor([9, 7, 6, 9])\n",
            "model_output: tensor([[7.1484],\n",
            "        [8.1165],\n",
            "        [8.4358],\n",
            "        [6.3186]]), target_rating: tensor([8, 9, 9, 7])\n",
            "model_output: tensor([[6.8097],\n",
            "        [5.7877],\n",
            "        [5.8609],\n",
            "        [5.6591]]), target_rating: tensor([6, 5, 6, 7])\n",
            "model_output: tensor([[6.7172],\n",
            "        [6.6144],\n",
            "        [9.8833],\n",
            "        [7.6013]]), target_rating: tensor([ 8, 10, 10,  7])\n",
            "model_output: tensor([[6.2020],\n",
            "        [7.0820],\n",
            "        [6.9309],\n",
            "        [9.1773]]), target_rating: tensor([9, 8, 5, 8])\n",
            "model_output: tensor([[7.2326],\n",
            "        [7.4053],\n",
            "        [7.9719],\n",
            "        [7.6027]]), target_rating: tensor([9, 9, 9, 7])\n",
            "model_output: tensor([[7.8570],\n",
            "        [7.8352],\n",
            "        [9.5177],\n",
            "        [5.6393]]), target_rating: tensor([8, 7, 6, 5])\n",
            "model_output: tensor([[6.1704],\n",
            "        [7.5806],\n",
            "        [8.4492],\n",
            "        [7.1669]]), target_rating: tensor([4, 6, 9, 7])\n",
            "model_output: tensor([[ 8.2814],\n",
            "        [ 8.1210],\n",
            "        [ 5.3114],\n",
            "        [10.0805]]), target_rating: tensor([8, 7, 6, 8])\n",
            "model_output: tensor([[6.4570],\n",
            "        [4.9888],\n",
            "        [7.5594],\n",
            "        [6.0272]]), target_rating: tensor([6, 5, 9, 4])\n",
            "model_output: tensor([[ 5.8648],\n",
            "        [ 5.7019],\n",
            "        [10.0656],\n",
            "        [ 8.7126]]), target_rating: tensor([ 6,  8, 10,  8])\n",
            "model_output: tensor([[7.0707],\n",
            "        [5.7304],\n",
            "        [9.2496],\n",
            "        [6.1624]]), target_rating: tensor([9, 7, 9, 5])\n",
            "model_output: tensor([[8.4277],\n",
            "        [6.9815],\n",
            "        [5.5991],\n",
            "        [8.4935]]), target_rating: tensor([ 8, 10,  8,  8])\n",
            "model_output: tensor([[7.2331],\n",
            "        [7.3685],\n",
            "        [8.0280],\n",
            "        [6.8428]]), target_rating: tensor([ 7, 10,  7,  7])\n",
            "model_output: tensor([[6.5334],\n",
            "        [5.8618],\n",
            "        [7.6697],\n",
            "        [8.0641]]), target_rating: tensor([7, 5, 6, 7])\n",
            "model_output: tensor([[5.8917],\n",
            "        [9.0809],\n",
            "        [8.9038],\n",
            "        [7.9186]]), target_rating: tensor([7, 9, 9, 8])\n",
            "model_output: tensor([[6.4774],\n",
            "        [7.9915],\n",
            "        [6.2379],\n",
            "        [6.7158]]), target_rating: tensor([5, 7, 7, 7])\n",
            "model_output: tensor([[7.2858],\n",
            "        [9.4773],\n",
            "        [6.3981],\n",
            "        [7.6355]]), target_rating: tensor([7, 9, 7, 7])\n",
            "model_output: tensor([[4.5572],\n",
            "        [8.6653],\n",
            "        [7.9048],\n",
            "        [5.7243]]), target_rating: tensor([3, 9, 8, 7])\n",
            "model_output: tensor([[6.0163],\n",
            "        [5.4639],\n",
            "        [6.8778],\n",
            "        [6.5656]]), target_rating: tensor([6, 8, 6, 7])\n",
            "model_output: tensor([[6.3557],\n",
            "        [8.0531],\n",
            "        [8.9591],\n",
            "        [6.9827]]), target_rating: tensor([10,  7,  7,  4])\n",
            "model_output: tensor([[8.7651],\n",
            "        [7.3144],\n",
            "        [7.9460],\n",
            "        [7.1505]]), target_rating: tensor([9, 7, 7, 6])\n",
            "model_output: tensor([[8.3832],\n",
            "        [6.9606],\n",
            "        [7.9480],\n",
            "        [5.9679]]), target_rating: tensor([9, 7, 5, 4])\n",
            "model_output: tensor([[5.7754],\n",
            "        [6.7365],\n",
            "        [7.0321],\n",
            "        [7.7142]]), target_rating: tensor([ 8,  8,  7, 10])\n",
            "model_output: tensor([[6.8762],\n",
            "        [6.9092],\n",
            "        [7.5977],\n",
            "        [5.5007]]), target_rating: tensor([8, 8, 4, 5])\n",
            "model_output: tensor([[8.2101],\n",
            "        [6.2213],\n",
            "        [6.2635],\n",
            "        [6.3441]]), target_rating: tensor([8, 7, 7, 6])\n",
            "model_output: tensor([[7.5947],\n",
            "        [6.6188],\n",
            "        [9.0576],\n",
            "        [6.7728]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[6.3742],\n",
            "        [6.4157],\n",
            "        [8.5154],\n",
            "        [8.1264]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[9.9703],\n",
            "        [7.7219],\n",
            "        [6.5453],\n",
            "        [5.7057]]), target_rating: tensor([6, 8, 7, 6])\n",
            "model_output: tensor([[8.9859],\n",
            "        [6.0255],\n",
            "        [7.1821],\n",
            "        [9.2497]]), target_rating: tensor([ 9,  7,  7, 10])\n",
            "model_output: tensor([[7.5625],\n",
            "        [6.9248],\n",
            "        [8.3797],\n",
            "        [6.4544]]), target_rating: tensor([ 7,  8, 10,  6])\n",
            "model_output: tensor([[8.5043],\n",
            "        [8.0740],\n",
            "        [7.9341],\n",
            "        [6.2838]]), target_rating: tensor([ 9,  2, 10,  6])\n",
            "model_output: tensor([[7.9750],\n",
            "        [8.1549],\n",
            "        [7.9330],\n",
            "        [7.2302]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[6.9452],\n",
            "        [5.9622],\n",
            "        [6.4949],\n",
            "        [4.8210]]), target_rating: tensor([7, 5, 5, 5])\n",
            "model_output: tensor([[5.1890],\n",
            "        [9.2453],\n",
            "        [7.1887],\n",
            "        [6.4558]]), target_rating: tensor([6, 9, 7, 8])\n",
            "model_output: tensor([[ 7.4312],\n",
            "        [ 6.4901],\n",
            "        [ 7.9685],\n",
            "        [10.4348]]), target_rating: tensor([ 9,  8,  8, 10])\n",
            "model_output: tensor([[7.7071],\n",
            "        [8.0516],\n",
            "        [7.4949],\n",
            "        [6.0862]]), target_rating: tensor([10,  8,  5,  6])\n",
            "model_output: tensor([[ 6.5728],\n",
            "        [10.0611],\n",
            "        [ 6.1780],\n",
            "        [ 6.6321]]), target_rating: tensor([9, 9, 4, 9])\n",
            "model_output: tensor([[5.8962],\n",
            "        [6.1998],\n",
            "        [7.0710],\n",
            "        [6.4689]]), target_rating: tensor([6, 6, 8, 5])\n",
            "model_output: tensor([[8.7465],\n",
            "        [5.1807],\n",
            "        [7.9867],\n",
            "        [6.2050]]), target_rating: tensor([7, 6, 8, 8])\n",
            "model_output: tensor([[8.0842],\n",
            "        [7.7036],\n",
            "        [8.9188],\n",
            "        [7.9019]]), target_rating: tensor([9, 6, 8, 8])\n",
            "model_output: tensor([[7.8961],\n",
            "        [9.1681],\n",
            "        [8.0406],\n",
            "        [7.6247]]), target_rating: tensor([10,  7,  6,  8])\n",
            "model_output: tensor([[7.4984],\n",
            "        [7.1225],\n",
            "        [6.6494],\n",
            "        [5.2044]]), target_rating: tensor([8, 8, 8, 4])\n",
            "model_output: tensor([[6.6267],\n",
            "        [8.5656],\n",
            "        [8.2941],\n",
            "        [7.9108]]), target_rating: tensor([7, 8, 9, 5])\n",
            "model_output: tensor([[9.5560],\n",
            "        [4.7395],\n",
            "        [8.9436],\n",
            "        [6.3473]]), target_rating: tensor([ 9,  6, 10,  7])\n",
            "model_output: tensor([[6.6386],\n",
            "        [8.6645],\n",
            "        [6.8322],\n",
            "        [7.2858]]), target_rating: tensor([ 7,  8, 10,  8])\n",
            "model_output: tensor([[7.6999],\n",
            "        [6.1113],\n",
            "        [6.3171],\n",
            "        [7.4709]]), target_rating: tensor([9, 7, 5, 7])\n",
            "model_output: tensor([[8.7662],\n",
            "        [7.1823],\n",
            "        [6.6504],\n",
            "        [8.4343]]), target_rating: tensor([ 9,  9,  7, 10])\n",
            "model_output: tensor([[6.5514],\n",
            "        [7.7727],\n",
            "        [6.0163],\n",
            "        [7.5608]]), target_rating: tensor([ 9, 10,  7,  5])\n",
            "model_output: tensor([[6.5997],\n",
            "        [7.7214],\n",
            "        [7.1335],\n",
            "        [7.6096]]), target_rating: tensor([6, 8, 8, 8])\n",
            "model_output: tensor([[7.4027],\n",
            "        [6.2899],\n",
            "        [7.3026],\n",
            "        [6.6129]]), target_rating: tensor([8, 5, 6, 7])\n",
            "model_output: tensor([[5.0606],\n",
            "        [8.0207],\n",
            "        [7.9456],\n",
            "        [7.2772]]), target_rating: tensor([7, 9, 7, 8])\n",
            "model_output: tensor([[8.0197],\n",
            "        [5.3214],\n",
            "        [8.3167],\n",
            "        [7.9313]]), target_rating: tensor([7, 6, 7, 7])\n",
            "model_output: tensor([[8.2942],\n",
            "        [7.0349],\n",
            "        [7.6762],\n",
            "        [6.8558]]), target_rating: tensor([9, 8, 7, 8])\n",
            "model_output: tensor([[8.2822],\n",
            "        [6.3299],\n",
            "        [9.2224],\n",
            "        [6.3941]]), target_rating: tensor([7, 8, 9, 6])\n",
            "model_output: tensor([[ 9.0955],\n",
            "        [ 8.2872],\n",
            "        [ 7.1806],\n",
            "        [10.1836]]), target_rating: tensor([ 9,  9,  7, 10])\n",
            "model_output: tensor([[6.1504],\n",
            "        [6.9847],\n",
            "        [8.3938],\n",
            "        [5.6456]]), target_rating: tensor([9, 7, 9, 5])\n",
            "model_output: tensor([[5.8873],\n",
            "        [7.9313],\n",
            "        [7.2164],\n",
            "        [8.2109]]), target_rating: tensor([7, 9, 6, 6])\n",
            "model_output: tensor([[8.4077],\n",
            "        [6.3044],\n",
            "        [5.8733],\n",
            "        [6.0020]]), target_rating: tensor([10,  7,  7,  8])\n",
            "model_output: tensor([[7.2128],\n",
            "        [7.9672],\n",
            "        [5.8031],\n",
            "        [6.8127]]), target_rating: tensor([6, 7, 7, 8])\n",
            "model_output: tensor([[7.8584],\n",
            "        [8.0451],\n",
            "        [7.7424],\n",
            "        [6.4062]]), target_rating: tensor([ 6, 10,  8,  8])\n",
            "model_output: tensor([[7.5634],\n",
            "        [7.5656],\n",
            "        [5.1488],\n",
            "        [8.3129]]), target_rating: tensor([ 6, 10,  8,  7])\n",
            "model_output: tensor([[7.6868],\n",
            "        [7.1200],\n",
            "        [7.1845],\n",
            "        [7.3809]]), target_rating: tensor([ 6,  7,  9, 10])\n",
            "model_output: tensor([[7.6421],\n",
            "        [7.7873],\n",
            "        [5.4811],\n",
            "        [8.7027]]), target_rating: tensor([9, 9, 8, 7])\n",
            "model_output: tensor([[ 7.3908],\n",
            "        [ 7.0314],\n",
            "        [10.5542],\n",
            "        [ 7.7189]]), target_rating: tensor([6, 8, 9, 8])\n",
            "model_output: tensor([[8.6038],\n",
            "        [9.0764],\n",
            "        [9.8392],\n",
            "        [8.4084]]), target_rating: tensor([10, 10, 10,  9])\n",
            "model_output: tensor([[8.2965],\n",
            "        [8.4022],\n",
            "        [7.4299],\n",
            "        [6.3716]]), target_rating: tensor([9, 8, 7, 8])\n",
            "model_output: tensor([[6.7745],\n",
            "        [7.3358],\n",
            "        [7.2244],\n",
            "        [7.9607]]), target_rating: tensor([7, 9, 7, 7])\n",
            "model_output: tensor([[9.5306],\n",
            "        [6.7628],\n",
            "        [6.8821],\n",
            "        [6.8451]]), target_rating: tensor([7, 4, 7, 9])\n",
            "model_output: tensor([[6.8738],\n",
            "        [5.6138],\n",
            "        [8.5090],\n",
            "        [8.7516]]), target_rating: tensor([8, 6, 9, 9])\n",
            "model_output: tensor([[8.4452],\n",
            "        [6.8733],\n",
            "        [8.9184],\n",
            "        [8.1506]]), target_rating: tensor([ 8, 10, 10,  7])\n",
            "model_output: tensor([[4.9261],\n",
            "        [8.1327],\n",
            "        [5.5768],\n",
            "        [8.4205]]), target_rating: tensor([4, 8, 6, 7])\n",
            "model_output: tensor([[6.2570],\n",
            "        [6.7033],\n",
            "        [7.6093],\n",
            "        [6.3189]]), target_rating: tensor([7, 8, 8, 6])\n",
            "model_output: tensor([[6.9945],\n",
            "        [5.2946],\n",
            "        [5.7137],\n",
            "        [8.5201]]), target_rating: tensor([8, 6, 6, 8])\n",
            "model_output: tensor([[7.4254],\n",
            "        [8.6432],\n",
            "        [8.4182],\n",
            "        [7.7453]]), target_rating: tensor([ 9, 10, 10,  9])\n",
            "model_output: tensor([[5.8198],\n",
            "        [7.7236],\n",
            "        [8.1903],\n",
            "        [6.4016]]), target_rating: tensor([6, 7, 6, 7])\n",
            "model_output: tensor([[6.0530],\n",
            "        [9.6683],\n",
            "        [7.2320],\n",
            "        [6.1182]]), target_rating: tensor([8, 8, 8, 8])\n",
            "model_output: tensor([[7.7699],\n",
            "        [5.6805],\n",
            "        [7.4618],\n",
            "        [7.2752]]), target_rating: tensor([6, 5, 9, 9])\n",
            "model_output: tensor([[4.9771],\n",
            "        [6.2276],\n",
            "        [7.7667],\n",
            "        [6.9091]]), target_rating: tensor([5, 6, 7, 8])\n",
            "model_output: tensor([[7.4190],\n",
            "        [5.9777],\n",
            "        [6.0125],\n",
            "        [5.6395]]), target_rating: tensor([7, 6, 7, 5])\n",
            "model_output: tensor([[5.9258],\n",
            "        [7.2432],\n",
            "        [8.6265],\n",
            "        [8.2814]]), target_rating: tensor([6, 6, 8, 9])\n",
            "model_output: tensor([[7.2849],\n",
            "        [6.8025],\n",
            "        [8.0166],\n",
            "        [7.3175]]), target_rating: tensor([7, 7, 9, 6])\n",
            "model_output: tensor([[6.6456],\n",
            "        [8.5590],\n",
            "        [8.7615],\n",
            "        [7.7630]]), target_rating: tensor([8, 7, 8, 8])\n",
            "model_output: tensor([[6.9403],\n",
            "        [6.7196],\n",
            "        [8.6830],\n",
            "        [7.9629]]), target_rating: tensor([8, 7, 8, 7])\n",
            "model_output: tensor([[7.5029],\n",
            "        [8.3627],\n",
            "        [7.3143],\n",
            "        [5.8267]]), target_rating: tensor([ 9, 10,  7,  7])\n",
            "model_output: tensor([[6.4655],\n",
            "        [7.3772],\n",
            "        [7.5654],\n",
            "        [5.4536]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[6.6709],\n",
            "        [5.9518],\n",
            "        [7.3606],\n",
            "        [8.2278]]), target_rating: tensor([ 6,  4,  7, 10])\n",
            "model_output: tensor([[5.8244],\n",
            "        [5.8187],\n",
            "        [7.4366],\n",
            "        [5.9224]]), target_rating: tensor([4, 6, 7, 7])\n",
            "model_output: tensor([[8.0738],\n",
            "        [8.5093],\n",
            "        [6.6521],\n",
            "        [8.0008]]), target_rating: tensor([8, 6, 7, 8])\n",
            "model_output: tensor([[8.6649],\n",
            "        [6.7583],\n",
            "        [6.2469],\n",
            "        [5.9361]]), target_rating: tensor([9, 6, 7, 7])\n",
            "model_output: tensor([[7.2405],\n",
            "        [6.5404],\n",
            "        [6.4719],\n",
            "        [7.4848]]), target_rating: tensor([7, 7, 7, 7])\n",
            "model_output: tensor([[6.5073],\n",
            "        [6.3860],\n",
            "        [7.6319],\n",
            "        [9.4472]]), target_rating: tensor([10,  6,  8,  8])\n",
            "model_output: tensor([[8.1926],\n",
            "        [8.0323],\n",
            "        [5.9025],\n",
            "        [6.4094]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[5.4596],\n",
            "        [7.8663],\n",
            "        [6.9799],\n",
            "        [6.8121]]), target_rating: tensor([ 9, 10,  8,  8])\n",
            "model_output: tensor([[5.8792],\n",
            "        [5.8005],\n",
            "        [6.6193],\n",
            "        [8.3966]]), target_rating: tensor([4, 6, 8, 7])\n",
            "model_output: tensor([[8.7964],\n",
            "        [7.1331],\n",
            "        [7.6471],\n",
            "        [6.7181]]), target_rating: tensor([ 8,  6, 10,  3])\n",
            "model_output: tensor([[6.9538],\n",
            "        [7.4057],\n",
            "        [9.4956],\n",
            "        [5.2907]]), target_rating: tensor([7, 7, 8, 4])\n",
            "model_output: tensor([[6.0106],\n",
            "        [7.3144],\n",
            "        [7.5897],\n",
            "        [7.7295]]), target_rating: tensor([ 5, 10,  7,  8])\n",
            "model_output: tensor([[9.1205],\n",
            "        [7.0811],\n",
            "        [6.1304],\n",
            "        [7.8986]]), target_rating: tensor([8, 8, 5, 6])\n",
            "model_output: tensor([[5.6706],\n",
            "        [7.8718],\n",
            "        [7.7683],\n",
            "        [7.0028]]), target_rating: tensor([ 7,  9,  4, 10])\n",
            "model_output: tensor([[6.6864],\n",
            "        [9.4190],\n",
            "        [7.1365],\n",
            "        [8.4398]]), target_rating: tensor([8, 9, 9, 8])\n",
            "model_output: tensor([[7.6121],\n",
            "        [7.0752],\n",
            "        [7.7046],\n",
            "        [8.7104]]), target_rating: tensor([7, 8, 7, 9])\n",
            "model_output: tensor([[6.8070],\n",
            "        [6.3453],\n",
            "        [6.9874],\n",
            "        [9.2544]]), target_rating: tensor([6, 6, 8, 7])\n",
            "model_output: tensor([[7.0852],\n",
            "        [8.5711],\n",
            "        [7.3204],\n",
            "        [8.8328]]), target_rating: tensor([ 6,  8,  7, 10])\n",
            "model_output: tensor([[10.4478],\n",
            "        [ 8.2736],\n",
            "        [ 9.1588],\n",
            "        [ 7.0640]]), target_rating: tensor([8, 9, 8, 5])\n",
            "model_output: tensor([[7.6862],\n",
            "        [7.4891],\n",
            "        [7.9422],\n",
            "        [7.8216]]), target_rating: tensor([8, 7, 5, 7])\n",
            "model_output: tensor([[5.9216],\n",
            "        [6.9143],\n",
            "        [7.8740],\n",
            "        [5.8629]]), target_rating: tensor([7, 6, 8, 5])\n",
            "model_output: tensor([[ 7.1849],\n",
            "        [ 7.9347],\n",
            "        [10.7087],\n",
            "        [ 8.1660]]), target_rating: tensor([7, 7, 9, 8])\n",
            "model_output: tensor([[7.2927],\n",
            "        [8.4008],\n",
            "        [6.6384],\n",
            "        [9.9166]]), target_rating: tensor([ 8,  6,  8, 10])\n",
            "model_output: tensor([[7.2442],\n",
            "        [8.3413],\n",
            "        [7.0736],\n",
            "        [9.1992]]), target_rating: tensor([10, 10,  7, 10])\n",
            "model_output: tensor([[8.0742],\n",
            "        [6.8032],\n",
            "        [8.3311],\n",
            "        [8.6660]]), target_rating: tensor([7, 7, 6, 6])\n",
            "model_output: tensor([[7.9270],\n",
            "        [6.5535],\n",
            "        [4.6208],\n",
            "        [8.6093]]), target_rating: tensor([ 7,  6,  7, 10])\n",
            "model_output: tensor([[8.7175],\n",
            "        [7.8909],\n",
            "        [7.2496],\n",
            "        [6.8185]]), target_rating: tensor([7, 9, 7, 7])\n",
            "model_output: tensor([[8.9549],\n",
            "        [7.1062],\n",
            "        [7.5402],\n",
            "        [8.5474]]), target_rating: tensor([9, 7, 8, 8])\n",
            "model_output: tensor([[6.6834],\n",
            "        [7.4431],\n",
            "        [7.5046],\n",
            "        [9.8863]]), target_rating: tensor([6, 7, 7, 9])\n",
            "model_output: tensor([[7.1529],\n",
            "        [7.1462],\n",
            "        [6.3504],\n",
            "        [5.7023]]), target_rating: tensor([8, 8, 8, 6])\n",
            "model_output: tensor([[ 6.5350],\n",
            "        [ 7.9088],\n",
            "        [ 7.6999],\n",
            "        [10.1486]]), target_rating: tensor([ 7,  9,  7, 10])\n",
            "model_output: tensor([[7.5570],\n",
            "        [6.5828],\n",
            "        [5.5882],\n",
            "        [7.4237]]), target_rating: tensor([ 9, 10,  6,  8])\n",
            "model_output: tensor([[6.8791],\n",
            "        [5.9883],\n",
            "        [8.4962],\n",
            "        [8.5055]]), target_rating: tensor([1, 7, 9, 7])\n",
            "model_output: tensor([[5.2361],\n",
            "        [6.0081],\n",
            "        [8.1855],\n",
            "        [7.2954]]), target_rating: tensor([ 6,  7, 10,  8])\n",
            "model_output: tensor([[5.9336],\n",
            "        [5.8061],\n",
            "        [7.7538],\n",
            "        [7.0851]]), target_rating: tensor([6, 6, 6, 2])\n",
            "model_output: tensor([[8.0920],\n",
            "        [6.1043],\n",
            "        [5.9765],\n",
            "        [7.3357]]), target_rating: tensor([8, 5, 7, 7])\n",
            "model_output: tensor([[5.0657],\n",
            "        [9.1784],\n",
            "        [5.4239],\n",
            "        [8.7652]]), target_rating: tensor([ 5, 10,  7, 10])\n",
            "model_output: tensor([[6.5178],\n",
            "        [7.0111],\n",
            "        [5.9251],\n",
            "        [8.8381]]), target_rating: tensor([8, 9, 6, 7])\n",
            "model_output: tensor([[8.8683],\n",
            "        [7.4248],\n",
            "        [6.9459],\n",
            "        [9.1980]]), target_rating: tensor([ 8,  7,  6, 10])\n",
            "model_output: tensor([[6.9497],\n",
            "        [7.5583],\n",
            "        [8.4614],\n",
            "        [6.1758]]), target_rating: tensor([8, 6, 7, 5])\n",
            "model_output: tensor([[7.7660],\n",
            "        [6.3030],\n",
            "        [8.0005],\n",
            "        [6.5421]]), target_rating: tensor([ 8,  6, 10,  4])\n",
            "model_output: tensor([[8.0800],\n",
            "        [8.6093],\n",
            "        [7.3623],\n",
            "        [8.7152]]), target_rating: tensor([8, 8, 8, 7])\n",
            "model_output: tensor([[9.3438],\n",
            "        [5.1514],\n",
            "        [7.2758],\n",
            "        [6.3920]]), target_rating: tensor([8, 8, 7, 9])\n",
            "model_output: tensor([[7.3600],\n",
            "        [7.2165],\n",
            "        [7.1734],\n",
            "        [8.9553]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[5.7381],\n",
            "        [6.3064],\n",
            "        [6.1360],\n",
            "        [7.8226]]), target_rating: tensor([5, 8, 7, 8])\n",
            "model_output: tensor([[7.9118],\n",
            "        [6.3082],\n",
            "        [8.5477],\n",
            "        [8.5332]]), target_rating: tensor([7, 6, 6, 6])\n",
            "model_output: tensor([[6.0917],\n",
            "        [5.2801],\n",
            "        [6.5854],\n",
            "        [7.7284]]), target_rating: tensor([6, 6, 9, 8])\n",
            "model_output: tensor([[8.4552],\n",
            "        [7.1649],\n",
            "        [9.0373],\n",
            "        [7.3183]]), target_rating: tensor([10,  7,  9,  6])\n",
            "model_output: tensor([[5.8702],\n",
            "        [6.6948],\n",
            "        [8.3651],\n",
            "        [7.2220]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[8.2733],\n",
            "        [6.1928],\n",
            "        [7.9021],\n",
            "        [9.0147]]), target_rating: tensor([ 9,  4, 10,  9])\n",
            "model_output: tensor([[7.3453],\n",
            "        [6.6316],\n",
            "        [8.6897],\n",
            "        [7.6028]]), target_rating: tensor([ 8,  6, 10,  8])\n",
            "model_output: tensor([[7.5288],\n",
            "        [8.7436],\n",
            "        [7.3178],\n",
            "        [7.7695]]), target_rating: tensor([8, 9, 7, 8])\n",
            "model_output: tensor([[7.2871],\n",
            "        [8.3720],\n",
            "        [7.2958],\n",
            "        [8.8870]]), target_rating: tensor([ 8, 10, 10,  9])\n",
            "model_output: tensor([[6.2565],\n",
            "        [8.6171],\n",
            "        [6.9239],\n",
            "        [6.7712]]), target_rating: tensor([ 6, 10,  8,  5])\n",
            "model_output: tensor([[6.3148],\n",
            "        [6.5898],\n",
            "        [7.2814],\n",
            "        [6.8899]]), target_rating: tensor([7, 8, 6, 7])\n",
            "model_output: tensor([[8.7031],\n",
            "        [6.7898],\n",
            "        [7.3329],\n",
            "        [7.5148]]), target_rating: tensor([8, 8, 8, 8])\n",
            "model_output: tensor([[6.9050],\n",
            "        [4.9727],\n",
            "        [7.1545],\n",
            "        [8.5332]]), target_rating: tensor([7, 7, 7, 9])\n",
            "model_output: tensor([[9.5820],\n",
            "        [9.8139],\n",
            "        [7.6622],\n",
            "        [7.4209]]), target_rating: tensor([ 9, 10,  9,  8])\n",
            "model_output: tensor([[7.9336],\n",
            "        [8.0175],\n",
            "        [6.5615],\n",
            "        [7.9948]]), target_rating: tensor([8, 5, 8, 9])\n",
            "model_output: tensor([[8.2946],\n",
            "        [9.7823],\n",
            "        [7.8572],\n",
            "        [5.2777]]), target_rating: tensor([8, 7, 8, 6])\n",
            "model_output: tensor([[6.6688],\n",
            "        [5.8236],\n",
            "        [7.5869],\n",
            "        [8.4539]]), target_rating: tensor([8, 9, 9, 8])\n",
            "model_output: tensor([[6.1668],\n",
            "        [8.9781],\n",
            "        [6.7165],\n",
            "        [8.2869]]), target_rating: tensor([ 5, 10,  7,  8])\n",
            "model_output: tensor([[7.9561],\n",
            "        [7.1202],\n",
            "        [3.8100],\n",
            "        [6.7757]]), target_rating: tensor([6, 7, 5, 7])\n",
            "model_output: tensor([[5.3094],\n",
            "        [7.9404],\n",
            "        [5.6634],\n",
            "        [8.2208]]), target_rating: tensor([5, 7, 6, 9])\n",
            "model_output: tensor([[6.1194],\n",
            "        [6.5819],\n",
            "        [9.0915],\n",
            "        [7.8304]]), target_rating: tensor([ 6,  7,  8, 10])\n",
            "model_output: tensor([[8.3952],\n",
            "        [7.6244],\n",
            "        [7.9106],\n",
            "        [6.4370]]), target_rating: tensor([8, 8, 7, 8])\n",
            "model_output: tensor([[7.6055],\n",
            "        [7.7016],\n",
            "        [7.0761],\n",
            "        [5.3688]]), target_rating: tensor([9, 6, 8, 7])\n",
            "model_output: tensor([[7.7862],\n",
            "        [8.2746],\n",
            "        [7.4972],\n",
            "        [6.7137]]), target_rating: tensor([ 9, 10,  8,  7])\n",
            "model_output: tensor([[5.3722],\n",
            "        [7.7466],\n",
            "        [8.7351],\n",
            "        [8.8294]]), target_rating: tensor([6, 7, 9, 9])\n",
            "model_output: tensor([[7.1009],\n",
            "        [8.4022],\n",
            "        [7.6108],\n",
            "        [6.2882]]), target_rating: tensor([6, 8, 8, 6])\n",
            "model_output: tensor([[8.6180],\n",
            "        [6.4267],\n",
            "        [6.3824],\n",
            "        [9.8646]]), target_rating: tensor([ 9,  6,  7, 10])\n",
            "model_output: tensor([[5.6668],\n",
            "        [7.7676],\n",
            "        [7.2649],\n",
            "        [9.6141]]), target_rating: tensor([ 6, 10,  9, 10])\n",
            "model_output: tensor([[8.2265],\n",
            "        [8.7265],\n",
            "        [6.8415],\n",
            "        [7.4579]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[8.8083],\n",
            "        [4.6185],\n",
            "        [5.7227],\n",
            "        [7.6626]]), target_rating: tensor([10,  3,  6,  7])\n",
            "model_output: tensor([[7.4157],\n",
            "        [5.5608],\n",
            "        [7.3698],\n",
            "        [6.5423]]), target_rating: tensor([8, 6, 8, 6])\n",
            "model_output: tensor([[8.1507],\n",
            "        [7.6171],\n",
            "        [9.8939],\n",
            "        [6.2899]]), target_rating: tensor([7, 9, 9, 5])\n",
            "model_output: tensor([[5.7251],\n",
            "        [5.8386],\n",
            "        [6.4680],\n",
            "        [7.8402]]), target_rating: tensor([5, 9, 6, 7])\n",
            "model_output: tensor([[6.3376],\n",
            "        [5.8454],\n",
            "        [6.3167],\n",
            "        [5.8595]]), target_rating: tensor([6, 7, 7, 8])\n",
            "model_output: tensor([[7.9011],\n",
            "        [8.6913],\n",
            "        [6.0151],\n",
            "        [6.7165]]), target_rating: tensor([ 7, 10,  8,  7])\n",
            "model_output: tensor([[7.4019],\n",
            "        [6.7528],\n",
            "        [6.5415],\n",
            "        [6.1441]]), target_rating: tensor([7, 7, 8, 6])\n",
            "model_output: tensor([[7.9125],\n",
            "        [7.8792],\n",
            "        [8.2752],\n",
            "        [6.8765]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[8.1578],\n",
            "        [6.6297],\n",
            "        [7.6412],\n",
            "        [5.8371]]), target_rating: tensor([9, 7, 8, 6])\n",
            "model_output: tensor([[7.9010],\n",
            "        [9.6796],\n",
            "        [9.0516],\n",
            "        [6.9361]]), target_rating: tensor([10,  9,  9,  8])\n",
            "model_output: tensor([[6.9260],\n",
            "        [6.7376],\n",
            "        [6.7952],\n",
            "        [7.7748]]), target_rating: tensor([7, 5, 8, 7])\n",
            "model_output: tensor([[8.8022],\n",
            "        [7.4692],\n",
            "        [7.7102],\n",
            "        [7.6768]]), target_rating: tensor([9, 6, 8, 8])\n",
            "model_output: tensor([[7.7177],\n",
            "        [9.4344],\n",
            "        [8.7315],\n",
            "        [7.8116]]), target_rating: tensor([7, 8, 8, 9])\n",
            "model_output: tensor([[6.0922],\n",
            "        [6.6668],\n",
            "        [5.9116],\n",
            "        [6.7603]]), target_rating: tensor([6, 6, 7, 5])\n",
            "model_output: tensor([[6.2389],\n",
            "        [6.3522],\n",
            "        [7.3007],\n",
            "        [8.2843]]), target_rating: tensor([6, 8, 7, 8])\n",
            "model_output: tensor([[6.3686],\n",
            "        [7.1676],\n",
            "        [7.3845],\n",
            "        [5.9347]]), target_rating: tensor([5, 9, 8, 3])\n",
            "model_output: tensor([[8.8132],\n",
            "        [5.8873],\n",
            "        [7.6957],\n",
            "        [7.6817]]), target_rating: tensor([9, 6, 7, 8])\n",
            "model_output: tensor([[7.9550],\n",
            "        [9.3086],\n",
            "        [8.6889],\n",
            "        [5.2871]]), target_rating: tensor([ 6, 10, 10,  8])\n",
            "model_output: tensor([[8.1820],\n",
            "        [8.9226],\n",
            "        [6.0047],\n",
            "        [8.3426]]), target_rating: tensor([8, 6, 7, 7])\n",
            "model_output: tensor([[9.4040],\n",
            "        [6.5975],\n",
            "        [6.8205],\n",
            "        [7.4271]]), target_rating: tensor([10,  7,  8,  8])\n",
            "model_output: tensor([[5.7220],\n",
            "        [7.5251],\n",
            "        [6.5460],\n",
            "        [6.3907]]), target_rating: tensor([8, 7, 6, 7])\n",
            "model_output: tensor([[7.4189],\n",
            "        [7.7606],\n",
            "        [7.2424],\n",
            "        [9.6117]]), target_rating: tensor([7, 8, 6, 9])\n",
            "model_output: tensor([[7.0066],\n",
            "        [4.9628],\n",
            "        [6.8155],\n",
            "        [6.7446]]), target_rating: tensor([ 8,  5,  6, 10])\n",
            "model_output: tensor([[7.8154],\n",
            "        [6.5035],\n",
            "        [5.8240],\n",
            "        [8.5765]]), target_rating: tensor([8, 8, 6, 7])\n",
            "model_output: tensor([[7.2381],\n",
            "        [6.8472],\n",
            "        [7.5792],\n",
            "        [8.1028]]), target_rating: tensor([ 6,  5, 10,  8])\n",
            "model_output: tensor([[6.8046],\n",
            "        [7.8495],\n",
            "        [6.3098],\n",
            "        [6.2321]]), target_rating: tensor([ 7, 10,  8,  7])\n",
            "model_output: tensor([[7.4797],\n",
            "        [7.0874],\n",
            "        [5.6186],\n",
            "        [7.9350]]), target_rating: tensor([7, 8, 6, 8])\n",
            "model_output: tensor([[8.3032],\n",
            "        [9.8022],\n",
            "        [7.1492],\n",
            "        [8.5649]]), target_rating: tensor([7, 9, 6, 8])\n",
            "model_output: tensor([[7.0399],\n",
            "        [8.3096],\n",
            "        [7.3946],\n",
            "        [9.2617]]), target_rating: tensor([8, 9, 9, 8])\n",
            "model_output: tensor([[7.1688],\n",
            "        [6.5664],\n",
            "        [8.5643],\n",
            "        [7.3708]]), target_rating: tensor([7, 8, 9, 8])\n",
            "model_output: tensor([[5.0496],\n",
            "        [6.7761],\n",
            "        [6.6096],\n",
            "        [7.6547]]), target_rating: tensor([7, 7, 7, 7])\n",
            "model_output: tensor([[4.7493],\n",
            "        [9.3869],\n",
            "        [7.3392],\n",
            "        [8.0029]]), target_rating: tensor([7, 7, 6, 5])\n",
            "model_output: tensor([[8.3371],\n",
            "        [5.9423],\n",
            "        [5.8701],\n",
            "        [5.9591]]), target_rating: tensor([8, 5, 5, 5])\n",
            "model_output: tensor([[7.6913],\n",
            "        [5.5363],\n",
            "        [6.9386],\n",
            "        [6.2195]]), target_rating: tensor([5, 4, 7, 6])\n",
            "model_output: tensor([[9.2264],\n",
            "        [6.9986],\n",
            "        [8.3630],\n",
            "        [6.8755]]), target_rating: tensor([9, 7, 8, 8])\n",
            "model_output: tensor([[6.4051],\n",
            "        [7.6510],\n",
            "        [7.6713],\n",
            "        [5.5098]]), target_rating: tensor([8, 9, 5, 7])\n",
            "model_output: tensor([[6.0028],\n",
            "        [7.6581],\n",
            "        [6.5852],\n",
            "        [9.3711]]), target_rating: tensor([5, 7, 4, 7])\n",
            "model_output: tensor([[6.1784],\n",
            "        [5.9550],\n",
            "        [7.0359],\n",
            "        [8.0223]]), target_rating: tensor([5, 5, 8, 8])\n",
            "model_output: tensor([[6.6685],\n",
            "        [6.2715],\n",
            "        [7.6745],\n",
            "        [9.0118]]), target_rating: tensor([7, 8, 8, 9])\n",
            "model_output: tensor([[5.2548],\n",
            "        [7.3078],\n",
            "        [5.9233],\n",
            "        [7.5639]]), target_rating: tensor([7, 9, 6, 8])\n",
            "model_output: tensor([[5.5285],\n",
            "        [8.1049],\n",
            "        [6.7661],\n",
            "        [7.8059]]), target_rating: tensor([8, 7, 9, 4])\n",
            "model_output: tensor([[8.0556],\n",
            "        [7.8809],\n",
            "        [7.7776],\n",
            "        [8.2615]]), target_rating: tensor([8, 9, 8, 7])\n",
            "model_output: tensor([[7.0179],\n",
            "        [7.7813],\n",
            "        [7.9274],\n",
            "        [8.1506]]), target_rating: tensor([6, 8, 9, 3])\n",
            "model_output: tensor([[6.0463],\n",
            "        [5.3250],\n",
            "        [6.6221],\n",
            "        [6.1403]]), target_rating: tensor([7, 7, 7, 6])\n",
            "model_output: tensor([[7.7214],\n",
            "        [7.0559],\n",
            "        [7.0056],\n",
            "        [6.9624]]), target_rating: tensor([7, 7, 7, 9])\n",
            "model_output: tensor([[6.4065],\n",
            "        [6.3938],\n",
            "        [6.2569],\n",
            "        [7.2014]]), target_rating: tensor([3, 5, 7, 7])\n",
            "model_output: tensor([[6.0957],\n",
            "        [5.7312],\n",
            "        [9.1350],\n",
            "        [6.3929]]), target_rating: tensor([6, 6, 9, 7])\n",
            "model_output: tensor([[6.2929],\n",
            "        [8.9513],\n",
            "        [7.1329],\n",
            "        [7.7865]]), target_rating: tensor([ 8, 10,  7,  8])\n",
            "model_output: tensor([[7.7052],\n",
            "        [5.9726],\n",
            "        [8.2567],\n",
            "        [6.9972]]), target_rating: tensor([7, 6, 8, 7])\n",
            "model_output: tensor([[7.3059],\n",
            "        [8.2394],\n",
            "        [7.2015],\n",
            "        [6.3703]]), target_rating: tensor([8, 9, 7, 6])\n",
            "model_output: tensor([[10.3953],\n",
            "        [ 7.3987],\n",
            "        [ 6.4358],\n",
            "        [ 8.0796]]), target_rating: tensor([8, 9, 7, 6])\n",
            "model_output: tensor([[7.0310],\n",
            "        [9.5820],\n",
            "        [8.5882],\n",
            "        [4.9355]]), target_rating: tensor([ 8, 10, 10,  4])\n",
            "model_output: tensor([[7.7970],\n",
            "        [5.6048],\n",
            "        [7.8043],\n",
            "        [8.9831]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[8.2518],\n",
            "        [6.2171],\n",
            "        [8.5765],\n",
            "        [9.2634]]), target_rating: tensor([ 4,  6,  9, 10])\n",
            "model_output: tensor([[6.5930],\n",
            "        [9.7294],\n",
            "        [6.0817],\n",
            "        [8.0019]]), target_rating: tensor([ 8,  8,  7, 10])\n",
            "model_output: tensor([[6.8677],\n",
            "        [9.1690],\n",
            "        [7.5774],\n",
            "        [7.9620]]), target_rating: tensor([6, 9, 7, 8])\n",
            "model_output: tensor([[7.7214],\n",
            "        [7.1388],\n",
            "        [6.0060],\n",
            "        [8.2113]]), target_rating: tensor([8, 7, 5, 3])\n",
            "model_output: tensor([[6.8908],\n",
            "        [8.7709],\n",
            "        [7.9912],\n",
            "        [7.3253]]), target_rating: tensor([5, 8, 8, 8])\n",
            "model_output: tensor([[8.5585],\n",
            "        [6.2640],\n",
            "        [6.2940],\n",
            "        [5.6071]]), target_rating: tensor([ 8,  6, 10,  6])\n",
            "model_output: tensor([[8.3466],\n",
            "        [6.2382],\n",
            "        [6.7136],\n",
            "        [8.9564]]), target_rating: tensor([ 8,  7,  5, 10])\n",
            "model_output: tensor([[5.7710],\n",
            "        [5.0377],\n",
            "        [9.1448],\n",
            "        [6.1403]]), target_rating: tensor([9, 4, 9, 6])\n",
            "model_output: tensor([[6.7965],\n",
            "        [7.1891],\n",
            "        [8.9918],\n",
            "        [7.7122]]), target_rating: tensor([9, 8, 8, 9])\n",
            "model_output: tensor([[7.1839],\n",
            "        [6.3785],\n",
            "        [6.8348],\n",
            "        [7.1854]]), target_rating: tensor([7, 7, 5, 7])\n",
            "model_output: tensor([[7.9793],\n",
            "        [8.3203],\n",
            "        [6.7137],\n",
            "        [6.6169]]), target_rating: tensor([8, 8, 7, 7])\n",
            "model_output: tensor([[7.8361],\n",
            "        [5.8963],\n",
            "        [6.5922],\n",
            "        [5.9432]]), target_rating: tensor([6, 7, 9, 5])\n",
            "model_output: tensor([[6.2493],\n",
            "        [6.4713],\n",
            "        [6.6717],\n",
            "        [6.4136]]), target_rating: tensor([7, 8, 8, 7])\n",
            "model_output: tensor([[7.6951],\n",
            "        [6.5161],\n",
            "        [7.1973],\n",
            "        [6.5787]]), target_rating: tensor([ 9,  6, 10,  6])\n",
            "model_output: tensor([[6.7244],\n",
            "        [7.0193],\n",
            "        [8.4484],\n",
            "        [7.2539]]), target_rating: tensor([8, 6, 7, 9])\n",
            "model_output: tensor([[7.3649],\n",
            "        [7.9043],\n",
            "        [6.8442],\n",
            "        [7.4548]]), target_rating: tensor([7, 9, 6, 6])\n",
            "model_output: tensor([[7.3123],\n",
            "        [7.0345],\n",
            "        [5.7599],\n",
            "        [7.8763]]), target_rating: tensor([6, 7, 7, 8])\n",
            "model_output: tensor([[5.7081],\n",
            "        [9.3899],\n",
            "        [6.5303],\n",
            "        [7.8513]]), target_rating: tensor([7, 8, 8, 8])\n",
            "model_output: tensor([[7.0852],\n",
            "        [6.0470],\n",
            "        [6.4452],\n",
            "        [7.8608]]), target_rating: tensor([7, 7, 5, 7])\n",
            "model_output: tensor([[5.3367],\n",
            "        [8.7510],\n",
            "        [7.0859],\n",
            "        [6.8282]]), target_rating: tensor([6, 7, 6, 7])\n",
            "model_output: tensor([[ 6.4598],\n",
            "        [ 7.9536],\n",
            "        [ 6.9004],\n",
            "        [10.4997]]), target_rating: tensor([ 5,  8,  7, 10])\n",
            "model_output: tensor([[6.4583],\n",
            "        [6.3660],\n",
            "        [7.0592],\n",
            "        [7.5315]]), target_rating: tensor([ 3,  6, 10,  7])\n",
            "model_output: tensor([[6.1817],\n",
            "        [5.1952],\n",
            "        [6.3080],\n",
            "        [7.0643]]), target_rating: tensor([5, 5, 6, 5])\n",
            "model_output: tensor([[6.3722],\n",
            "        [8.4011],\n",
            "        [8.4115],\n",
            "        [8.8883]]), target_rating: tensor([ 6, 10,  8,  9])\n",
            "model_output: tensor([[5.6393],\n",
            "        [7.9887],\n",
            "        [7.5518],\n",
            "        [8.5081]]), target_rating: tensor([4, 6, 8, 8])\n",
            "model_output: tensor([[8.7643],\n",
            "        [5.4460],\n",
            "        [9.8240],\n",
            "        [6.7697]]), target_rating: tensor([ 6,  5, 10,  8])\n",
            "model_output: tensor([[7.2638],\n",
            "        [6.9839],\n",
            "        [5.9743],\n",
            "        [6.1575]]), target_rating: tensor([ 8,  5, 10,  5])\n",
            "model_output: tensor([[8.1043],\n",
            "        [8.6254],\n",
            "        [5.9374],\n",
            "        [7.9001]]), target_rating: tensor([8, 8, 6, 8])\n",
            "model_output: tensor([[7.7508],\n",
            "        [5.2677],\n",
            "        [8.3310],\n",
            "        [8.3475]]), target_rating: tensor([ 8,  3, 10,  8])\n",
            "model_output: tensor([[9.0288],\n",
            "        [5.1601],\n",
            "        [8.1180],\n",
            "        [6.8416]]), target_rating: tensor([9, 5, 8, 8])\n",
            "model_output: tensor([[8.5343],\n",
            "        [9.2413],\n",
            "        [5.8266],\n",
            "        [6.6712]]), target_rating: tensor([ 6, 10,  8,  8])\n",
            "model_output: tensor([[7.3109],\n",
            "        [5.1131],\n",
            "        [7.2218],\n",
            "        [6.3221]]), target_rating: tensor([8, 5, 6, 8])\n",
            "model_output: tensor([[7.3389],\n",
            "        [6.3016],\n",
            "        [7.6688],\n",
            "        [6.3760]]), target_rating: tensor([7, 8, 7, 8])\n",
            "model_output: tensor([[ 7.8434],\n",
            "        [ 7.8168],\n",
            "        [ 7.7455],\n",
            "        [10.7694]]), target_rating: tensor([ 7,  8,  8, 10])\n",
            "model_output: tensor([[8.2933],\n",
            "        [7.9771],\n",
            "        [8.2709],\n",
            "        [8.3433]]), target_rating: tensor([ 7,  8, 10,  7])\n",
            "model_output: tensor([[9.8191],\n",
            "        [7.6251],\n",
            "        [8.7106],\n",
            "        [6.8607]]), target_rating: tensor([9, 9, 7, 7])\n",
            "model_output: tensor([[9.1029],\n",
            "        [8.6130],\n",
            "        [7.1427],\n",
            "        [7.5268]]), target_rating: tensor([8, 9, 8, 8])\n",
            "model_output: tensor([[7.2729],\n",
            "        [6.9117],\n",
            "        [6.9305],\n",
            "        [6.4920]]), target_rating: tensor([8, 6, 7, 6])\n",
            "model_output: tensor([[6.7026],\n",
            "        [7.0158],\n",
            "        [8.7305],\n",
            "        [4.4790]]), target_rating: tensor([9, 5, 8, 6])\n",
            "model_output: tensor([[7.2305],\n",
            "        [8.0517],\n",
            "        [8.9959],\n",
            "        [7.9680]]), target_rating: tensor([6, 6, 9, 8])\n",
            "model_output: tensor([[ 8.1314],\n",
            "        [ 6.4543],\n",
            "        [10.0634],\n",
            "        [ 8.3933]]), target_rating: tensor([8, 7, 9, 6])\n",
            "model_output: tensor([[8.6402],\n",
            "        [5.6611],\n",
            "        [6.1773],\n",
            "        [7.6302]]), target_rating: tensor([7, 6, 6, 8])\n",
            "model_output: tensor([[8.9569],\n",
            "        [8.4815],\n",
            "        [6.8136],\n",
            "        [7.1621]]), target_rating: tensor([10,  9,  7,  6])\n",
            "model_output: tensor([[6.8211],\n",
            "        [7.3021],\n",
            "        [6.9798],\n",
            "        [5.9464]]), target_rating: tensor([9, 6, 9, 6])\n",
            "model_output: tensor([[5.7983],\n",
            "        [6.1789],\n",
            "        [7.3552],\n",
            "        [6.0739]]), target_rating: tensor([6, 8, 7, 5])\n",
            "model_output: tensor([[8.3759],\n",
            "        [6.6398],\n",
            "        [6.3118],\n",
            "        [6.6765]]), target_rating: tensor([8, 5, 7, 7])\n",
            "model_output: tensor([[8.1292],\n",
            "        [9.4282],\n",
            "        [8.4305],\n",
            "        [6.4273]]), target_rating: tensor([6, 9, 9, 2])\n",
            "model_output: tensor([[ 5.8625],\n",
            "        [ 8.2128],\n",
            "        [ 8.2833],\n",
            "        [10.4660]]), target_rating: tensor([ 6,  9, 10,  9])\n",
            "model_output: tensor([[5.6557],\n",
            "        [8.7225],\n",
            "        [7.1204],\n",
            "        [7.1740]]), target_rating: tensor([6, 8, 6, 9])\n",
            "model_output: tensor([[8.1055],\n",
            "        [8.4152],\n",
            "        [8.1852],\n",
            "        [6.3382]]), target_rating: tensor([9, 8, 7, 5])\n",
            "model_output: tensor([[7.4857],\n",
            "        [6.2393],\n",
            "        [8.2705],\n",
            "        [6.8911]]), target_rating: tensor([8, 6, 7, 6])\n",
            "model_output: tensor([[10.1079],\n",
            "        [ 7.6581],\n",
            "        [ 4.6962],\n",
            "        [ 8.1874]]), target_rating: tensor([8, 9, 5, 3])\n",
            "model_output: tensor([[7.8644],\n",
            "        [6.3119],\n",
            "        [7.0838],\n",
            "        [6.3461]]), target_rating: tensor([4, 6, 8, 5])\n",
            "model_output: tensor([[8.3418],\n",
            "        [5.8031],\n",
            "        [6.9978],\n",
            "        [7.7687]]), target_rating: tensor([10,  5,  8,  7])\n",
            "model_output: tensor([[7.4054],\n",
            "        [7.7270],\n",
            "        [7.3067],\n",
            "        [5.5739]]), target_rating: tensor([8, 6, 8, 7])\n",
            "model_output: tensor([[6.3416],\n",
            "        [8.7265],\n",
            "        [8.2774],\n",
            "        [7.5593]]), target_rating: tensor([ 5, 10, 10,  7])\n",
            "model_output: tensor([[7.3223],\n",
            "        [5.9532],\n",
            "        [8.7584],\n",
            "        [5.0633]]), target_rating: tensor([9, 5, 8, 5])\n",
            "model_output: tensor([[8.6974],\n",
            "        [6.9281],\n",
            "        [6.6486],\n",
            "        [5.9178]]), target_rating: tensor([7, 8, 7, 7])\n",
            "model_output: tensor([[8.5978],\n",
            "        [7.2022],\n",
            "        [8.0822],\n",
            "        [6.3656]]), target_rating: tensor([10,  8,  8,  6])\n",
            "model_output: tensor([[7.8031],\n",
            "        [8.8802],\n",
            "        [6.1400],\n",
            "        [9.1493]]), target_rating: tensor([7, 9, 6, 7])\n",
            "model_output: tensor([[10.2699],\n",
            "        [ 8.4486],\n",
            "        [ 6.5823],\n",
            "        [ 6.8412]]), target_rating: tensor([10,  9,  1,  7])\n",
            "model_output: tensor([[7.5073],\n",
            "        [5.5448],\n",
            "        [7.5358],\n",
            "        [8.4719]]), target_rating: tensor([8, 7, 9, 9])\n",
            "model_output: tensor([[7.8014],\n",
            "        [8.2222],\n",
            "        [7.7855],\n",
            "        [6.9531]]), target_rating: tensor([1, 9, 8, 7])\n",
            "model_output: tensor([[6.4008],\n",
            "        [7.3509],\n",
            "        [6.3688],\n",
            "        [8.8621]]), target_rating: tensor([6, 9, 7, 8])\n",
            "model_output: tensor([[6.7520],\n",
            "        [7.8964],\n",
            "        [6.6635],\n",
            "        [6.3496]]), target_rating: tensor([9, 8, 8, 6])\n",
            "model_output: tensor([[6.4405],\n",
            "        [8.4158],\n",
            "        [7.3581],\n",
            "        [5.0204]]), target_rating: tensor([ 5, 10,  5,  5])\n",
            "model_output: tensor([[7.7600],\n",
            "        [8.2175],\n",
            "        [7.7649],\n",
            "        [7.1366]]), target_rating: tensor([7, 7, 9, 6])\n",
            "model_output: tensor([[6.3265],\n",
            "        [6.8377],\n",
            "        [7.6548],\n",
            "        [5.5348]]), target_rating: tensor([6, 6, 7, 7])\n",
            "model_output: tensor([[4.9340],\n",
            "        [7.1745],\n",
            "        [7.4644],\n",
            "        [6.6096]]), target_rating: tensor([6, 5, 8, 7])\n",
            "model_output: tensor([[8.5116],\n",
            "        [5.6590],\n",
            "        [9.2704],\n",
            "        [9.0782]]), target_rating: tensor([ 8,  5,  8, 10])\n",
            "model_output: tensor([[7.5946],\n",
            "        [6.0145],\n",
            "        [9.5894],\n",
            "        [8.3375]]), target_rating: tensor([9, 7, 8, 6])\n",
            "model_output: tensor([[8.2827],\n",
            "        [8.6495],\n",
            "        [7.9566],\n",
            "        [6.8278]]), target_rating: tensor([8, 8, 7, 6])\n",
            "model_output: tensor([[7.8517],\n",
            "        [5.5691],\n",
            "        [6.0459],\n",
            "        [7.9006]]), target_rating: tensor([ 9,  7,  6, 10])\n",
            "model_output: tensor([[5.7657],\n",
            "        [7.0488],\n",
            "        [6.7840],\n",
            "        [8.7619]]), target_rating: tensor([ 8,  7,  7, 10])\n",
            "model_output: tensor([[6.2285],\n",
            "        [8.5426],\n",
            "        [6.8710],\n",
            "        [7.3598]]), target_rating: tensor([8, 9, 8, 9])\n",
            "model_output: tensor([[7.6708],\n",
            "        [8.6695],\n",
            "        [8.1356],\n",
            "        [6.6894]]), target_rating: tensor([9, 7, 9, 6])\n",
            "model_output: tensor([[6.7966],\n",
            "        [8.4291],\n",
            "        [8.6728],\n",
            "        [8.5147]]), target_rating: tensor([9, 7, 8, 9])\n",
            "model_output: tensor([[8.7378],\n",
            "        [6.5100],\n",
            "        [8.2966],\n",
            "        [7.2954]]), target_rating: tensor([8, 7, 8, 9])\n",
            "model_output: tensor([[3.7465],\n",
            "        [7.1602],\n",
            "        [7.3490],\n",
            "        [6.3641]]), target_rating: tensor([5, 7, 6, 5])\n",
            "model_output: tensor([[5.9721],\n",
            "        [5.4089],\n",
            "        [8.2335],\n",
            "        [6.0277]]), target_rating: tensor([7, 6, 7, 7])\n",
            "model_output: tensor([[5.6732],\n",
            "        [7.3424],\n",
            "        [6.3692],\n",
            "        [5.9828]]), target_rating: tensor([6, 9, 7, 7])\n",
            "model_output: tensor([[8.0592],\n",
            "        [6.7066],\n",
            "        [7.3370],\n",
            "        [5.5994]]), target_rating: tensor([ 7,  8, 10,  4])\n",
            "model_output: tensor([[6.3152],\n",
            "        [6.3676],\n",
            "        [8.8256],\n",
            "        [5.1749]]), target_rating: tensor([7, 6, 9, 4])\n",
            "model_output: tensor([[ 7.8596],\n",
            "        [ 7.4852],\n",
            "        [ 6.9140],\n",
            "        [10.3627]]), target_rating: tensor([7, 9, 4, 7])\n",
            "model_output: tensor([[9.6316],\n",
            "        [7.8892],\n",
            "        [7.8712],\n",
            "        [6.5033]]), target_rating: tensor([9, 8, 8, 5])\n",
            "model_output: tensor([[5.5888],\n",
            "        [8.2855],\n",
            "        [8.7967],\n",
            "        [6.9267]]), target_rating: tensor([6, 7, 9, 6])\n",
            "model_output: tensor([[8.2647],\n",
            "        [8.4747],\n",
            "        [7.7727],\n",
            "        [7.7869]]), target_rating: tensor([ 9,  7,  8, 10])\n",
            "model_output: tensor([[8.5187],\n",
            "        [6.6337],\n",
            "        [9.2651],\n",
            "        [8.2395]]), target_rating: tensor([9, 4, 9, 9])\n",
            "model_output: tensor([[7.7618],\n",
            "        [8.7647],\n",
            "        [8.4911],\n",
            "        [5.6872]]), target_rating: tensor([9, 7, 7, 7])\n",
            "model_output: tensor([[6.7482],\n",
            "        [5.0532],\n",
            "        [7.9935],\n",
            "        [7.4590]]), target_rating: tensor([7, 7, 9, 7])\n",
            "model_output: tensor([[8.6836],\n",
            "        [5.8614],\n",
            "        [5.1176],\n",
            "        [6.8372]]), target_rating: tensor([7, 6, 7, 7])\n",
            "model_output: tensor([[8.0488],\n",
            "        [9.5804],\n",
            "        [7.3130],\n",
            "        [6.4469]]), target_rating: tensor([ 9, 10,  9,  8])\n",
            "model_output: tensor([[6.8421],\n",
            "        [7.2048],\n",
            "        [7.4013],\n",
            "        [5.9409]]), target_rating: tensor([7, 7, 8, 4])\n",
            "model_output: tensor([[8.4853],\n",
            "        [7.8153],\n",
            "        [6.3892],\n",
            "        [7.3895]]), target_rating: tensor([9, 8, 9, 7])\n",
            "model_output: tensor([[7.4977],\n",
            "        [4.9436],\n",
            "        [6.9570],\n",
            "        [7.6909]]), target_rating: tensor([9, 7, 8, 8])\n",
            "model_output: tensor([[7.4516],\n",
            "        [7.0375],\n",
            "        [6.6242],\n",
            "        [7.5474]]), target_rating: tensor([6, 4, 6, 7])\n",
            "model_output: tensor([[6.4213],\n",
            "        [5.9090],\n",
            "        [6.3190],\n",
            "        [8.5374]]), target_rating: tensor([5, 6, 5, 6])\n",
            "model_output: tensor([[7.7593],\n",
            "        [7.9235],\n",
            "        [7.4628],\n",
            "        [6.7215]]), target_rating: tensor([8, 9, 8, 8])\n",
            "model_output: tensor([[7.5439],\n",
            "        [9.7987],\n",
            "        [7.6853],\n",
            "        [6.9174]]), target_rating: tensor([8, 9, 7, 7])\n",
            "model_output: tensor([[8.3707],\n",
            "        [9.0668],\n",
            "        [7.5863],\n",
            "        [7.7838]]), target_rating: tensor([ 6,  8,  7, 10])\n",
            "model_output: tensor([[7.0121],\n",
            "        [8.0388],\n",
            "        [7.5670],\n",
            "        [7.4681]]), target_rating: tensor([5, 9, 9, 6])\n",
            "model_output: tensor([[6.5758],\n",
            "        [5.9108],\n",
            "        [8.0007],\n",
            "        [6.5795]]), target_rating: tensor([7, 5, 9, 8])\n",
            "model_output: tensor([[6.9522],\n",
            "        [7.0413],\n",
            "        [8.7009],\n",
            "        [7.4803]]), target_rating: tensor([5, 6, 7, 7])\n",
            "model_output: tensor([[10.1185],\n",
            "        [ 7.8862],\n",
            "        [ 5.2615],\n",
            "        [ 6.8770]]), target_rating: tensor([ 8, 10,  6,  7])\n",
            "model_output: tensor([[6.5002],\n",
            "        [8.8753],\n",
            "        [7.6023],\n",
            "        [7.2171]]), target_rating: tensor([3, 9, 7, 7])\n",
            "model_output: tensor([[6.2617],\n",
            "        [7.8120],\n",
            "        [7.2987],\n",
            "        [6.5389]]), target_rating: tensor([5, 8, 8, 5])\n",
            "model_output: tensor([[9.9721],\n",
            "        [6.5238],\n",
            "        [6.5928],\n",
            "        [7.0299]]), target_rating: tensor([10,  4,  7,  7])\n",
            "model_output: tensor([[4.7814],\n",
            "        [7.0373],\n",
            "        [7.4317],\n",
            "        [7.3269]]), target_rating: tensor([8, 6, 9, 9])\n",
            "model_output: tensor([[ 6.0124],\n",
            "        [ 9.1451],\n",
            "        [10.2944],\n",
            "        [ 7.0545]]), target_rating: tensor([ 7, 10, 10, 10])\n",
            "model_output: tensor([[5.7103],\n",
            "        [7.7579],\n",
            "        [8.5701],\n",
            "        [7.7754]]), target_rating: tensor([5, 7, 7, 9])\n",
            "model_output: tensor([[6.6369],\n",
            "        [5.3054],\n",
            "        [7.0375],\n",
            "        [7.7173]]), target_rating: tensor([6, 8, 9, 8])\n",
            "model_output: tensor([[7.0818],\n",
            "        [8.4164],\n",
            "        [6.4859],\n",
            "        [9.5058]]), target_rating: tensor([9, 8, 7, 7])\n",
            "model_output: tensor([[4.2762],\n",
            "        [7.6981],\n",
            "        [8.3010],\n",
            "        [7.6522]]), target_rating: tensor([10,  7,  9, 10])\n",
            "model_output: tensor([[7.2564],\n",
            "        [5.9261],\n",
            "        [6.6131],\n",
            "        [7.2043]]), target_rating: tensor([8, 6, 6, 8])\n",
            "model_output: tensor([[8.8904],\n",
            "        [6.5901],\n",
            "        [8.2618],\n",
            "        [6.1210]]), target_rating: tensor([ 9,  6, 10,  7])\n",
            "model_output: tensor([[4.9629],\n",
            "        [5.9860],\n",
            "        [8.6781],\n",
            "        [9.5814]]), target_rating: tensor([5, 3, 7, 8])\n",
            "model_output: tensor([[ 7.1706],\n",
            "        [10.0517],\n",
            "        [ 6.2566],\n",
            "        [10.0068]]), target_rating: tensor([ 8, 10,  8,  6])\n",
            "model_output: tensor([[4.3569],\n",
            "        [8.2135],\n",
            "        [6.3009],\n",
            "        [7.2774]]), target_rating: tensor([ 8, 10,  8, 10])\n",
            "model_output: tensor([[7.1743],\n",
            "        [9.6104],\n",
            "        [6.9968],\n",
            "        [6.0391]]), target_rating: tensor([8, 9, 7, 6])\n",
            "model_output: tensor([[6.8896],\n",
            "        [8.1142],\n",
            "        [6.8269],\n",
            "        [8.3909]]), target_rating: tensor([7, 5, 8, 8])\n",
            "model_output: tensor([[6.6035],\n",
            "        [5.2802],\n",
            "        [6.6792],\n",
            "        [6.0199]]), target_rating: tensor([7, 6, 7, 6])\n",
            "model_output: tensor([[8.0318],\n",
            "        [7.4918],\n",
            "        [5.1421]]), target_rating: tensor([9, 7, 5])\n",
            "rms: 0.6945110035581367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# a dict that stores a list of predicted rating and actual rating pair for each user\n",
        "user_est_true = defaultdict(list)\n",
        "\n",
        "# iterate through the validation data to build the user-> [(y1, y1_hat), (y2, y2_hat)...]\n",
        "with torch.no_grad():\n",
        "    for i, batched_data in enumerate(validation_loader):\n",
        "        users = batched_data['users']\n",
        "        animes = batched_data['animes']\n",
        "        ratings = batched_data['ratings']\n",
        "\n",
        "        model_output = model(batched_data['users'], batched_data[\"animes\"])\n",
        "\n",
        "        for i in range(len(users)):\n",
        "            user_id = users[i].item()\n",
        "            anime_id = animes[i].item()\n",
        "            pred_rating = model_output[i][0].item()\n",
        "            true_rating = ratings[i].item()\n",
        "\n",
        "            print(f\"{user_id}, {anime_id}, {pred_rating}, {true_rating}\")\n",
        "            user_est_true[user_id].append((pred_rating, true_rating))\n"
      ],
      "metadata": {
        "id": "i-wlX3REJdfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1ee92a-d083-4c3a-f973-97cbeb022b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33, 124, 8.063875198364258, 7\n",
            "199, 60, 8.358626365661621, 8\n",
            "193, 867, 7.2711896896362305, 8\n",
            "1, 4502, 7.7996296882629395, 8\n",
            "20, 1066, 6.208942890167236, 7\n",
            "84, 3728, 7.988121509552002, 9\n",
            "210, 2748, 8.263138771057129, 9\n",
            "216, 167, 6.438809871673584, 5\n",
            "111, 4993, 6.516317367553711, 8\n",
            "212, 2504, 9.638263702392578, 10\n",
            "210, 982, 6.733669281005859, 7\n",
            "209, 772, 9.309650421142578, 6\n",
            "61, 2630, 7.414953231811523, 7\n",
            "156, 743, 6.496890544891357, 8\n",
            "81, 4953, 6.376847743988037, 7\n",
            "81, 4668, 6.3884477615356445, 6\n",
            "96, 2312, 7.213757514953613, 6\n",
            "84, 2535, 7.057563304901123, 8\n",
            "81, 357, 7.50219202041626, 8\n",
            "168, 2851, 5.791645526885986, 5\n",
            "162, 3546, 7.122175693511963, 8\n",
            "71, 704, 6.743241310119629, 7\n",
            "230, 245, 8.146862983703613, 8\n",
            "226, 701, 9.209311485290527, 8\n",
            "27, 3968, 6.030610084533691, 5\n",
            "233, 2133, 6.29558801651001, 7\n",
            "7, 2056, 7.582315444946289, 7\n",
            "151, 2229, 7.5591559410095215, 6\n",
            "153, 2464, 7.674490451812744, 7\n",
            "123, 798, 5.744808673858643, 8\n",
            "100, 212, 8.32509708404541, 10\n",
            "175, 286, 7.5663676261901855, 3\n",
            "206, 425, 5.883395671844482, 8\n",
            "125, 543, 8.052587509155273, 8\n",
            "210, 1612, 7.832701683044434, 8\n",
            "148, 2383, 6.031825065612793, 6\n",
            "149, 214, 7.939558029174805, 9\n",
            "162, 5362, 9.238103866577148, 7\n",
            "74, 2689, 9.380878448486328, 8\n",
            "168, 2506, 5.992449760437012, 7\n",
            "211, 856, 9.638611793518066, 6\n",
            "211, 373, 8.688575744628906, 10\n",
            "111, 3470, 8.42557430267334, 7\n",
            "61, 112, 8.301918983459473, 8\n",
            "31, 2192, 7.5189361572265625, 8\n",
            "213, 201, 7.268392562866211, 8\n",
            "149, 223, 6.075244903564453, 4\n",
            "218, 365, 8.055925369262695, 6\n",
            "74, 76, 6.684810638427734, 8\n",
            "107, 4912, 8.408869743347168, 7\n",
            "41, 679, 4.494174003601074, 5\n",
            "149, 757, 5.712155342102051, 6\n",
            "217, 243, 7.801185607910156, 6\n",
            "123, 589, 6.247015953063965, 6\n",
            "174, 308, 7.625425338745117, 7\n",
            "78, 717, 8.652454376220703, 10\n",
            "162, 3579, 5.935446262359619, 8\n",
            "65, 3416, 5.391183853149414, 1\n",
            "99, 141, 9.610614776611328, 7\n",
            "193, 3441, 7.28120756149292, 7\n",
            "89, 1099, 7.592441082000732, 7\n",
            "11, 2354, 6.73529052734375, 6\n",
            "162, 3925, 6.451254844665527, 8\n",
            "197, 753, 7.252840995788574, 8\n",
            "146, 484, 4.652244567871094, 2\n",
            "188, 2340, 7.415285587310791, 8\n",
            "225, 47, 7.365731716156006, 6\n",
            "104, 894, 8.780634880065918, 9\n",
            "66, 172, 6.084236145019531, 5\n",
            "210, 345, 7.589179992675781, 8\n",
            "190, 4527, 6.835832595825195, 8\n",
            "96, 483, 7.16458797454834, 6\n",
            "212, 5235, 5.946815013885498, 8\n",
            "146, 99, 7.83022403717041, 10\n",
            "111, 1338, 6.9249773025512695, 7\n",
            "231, 1465, 7.889779567718506, 6\n",
            "233, 1480, 7.291553497314453, 5\n",
            "63, 2003, 6.785841941833496, 8\n",
            "58, 846, 7.744353771209717, 7\n",
            "124, 997, 8.358962059020996, 8\n",
            "54, 1183, 7.949368476867676, 10\n",
            "221, 796, 7.830392837524414, 7\n",
            "112, 3367, 6.528449535369873, 7\n",
            "111, 3684, 5.218851089477539, 7\n",
            "187, 1292, 6.9349565505981445, 8\n",
            "148, 1357, 5.692947864532471, 3\n",
            "178, 3286, 5.499875068664551, 9\n",
            "57, 449, 7.2824201583862305, 7\n",
            "81, 3998, 7.297012805938721, 6\n",
            "129, 868, 5.18820858001709, 8\n",
            "43, 185, 8.095149993896484, 8\n",
            "230, 417, 7.9950456619262695, 4\n",
            "148, 2448, 7.882076740264893, 5\n",
            "118, 76, 6.929935455322266, 7\n",
            "75, 628, 5.184395790100098, 9\n",
            "32, 419, 8.265156745910645, 9\n",
            "55, 744, 9.769268035888672, 10\n",
            "43, 521, 6.8357415199279785, 5\n",
            "10, 4177, 8.413823127746582, 8\n",
            "89, 3606, 8.251712799072266, 9\n",
            "20, 3706, 5.577522277832031, 4\n",
            "192, 2359, 8.958751678466797, 9\n",
            "151, 772, 7.724098205566406, 9\n",
            "148, 3236, 7.198838233947754, 8\n",
            "0, 14, 7.742897987365723, 9\n",
            "61, 841, 7.550735950469971, 9\n",
            "233, 11, 8.291035652160645, 5\n",
            "111, 4879, 7.608781814575195, 8\n",
            "25, 1968, 5.829411029815674, 7\n",
            "226, 3526, 8.956470489501953, 9\n",
            "181, 1091, 8.78759479522705, 9\n",
            "107, 23, 7.353321075439453, 8\n",
            "151, 2194, 7.9675984382629395, 7\n",
            "39, 401, 8.22537899017334, 5\n",
            "89, 200, 6.883881568908691, 5\n",
            "89, 2376, 7.061466217041016, 9\n",
            "207, 1683, 7.136568546295166, 5\n",
            "199, 1150, 5.242074966430664, 6\n",
            "222, 2524, 9.33780574798584, 7\n",
            "143, 2061, 8.075296401977539, 8\n",
            "111, 701, 9.083178520202637, 9\n",
            "125, 59, 7.82841682434082, 8\n",
            "111, 2463, 8.442239761352539, 7\n",
            "105, 1358, 7.839609146118164, 10\n",
            "118, 50, 5.37175178527832, 7\n",
            "184, 365, 7.395610332489014, 7\n",
            "115, 38, 7.723135948181152, 9\n",
            "232, 1024, 5.564963340759277, 6\n",
            "104, 2916, 8.213120460510254, 8\n",
            "81, 5160, 8.38840103149414, 8\n",
            "217, 486, 7.892613410949707, 7\n",
            "151, 3061, 6.924093723297119, 5\n",
            "93, 426, 7.0244059562683105, 9\n",
            "190, 3263, 6.2063703536987305, 6\n",
            "38, 175, 8.043862342834473, 8\n",
            "118, 102, 5.11773681640625, 7\n",
            "118, 803, 6.988315105438232, 7\n",
            "74, 241, 6.6979780197143555, 7\n",
            "129, 1480, 6.3094258308410645, 5\n",
            "61, 1468, 8.009807586669922, 7\n",
            "65, 970, 6.64437198638916, 8\n",
            "149, 3955, 6.57005500793457, 6\n",
            "61, 1350, 8.719804763793945, 7\n",
            "20, 1592, 7.607059478759766, 10\n",
            "118, 1534, 5.999420642852783, 5\n",
            "0, 830, 6.505298614501953, 7\n",
            "115, 184, 6.583495140075684, 8\n",
            "171, 4088, 7.5193586349487305, 8\n",
            "172, 1361, 8.454354286193848, 8\n",
            "118, 2654, 7.520214080810547, 7\n",
            "179, 153, 7.177815914154053, 7\n",
            "207, 73, 6.439523220062256, 7\n",
            "104, 1361, 9.187381744384766, 9\n",
            "166, 150, 7.797821998596191, 7\n",
            "69, 286, 7.73298454284668, 8\n",
            "125, 1054, 7.1754913330078125, 9\n",
            "202, 747, 8.246816635131836, 5\n",
            "223, 5256, 8.447769165039062, 7\n",
            "194, 2003, 8.263108253479004, 7\n",
            "144, 124, 8.424341201782227, 7\n",
            "116, 1473, 7.682431221008301, 8\n",
            "206, 2664, 7.110849380493164, 7\n",
            "230, 1516, 5.7608442306518555, 3\n",
            "193, 2748, 7.340720176696777, 8\n",
            "111, 789, 6.9592485427856445, 7\n",
            "209, 481, 7.236368179321289, 7\n",
            "197, 1940, 6.488516330718994, 10\n",
            "12, 677, 8.86063003540039, 8\n",
            "162, 2244, 5.413018226623535, 4\n",
            "197, 3828, 7.259409427642822, 7\n",
            "124, 1038, 9.093498229980469, 7\n",
            "213, 49, 7.0081353187561035, 8\n",
            "118, 2484, 7.417158126831055, 8\n",
            "54, 591, 9.71683120727539, 8\n",
            "151, 2696, 8.263846397399902, 7\n",
            "116, 3, 9.674688339233398, 9\n",
            "180, 42, 7.079924583435059, 8\n",
            "89, 1446, 8.55584716796875, 9\n",
            "81, 1331, 6.916318416595459, 6\n",
            "60, 99, 10.352531433105469, 10\n",
            "118, 1649, 6.901841163635254, 3\n",
            "111, 4982, 6.753417491912842, 7\n",
            "198, 286, 7.050779342651367, 8\n",
            "226, 239, 9.939592361450195, 9\n",
            "40, 3324, 8.513269424438477, 9\n",
            "168, 203, 6.087332248687744, 6\n",
            "153, 746, 8.624246597290039, 9\n",
            "65, 2742, 7.975383758544922, 7\n",
            "194, 2748, 8.180208206176758, 7\n",
            "106, 639, 7.169020175933838, 7\n",
            "219, 3515, 6.384478569030762, 6\n",
            "89, 2812, 8.092727661132812, 8\n",
            "96, 358, 8.183310508728027, 10\n",
            "66, 494, 5.006575584411621, 6\n",
            "118, 730, 5.929377555847168, 5\n",
            "15, 116, 9.813318252563477, 9\n",
            "7, 2286, 5.608005523681641, 5\n",
            "228, 184, 7.778772354125977, 8\n",
            "197, 1361, 9.209177017211914, 10\n",
            "136, 1683, 8.088171005249023, 7\n",
            "111, 2808, 7.262392520904541, 9\n",
            "232, 540, 6.82940673828125, 6\n",
            "211, 166, 8.028787612915039, 10\n",
            "206, 1571, 6.473870277404785, 6\n",
            "25, 2366, 5.4960479736328125, 7\n",
            "167, 1446, 6.034605979919434, 6\n",
            "167, 219, 4.934197902679443, 6\n",
            "230, 2029, 8.735478401184082, 9\n",
            "223, 4094, 6.337608337402344, 6\n",
            "152, 203, 8.882111549377441, 8\n",
            "151, 870, 6.412055015563965, 9\n",
            "104, 336, 7.640748500823975, 8\n",
            "218, 681, 5.949739933013916, 6\n",
            "36, 4107, 6.830127239227295, 8\n",
            "213, 421, 7.783466339111328, 7\n",
            "168, 2348, 6.90842866897583, 5\n",
            "39, 379, 6.58404541015625, 7\n",
            "131, 781, 6.506207466125488, 3\n",
            "111, 2156, 7.206377029418945, 7\n",
            "186, 401, 8.455992698669434, 7\n",
            "151, 211, 6.993100166320801, 5\n",
            "163, 910, 7.256011486053467, 7\n",
            "211, 185, 8.729772567749023, 10\n",
            "118, 115, 8.56056022644043, 7\n",
            "111, 3772, 7.462887763977051, 8\n",
            "31, 229, 7.908084869384766, 8\n",
            "12, 239, 9.70784854888916, 9\n",
            "51, 257, 7.975346088409424, 8\n",
            "111, 5215, 6.678645133972168, 5\n",
            "213, 157, 6.812894821166992, 9\n",
            "96, 1340, 7.369873046875, 8\n",
            "157, 2853, 7.3685221672058105, 9\n",
            "128, 1535, 6.973415374755859, 9\n",
            "118, 4939, 5.108482837677002, 6\n",
            "82, 2689, 9.610763549804688, 9\n",
            "198, 35, 6.860459327697754, 5\n",
            "202, 540, 7.164381980895996, 6\n",
            "175, 604, 7.861769676208496, 8\n",
            "151, 1665, 9.35612678527832, 9\n",
            "213, 449, 8.229753494262695, 7\n",
            "219, 3678, 7.080609321594238, 8\n",
            "96, 440, 6.1091837882995605, 9\n",
            "187, 3300, 7.599855422973633, 8\n",
            "89, 2840, 9.007062911987305, 9\n",
            "226, 2591, 8.327367782592773, 9\n",
            "175, 3025, 7.027184963226318, 7\n",
            "95, 4956, 6.907524585723877, 8\n",
            "124, 311, 7.653493881225586, 7\n",
            "194, 194, 7.221053600311279, 7\n",
            "162, 3451, 6.04522705078125, 7\n",
            "224, 827, 7.223515510559082, 9\n",
            "189, 2210, 7.983480930328369, 8\n",
            "149, 1730, 5.5172905921936035, 5\n",
            "95, 2904, 6.541243553161621, 8\n",
            "40, 1004, 7.114681720733643, 9\n",
            "208, 784, 8.371437072753906, 10\n",
            "197, 178, 9.040406227111816, 10\n",
            "86, 3383, 7.407395362854004, 5\n",
            "61, 1325, 8.412875175476074, 7\n",
            "81, 4686, 6.45545768737793, 7\n",
            "208, 3489, 8.615067481994629, 8\n",
            "133, 1450, 7.554949760437012, 7\n",
            "116, 400, 8.410179138183594, 8\n",
            "29, 26, 7.732582092285156, 8\n",
            "107, 4899, 7.333560943603516, 7\n",
            "94, 3229, 8.843875885009766, 10\n",
            "206, 2593, 5.607892990112305, 6\n",
            "4, 3708, 7.372443199157715, 8\n",
            "167, 215, 6.769118309020996, 8\n",
            "134, 4430, 6.022430896759033, 5\n",
            "118, 1151, 5.797320365905762, 5\n",
            "118, 2028, 6.876428127288818, 8\n",
            "19, 403, 6.059178352355957, 7\n",
            "118, 4878, 7.808987617492676, 8\n",
            "134, 3099, 4.961315631866455, 5\n",
            "202, 637, 8.459095001220703, 7\n",
            "0, 512, 7.666186332702637, 8\n",
            "190, 511, 6.74235725402832, 10\n",
            "89, 4600, 9.997082710266113, 8\n",
            "32, 1385, 9.20461654663086, 9\n",
            "32, 1372, 8.823831558227539, 10\n",
            "71, 392, 7.56430721282959, 6\n",
            "171, 4108, 7.419197082519531, 7\n",
            "81, 1686, 6.632223606109619, 5\n",
            "156, 1098, 5.435398101806641, 5\n",
            "165, 113, 7.524441242218018, 6\n",
            "148, 1385, 8.002849578857422, 8\n",
            "58, 113, 8.913904190063477, 7\n",
            "104, 107, 9.421768188476562, 10\n",
            "164, 99, 9.474409103393555, 10\n",
            "194, 569, 7.205482482910156, 8\n",
            "175, 1914, 7.286630630493164, 6\n",
            "226, 3823, 6.982393264770508, 7\n",
            "192, 1558, 7.227118492126465, 9\n",
            "156, 5732, 4.406511306762695, 6\n",
            "117, 1666, 9.028524398803711, 8\n",
            "66, 775, 6.49098014831543, 7\n",
            "190, 289, 6.481182098388672, 6\n",
            "172, 87, 6.707502365112305, 5\n",
            "188, 2707, 5.5021772384643555, 4\n",
            "190, 1242, 7.627435684204102, 7\n",
            "129, 492, 5.652322292327881, 6\n",
            "178, 141, 7.9359846115112305, 8\n",
            "122, 596, 8.302594184875488, 8\n",
            "234, 1325, 6.41717529296875, 8\n",
            "134, 4930, 7.628076076507568, 6\n",
            "168, 3302, 6.8480682373046875, 4\n",
            "209, 274, 6.157201766967773, 7\n",
            "156, 5268, 4.978980541229248, 7\n",
            "149, 3454, 6.310999870300293, 4\n",
            "193, 746, 8.856036186218262, 9\n",
            "137, 1352, 7.712430000305176, 7\n",
            "214, 1134, 6.641015529632568, 9\n",
            "219, 4733, 6.979846477508545, 7\n",
            "151, 3191, 7.100602149963379, 7\n",
            "168, 649, 5.169207572937012, 8\n",
            "212, 5335, 6.990021705627441, 6\n",
            "157, 116, 8.518296241760254, 10\n",
            "7, 363, 9.2149076461792, 7\n",
            "63, 52, 7.2060041427612305, 9\n",
            "134, 3818, 5.070689678192139, 5\n",
            "156, 5031, 7.596100807189941, 6\n",
            "148, 2743, 6.657153129577637, 7\n",
            "97, 3850, 8.061409950256348, 8\n",
            "168, 4213, 5.56247615814209, 5\n",
            "151, 28, 8.2413330078125, 9\n",
            "224, 3646, 7.8564558029174805, 9\n",
            "231, 1448, 7.7354302406311035, 6\n",
            "153, 3809, 8.493857383728027, 9\n",
            "157, 1774, 7.590048789978027, 9\n",
            "232, 655, 7.242223262786865, 8\n",
            "168, 426, 5.985424995422363, 6\n",
            "81, 4331, 6.154984951019287, 8\n",
            "119, 114, 8.769556999206543, 8\n",
            "199, 9, 9.226560592651367, 9\n",
            "83, 425, 7.879741668701172, 8\n",
            "219, 1331, 7.586991786956787, 6\n",
            "234, 4939, 4.201251029968262, 3\n",
            "168, 2569, 6.435284614562988, 5\n",
            "81, 5572, 7.186151504516602, 8\n",
            "234, 3806, 6.540909767150879, 4\n",
            "89, 2599, 8.941482543945312, 9\n",
            "168, 4915, 6.526432037353516, 7\n",
            "162, 4835, 9.567893981933594, 9\n",
            "147, 3441, 6.496440887451172, 7\n",
            "183, 5050, 7.894674301147461, 10\n",
            "111, 1559, 8.634931564331055, 7\n",
            "107, 2045, 6.107403755187988, 5\n",
            "116, 428, 10.105096817016602, 7\n",
            "81, 5460, 8.19505500793457, 7\n",
            "61, 115, 8.95533275604248, 9\n",
            "128, 2882, 6.96616268157959, 10\n",
            "197, 1573, 7.959872722625732, 7\n",
            "197, 704, 7.178957462310791, 7\n",
            "134, 1361, 6.8561296463012695, 6\n",
            "117, 1682, 8.451775550842285, 10\n",
            "224, 2229, 7.207558631896973, 7\n",
            "59, 3805, 7.236583232879639, 7\n",
            "192, 3064, 7.52600622177124, 7\n",
            "149, 5112, 7.266655921936035, 10\n",
            "206, 2700, 6.884906768798828, 7\n",
            "210, 414, 7.7210211753845215, 8\n",
            "167, 712, 5.3288140296936035, 5\n",
            "158, 487, 8.21000862121582, 9\n",
            "61, 2506, 7.219010829925537, 7\n",
            "228, 11, 8.60973834991455, 10\n",
            "89, 93, 6.734658718109131, 8\n",
            "208, 141, 9.627110481262207, 9\n",
            "172, 3066, 7.557011604309082, 7\n",
            "70, 943, 7.154982566833496, 8\n",
            "168, 306, 4.959319591522217, 6\n",
            "64, 568, 8.426380157470703, 10\n",
            "178, 4502, 7.670035362243652, 7\n",
            "75, 1543, 6.30548095703125, 8\n",
            "147, 1361, 7.830118179321289, 6\n",
            "107, 5629, 7.119999885559082, 7\n",
            "85, 2284, 6.27396297454834, 5\n",
            "222, 121, 7.399782180786133, 8\n",
            "219, 4200, 7.4370880126953125, 10\n",
            "32, 424, 10.461140632629395, 10\n",
            "1, 3728, 8.239323616027832, 8\n",
            "99, 4541, 6.125872611999512, 6\n",
            "147, 2616, 6.188757419586182, 6\n",
            "78, 1918, 9.720186233520508, 9\n",
            "190, 1244, 6.860133171081543, 8\n",
            "91, 321, 7.860645294189453, 7\n",
            "162, 2872, 7.951336860656738, 8\n",
            "111, 1907, 6.548331260681152, 8\n",
            "226, 3472, 6.779629707336426, 6\n",
            "111, 4500, 7.562782287597656, 5\n",
            "96, 1665, 8.735417366027832, 9\n",
            "56, 3854, 6.245708465576172, 9\n",
            "0, 812, 5.782039642333984, 7\n",
            "117, 2377, 7.492252826690674, 7\n",
            "171, 1326, 5.816275119781494, 7\n",
            "132, 321, 8.658316612243652, 10\n",
            "125, 160, 6.747217178344727, 9\n",
            "188, 47, 7.621230125427246, 9\n",
            "31, 1742, 6.174797058105469, 8\n",
            "148, 1057, 5.815116882324219, 4\n",
            "199, 967, 5.69752311706543, 4\n",
            "176, 1452, 6.541869163513184, 5\n",
            "76, 5029, 6.8721184730529785, 8\n",
            "122, 105, 6.13890266418457, 5\n",
            "151, 2748, 6.997835636138916, 6\n",
            "193, 3308, 6.990774154663086, 8\n",
            "82, 5304, 6.17181396484375, 6\n",
            "208, 3245, 10.03370475769043, 8\n",
            "104, 23, 8.549951553344727, 9\n",
            "66, 232, 4.817136764526367, 6\n",
            "128, 2921, 8.101550102233887, 8\n",
            "118, 512, 6.97440767288208, 8\n",
            "152, 227, 8.841797828674316, 9\n",
            "223, 4830, 7.042965888977051, 5\n",
            "221, 131, 6.788341522216797, 7\n",
            "163, 1092, 5.451675891876221, 6\n",
            "81, 4063, 8.610787391662598, 7\n",
            "73, 512, 6.0581536293029785, 9\n",
            "165, 212, 7.52436637878418, 9\n",
            "89, 4457, 7.618471145629883, 9\n",
            "156, 5335, 4.5857744216918945, 7\n",
            "149, 3273, 6.002092361450195, 8\n",
            "156, 3897, 5.693657398223877, 7\n",
            "104, 648, 8.178194046020508, 7\n",
            "39, 112, 8.41028118133545, 7\n",
            "111, 1325, 7.438026428222656, 10\n",
            "90, 475, 8.213544845581055, 10\n",
            "225, 22, 7.92352294921875, 7\n",
            "187, 11, 8.365917205810547, 4\n",
            "118, 332, 5.628988265991211, 4\n",
            "35, 1824, 10.26064682006836, 9\n",
            "4, 4097, 4.967349529266357, 5\n",
            "92, 1665, 8.025949478149414, 5\n",
            "102, 358, 8.088505744934082, 8\n",
            "104, 5606, 8.55319881439209, 10\n",
            "44, 457, 7.237252235412598, 8\n",
            "97, 3489, 11.283546447753906, 7\n",
            "222, 2888, 8.713985443115234, 8\n",
            "173, 220, 8.964967727661133, 8\n",
            "80, 138, 6.906958103179932, 8\n",
            "47, 33, 7.606128692626953, 7\n",
            "20, 324, 6.247055530548096, 6\n",
            "162, 3764, 6.506863117218018, 8\n",
            "129, 10, 7.140838623046875, 7\n",
            "26, 244, 7.275918483734131, 9\n",
            "229, 569, 5.723085403442383, 5\n",
            "63, 473, 6.545492172241211, 5\n",
            "208, 789, 6.809391021728516, 4\n",
            "104, 110, 9.46371841430664, 9\n",
            "172, 5788, 7.297920227050781, 7\n",
            "172, 4586, 7.827518463134766, 8\n",
            "206, 2365, 6.20994758605957, 6\n",
            "53, 178, 9.57282543182373, 10\n",
            "37, 1754, 7.4543046951293945, 6\n",
            "219, 2504, 9.092041969299316, 9\n",
            "110, 220, 9.09472942352295, 10\n",
            "26, 212, 8.233223915100098, 7\n",
            "172, 5597, 6.996138572692871, 6\n",
            "68, 2860, 6.08549690246582, 4\n",
            "35, 4388, 8.84832763671875, 9\n",
            "173, 1666, 8.534616470336914, 6\n",
            "6, 744, 6.921299934387207, 9\n",
            "122, 894, 7.36627197265625, 9\n",
            "185, 2741, 8.449914932250977, 7\n",
            "115, 366, 6.950430870056152, 8\n",
            "191, 182, 6.961437702178955, 7\n",
            "223, 5534, 7.6901445388793945, 9\n",
            "44, 2, 9.378677368164062, 9\n",
            "111, 84, 5.827861785888672, 6\n",
            "7, 2711, 5.810251712799072, 7\n",
            "204, 26, 7.527101993560791, 7\n",
            "85, 4379, 7.411717414855957, 7\n",
            "193, 2876, 7.10057258605957, 7\n",
            "117, 272, 7.582764625549316, 7\n",
            "9, 1361, 8.405488014221191, 9\n",
            "156, 1758, 4.89373779296875, 4\n",
            "149, 2576, 6.9707512855529785, 6\n",
            "218, 716, 7.292050361633301, 6\n",
            "172, 1358, 7.322816848754883, 8\n",
            "218, 168, 6.713427543640137, 7\n",
            "105, 2190, 6.829833984375, 9\n",
            "107, 1776, 6.053708076477051, 7\n",
            "89, 78, 8.316473007202148, 9\n",
            "105, 3019, 6.028563022613525, 7\n",
            "166, 186, 8.341276168823242, 9\n",
            "188, 380, 7.1944260597229, 7\n",
            "167, 784, 7.8563079833984375, 7\n",
            "104, 5307, 8.706011772155762, 10\n",
            "153, 44, 8.190366744995117, 8\n",
            "149, 4265, 6.595322132110596, 5\n",
            "188, 2705, 7.867465496063232, 8\n",
            "202, 2445, 6.828534126281738, 6\n",
            "112, 80, 9.139610290527344, 7\n",
            "111, 280, 7.637090682983398, 7\n",
            "133, 121, 7.857954025268555, 6\n",
            "19, 375, 6.279025554656982, 5\n",
            "131, 1056, 6.611569881439209, 5\n",
            "148, 52, 8.00892162322998, 9\n",
            "94, 2477, 9.193130493164062, 8\n",
            "111, 1843, 5.834437370300293, 7\n",
            "89, 151, 7.370846748352051, 9\n",
            "162, 4486, 6.176429748535156, 7\n",
            "4, 161, 8.404824256896973, 7\n",
            "148, 449, 8.296014785766602, 8\n",
            "82, 113, 8.452207565307617, 7\n",
            "92, 99, 8.123312950134277, 8\n",
            "114, 430, 5.40478515625, 5\n",
            "114, 660, 7.256381988525391, 7\n",
            "16, 754, 6.6156463623046875, 5\n",
            "224, 1961, 7.452669620513916, 10\n",
            "144, 381, 6.548365592956543, 9\n",
            "172, 2145, 7.346736907958984, 8\n",
            "156, 718, 4.953086853027344, 3\n",
            "212, 1153, 5.598537921905518, 5\n",
            "198, 1316, 8.295188903808594, 8\n",
            "45, 403, 6.964839935302734, 8\n",
            "107, 72, 8.001482009887695, 9\n",
            "178, 4779, 6.909527778625488, 7\n",
            "194, 203, 8.026216506958008, 10\n",
            "59, 2752, 8.041998863220215, 9\n",
            "45, 369, 7.510530471801758, 7\n",
            "58, 790, 6.798140525817871, 6\n",
            "76, 4822, 6.167089939117432, 6\n",
            "164, 51, 8.05611515045166, 7\n",
            "143, 788, 7.069418430328369, 6\n",
            "21, 2375, 5.496541976928711, 4\n",
            "235, 1758, 5.7322821617126465, 6\n",
            "97, 3561, 9.347623825073242, 8\n",
            "168, 127, 7.04871940612793, 7\n",
            "176, 2554, 5.255573749542236, 6\n",
            "82, 754, 7.310984134674072, 7\n",
            "117, 2627, 6.604835510253906, 7\n",
            "0, 754, 6.7670183181762695, 6\n",
            "209, 236, 7.317127227783203, 7\n",
            "156, 2752, 6.829272270202637, 7\n",
            "184, 393, 9.014598846435547, 10\n",
            "230, 982, 6.0646867752075195, 4\n",
            "223, 3694, 6.405717849731445, 6\n",
            "133, 2591, 9.311457633972168, 8\n",
            "117, 744, 7.673353672027588, 9\n",
            "205, 3139, 6.935399055480957, 7\n",
            "23, 679, 6.7820940017700195, 2\n",
            "60, 1195, 8.97449779510498, 8\n",
            "137, 868, 7.521605014801025, 8\n",
            "21, 1057, 4.7225141525268555, 4\n",
            "117, 72, 9.79296875, 9\n",
            "163, 178, 6.925722599029541, 8\n",
            "162, 840, 7.9352521896362305, 8\n",
            "168, 12, 7.785370826721191, 6\n",
            "197, 4162, 7.404494285583496, 6\n",
            "172, 1291, 6.740900993347168, 5\n",
            "81, 2563, 5.997739791870117, 7\n",
            "157, 2741, 7.665370464324951, 10\n",
            "131, 22, 7.0750041007995605, 8\n",
            "187, 925, 6.588983535766602, 4\n",
            "39, 113, 8.259567260742188, 8\n",
            "125, 1450, 7.652997016906738, 9\n",
            "179, 221, 6.330526351928711, 7\n",
            "89, 358, 8.613614082336426, 6\n",
            "176, 846, 5.917468070983887, 7\n",
            "100, 1134, 7.49143648147583, 9\n",
            "163, 840, 7.09105110168457, 5\n",
            "178, 2408, 6.603343486785889, 6\n",
            "151, 1910, 6.4654154777526855, 6\n",
            "162, 1076, 6.093138694763184, 7\n",
            "146, 117, 8.357755661010742, 8\n",
            "130, 207, 6.747056007385254, 7\n",
            "73, 784, 7.047055721282959, 8\n",
            "32, 72, 9.034622192382812, 9\n",
            "156, 2352, 6.406238079071045, 7\n",
            "219, 1448, 8.100016593933105, 8\n",
            "172, 1004, 5.705975532531738, 6\n",
            "93, 457, 6.981112003326416, 8\n",
            "168, 4572, 6.322272777557373, 5\n",
            "148, 227, 6.537398815155029, 7\n",
            "174, 353, 8.8718900680542, 8\n",
            "111, 3466, 6.574090957641602, 7\n",
            "117, 1558, 7.981518745422363, 10\n",
            "226, 3448, 7.348732948303223, 7\n",
            "104, 5514, 6.7154436111450195, 8\n",
            "204, 2500, 8.837909698486328, 9\n",
            "218, 244, 6.810206413269043, 7\n",
            "24, 4153, 8.742903709411621, 10\n",
            "39, 163, 9.265973091125488, 8\n",
            "23, 178, 8.489631652832031, 10\n",
            "188, 1490, 5.411729335784912, 2\n",
            "156, 429, 6.3397417068481445, 3\n",
            "162, 1726, 7.371975898742676, 7\n",
            "151, 947, 7.1039838790893555, 7\n",
            "1, 3064, 6.349486351013184, 7\n",
            "111, 3845, 7.662801742553711, 7\n",
            "109, 470, 7.794577598571777, 4\n",
            "157, 3191, 5.925253868103027, 8\n",
            "89, 4330, 10.04704761505127, 10\n",
            "26, 100, 8.749846458435059, 6\n",
            "73, 2014, 5.247634410858154, 6\n",
            "76, 647, 6.93981409072876, 10\n",
            "22, 1342, 7.672009468078613, 8\n",
            "31, 2614, 8.2758207321167, 6\n",
            "118, 3413, 7.776335716247559, 8\n",
            "184, 358, 7.784036636352539, 8\n",
            "167, 335, 6.791194915771484, 10\n",
            "229, 1301, 7.34632682800293, 7\n",
            "171, 70, 8.000082969665527, 6\n",
            "163, 375, 5.949444770812988, 6\n",
            "47, 338, 8.146917343139648, 9\n",
            "114, 1683, 7.6673264503479, 6\n",
            "134, 5027, 4.962230205535889, 6\n",
            "65, 1627, 8.80199909210205, 10\n",
            "61, 201, 8.373977661132812, 9\n",
            "104, 2266, 8.70407485961914, 8\n",
            "190, 3425, 5.313190460205078, 7\n",
            "148, 3409, 7.481019973754883, 7\n",
            "151, 201, 7.303619861602783, 10\n",
            "163, 249, 6.504694938659668, 6\n",
            "81, 1355, 5.322552680969238, 6\n",
            "191, 790, 6.252686500549316, 6\n",
            "81, 1453, 6.996173858642578, 6\n",
            "122, 23, 7.389535903930664, 9\n",
            "115, 166, 6.019692420959473, 8\n",
            "147, 2407, 8.009712219238281, 8\n",
            "103, 98, 7.72490930557251, 9\n",
            "138, 200, 7.7518439292907715, 9\n",
            "148, 2646, 6.798559188842773, 6\n",
            "183, 28, 8.490358352661133, 9\n",
            "108, 41, 7.724512100219727, 9\n",
            "196, 1340, 8.29670524597168, 7\n",
            "90, 2576, 9.190683364868164, 8\n",
            "149, 3381, 5.945605278015137, 6\n",
            "118, 171, 6.686828136444092, 8\n",
            "61, 2980, 6.015659332275391, 7\n",
            "213, 1185, 8.167448043823242, 8\n",
            "230, 76, 6.547632217407227, 8\n",
            "146, 212, 8.071616172790527, 9\n",
            "111, 799, 5.9150614738464355, 7\n",
            "83, 640, 7.680108070373535, 10\n",
            "150, 353, 7.683696746826172, 9\n",
            "15, 5691, 8.995243072509766, 9\n",
            "73, 392, 6.768571853637695, 9\n",
            "6, 746, 8.478363037109375, 10\n",
            "75, 2319, 6.588405609130859, 8\n",
            "193, 4330, 8.277931213378906, 9\n",
            "118, 520, 5.242020606994629, 5\n",
            "36, 794, 7.230319976806641, 7\n",
            "223, 4076, 6.249926567077637, 7\n",
            "27, 1064, 8.70927619934082, 7\n",
            "75, 2641, 6.522884368896484, 4\n",
            "33, 907, 8.36376953125, 8\n",
            "118, 206, 4.516543865203857, 6\n",
            "42, 1018, 6.505413055419922, 9\n",
            "164, 609, 7.083264350891113, 7\n",
            "33, 135, 7.720758438110352, 5\n",
            "225, 2798, 7.383316516876221, 8\n",
            "156, 91, 7.217092514038086, 8\n",
            "157, 3127, 5.903168678283691, 6\n",
            "144, 3, 8.687549591064453, 7\n",
            "118, 2283, 5.303229808807373, 8\n",
            "33, 445, 8.286553382873535, 9\n",
            "107, 3305, 6.594362258911133, 7\n",
            "74, 73, 6.519036293029785, 7\n",
            "123, 446, 5.081961154937744, 6\n",
            "70, 404, 8.034980773925781, 9\n",
            "7, 804, 5.460434436798096, 4\n",
            "47, 101, 7.045639514923096, 8\n",
            "162, 3628, 7.153103351593018, 9\n",
            "148, 77, 7.127031326293945, 9\n",
            "124, 4051, 7.8403425216674805, 9\n",
            "175, 2165, 6.903284072875977, 9\n",
            "75, 549, 7.287352085113525, 7\n",
            "153, 25, 8.978872299194336, 9\n",
            "149, 3187, 7.1307477951049805, 7\n",
            "216, 77, 7.2019147872924805, 5\n",
            "149, 3153, 7.577333450317383, 6\n",
            "176, 451, 5.984794616699219, 1\n",
            "99, 2056, 9.095900535583496, 8\n",
            "168, 2748, 6.517786026000977, 5\n",
            "226, 3484, 9.115306854248047, 10\n",
            "0, 220, 8.367615699768066, 9\n",
            "163, 1152, 5.298148155212402, 7\n",
            "111, 217, 7.353859901428223, 9\n",
            "149, 4289, 6.580638408660889, 5\n",
            "43, 1222, 5.189477920532227, 7\n",
            "15, 704, 8.044231414794922, 7\n",
            "6, 2122, 7.165046691894531, 6\n",
            "147, 243, 7.385214805603027, 7\n",
            "156, 5557, 4.475359916687012, 6\n",
            "226, 73, 7.120418548583984, 5\n",
            "179, 1590, 7.507486343383789, 8\n",
            "89, 3522, 7.838629722595215, 7\n",
            "104, 5735, 8.89222526550293, 8\n",
            "222, 2852, 8.095215797424316, 8\n",
            "210, 2954, 9.488632202148438, 9\n",
            "111, 3049, 6.8590779304504395, 9\n",
            "213, 238, 8.981229782104492, 10\n",
            "28, 242, 6.663956642150879, 7\n",
            "221, 72, 8.777235984802246, 9\n",
            "156, 2963, 5.510046005249023, 3\n",
            "111, 3818, 5.377742767333984, 6\n",
            "162, 3350, 8.690621376037598, 9\n",
            "58, 1815, 9.068204879760742, 10\n",
            "192, 1453, 8.038641929626465, 8\n",
            "134, 4732, 5.878789901733398, 5\n",
            "175, 4334, 6.6802496910095215, 9\n",
            "210, 3769, 9.20566177368164, 9\n",
            "146, 2395, 5.869682788848877, 4\n",
            "108, 3079, 6.514095306396484, 8\n",
            "230, 2750, 7.939787864685059, 7\n",
            "84, 0, 9.02330207824707, 10\n",
            "36, 323, 7.600146770477295, 4\n",
            "96, 1729, 6.707164764404297, 9\n",
            "190, 1121, 6.611697196960449, 9\n",
            "171, 2951, 6.242245674133301, 7\n",
            "36, 2439, 8.168895721435547, 8\n",
            "172, 5378, 6.5189361572265625, 6\n",
            "149, 11, 8.041160583496094, 8\n",
            "210, 239, 9.867415428161621, 9\n",
            "89, 226, 8.478511810302734, 10\n",
            "228, 676, 6.090022563934326, 7\n",
            "89, 4669, 8.756705284118652, 10\n",
            "163, 1075, 7.513855934143066, 5\n",
            "148, 1569, 7.322173595428467, 4\n",
            "163, 672, 5.745641708374023, 7\n",
            "61, 2270, 7.787219524383545, 8\n",
            "109, 295, 7.8282036781311035, 9\n",
            "234, 100, 8.340339660644531, 8\n",
            "206, 178, 7.39461088180542, 8\n",
            "81, 3448, 6.865401744842529, 6\n",
            "57, 2710, 7.338259696960449, 7\n",
            "220, 2504, 8.205448150634766, 9\n",
            "63, 64, 7.803542137145996, 9\n",
            "68, 3669, 7.355827331542969, 10\n",
            "4, 1766, 9.357973098754883, 7\n",
            "89, 4028, 9.05212688446045, 8\n",
            "7, 2479, 6.128170013427734, 5\n",
            "124, 427, 9.760740280151367, 9\n",
            "206, 1947, 5.858631134033203, 6\n",
            "82, 2675, 7.381769180297852, 8\n",
            "81, 2642, 6.981564521789551, 6\n",
            "157, 1001, 7.350339889526367, 6\n",
            "183, 53, 7.588233947753906, 9\n",
            "188, 2739, 6.960268020629883, 8\n",
            "114, 1999, 8.084359169006348, 7\n",
            "222, 3298, 8.168145179748535, 7\n",
            "7, 2986, 7.056683540344238, 8\n",
            "216, 537, 7.047578811645508, 9\n",
            "115, 40, 5.563917636871338, 8\n",
            "179, 1911, 6.989577293395996, 6\n",
            "174, 1820, 8.536077499389648, 8\n",
            "226, 4869, 8.75017261505127, 10\n",
            "118, 212, 7.406229496002197, 8\n",
            "57, 230, 6.746372222900391, 6\n",
            "168, 1698, 6.333093166351318, 5\n",
            "6, 750, 8.199051856994629, 7\n",
            "122, 526, 8.158519744873047, 10\n",
            "149, 2541, 6.757320404052734, 6\n",
            "202, 344, 7.128723621368408, 6\n",
            "163, 1072, 5.342473983764648, 5\n",
            "128, 96, 6.43322229385376, 8\n",
            "104, 789, 8.221223831176758, 5\n",
            "171, 1064, 8.327991485595703, 8\n",
            "123, 1145, 5.23475456237793, 4\n",
            "81, 4361, 5.596895694732666, 6\n",
            "57, 1774, 7.279263019561768, 6\n",
            "167, 1803, 5.8381218910217285, 5\n",
            "118, 4548, 6.006223201751709, 8\n",
            "172, 4162, 6.921347618103027, 8\n",
            "1, 3677, 9.62844467163086, 7\n",
            "53, 1365, 7.370882987976074, 7\n",
            "172, 2852, 6.584349632263184, 7\n",
            "61, 3263, 6.784785747528076, 7\n",
            "190, 2566, 7.286199569702148, 8\n",
            "104, 548, 8.958803176879883, 8\n",
            "212, 5777, 7.972478866577148, 7\n",
            "0, 23, 7.8875017166137695, 9\n",
            "42, 678, 8.299975395202637, 9\n",
            "111, 5484, 8.761874198913574, 9\n",
            "111, 4883, 6.895216941833496, 6\n",
            "162, 2992, 8.333724975585938, 9\n",
            "151, 11, 8.338528633117676, 8\n",
            "78, 568, 8.595954895019531, 9\n",
            "27, 4036, 7.171677112579346, 9\n",
            "15, 5427, 8.646162033081055, 8\n",
            "172, 3281, 8.090264320373535, 8\n",
            "99, 2855, 8.272127151489258, 8\n",
            "166, 1666, 7.613201141357422, 9\n",
            "220, 403, 6.744848728179932, 7\n",
            "134, 5473, 5.771249771118164, 6\n",
            "123, 799, 5.648884296417236, 6\n",
            "94, 409, 7.7135210037231445, 7\n",
            "24, 138, 7.464765548706055, 9\n",
            "186, 498, 8.555102348327637, 7\n",
            "111, 2192, 7.344150543212891, 5\n",
            "165, 156, 6.065638542175293, 7\n",
            "61, 2599, 7.923258304595947, 8\n",
            "149, 4034, 7.168831825256348, 9\n",
            "183, 77, 6.764248371124268, 7\n",
            "107, 3514, 6.789422035217285, 7\n",
            "210, 202, 7.524433135986328, 9\n",
            "212, 5299, 6.805566787719727, 7\n",
            "179, 2029, 9.223471641540527, 8\n",
            "156, 3127, 4.925743579864502, 7\n",
            "107, 4651, 7.9521684646606445, 7\n",
            "151, 851, 7.518773555755615, 4\n",
            "168, 413, 6.136930465698242, 9\n",
            "66, 675, 6.7560930252075195, 8\n",
            "6, 6, 8.500088691711426, 6\n",
            "151, 3281, 6.384721755981445, 9\n",
            "118, 126, 6.422884464263916, 8\n",
            "193, 3101, 6.636975288391113, 6\n",
            "137, 2017, 8.636751174926758, 9\n",
            "197, 3434, 10.607210159301758, 7\n",
            "104, 1003, 9.02284049987793, 10\n",
            "122, 1263, 5.902926445007324, 6\n",
            "173, 4277, 8.681485176086426, 9\n",
            "167, 638, 5.503388404846191, 7\n",
            "162, 263, 5.589260101318359, 6\n",
            "16, 20, 7.55354118347168, 10\n",
            "172, 112, 7.323140621185303, 6\n",
            "76, 214, 6.974767208099365, 8\n",
            "72, 429, 7.695627212524414, 6\n",
            "216, 478, 6.844250679016113, 8\n",
            "118, 142, 6.755532264709473, 6\n",
            "66, 1179, 4.574161052703857, 7\n",
            "222, 2796, 7.617555618286133, 8\n",
            "152, 195, 8.410097122192383, 9\n",
            "156, 2229, 6.769580841064453, 7\n",
            "168, 4498, 6.107029438018799, 6\n",
            "172, 48, 7.37994384765625, 7\n",
            "168, 4687, 5.475024223327637, 5\n",
            "148, 2750, 8.15575885772705, 6\n",
            "89, 4189, 8.870192527770996, 8\n",
            "59, 114, 10.11984920501709, 9\n",
            "107, 1771, 8.606545448303223, 9\n",
            "178, 3281, 7.1915483474731445, 9\n",
            "10, 2622, 7.880613327026367, 8\n",
            "118, 3060, 8.36812686920166, 8\n",
            "122, 199, 7.166810512542725, 8\n",
            "147, 375, 5.411434650421143, 6\n",
            "107, 2839, 6.662017822265625, 6\n",
            "147, 58, 5.7213850021362305, 5\n",
            "1, 1048, 4.5600409507751465, 5\n",
            "171, 3608, 5.598749160766602, 7\n",
            "134, 4204, 6.1548991203308105, 5\n",
            "27, 111, 6.706988334655762, 7\n",
            "190, 184, 7.490976810455322, 6\n",
            "111, 883, 8.004265785217285, 7\n",
            "31, 2650, 7.886284828186035, 6\n",
            "149, 840, 7.297032356262207, 7\n",
            "173, 2125, 7.637813568115234, 6\n",
            "111, 1005, 6.41413688659668, 7\n",
            "106, 244, 6.232222557067871, 8\n",
            "174, 1088, 7.0776567459106445, 8\n",
            "72, 716, 6.441658020019531, 6\n",
            "66, 643, 6.207061290740967, 6\n",
            "56, 870, 7.3305158615112305, 7\n",
            "190, 264, 7.1084136962890625, 7\n",
            "152, 1950, 8.81764030456543, 7\n",
            "210, 1055, 6.867984771728516, 9\n",
            "172, 2160, 6.956002235412598, 8\n",
            "174, 31, 7.034257411956787, 6\n",
            "9, 110, 7.779195785522461, 8\n",
            "202, 2724, 7.242311477661133, 7\n",
            "168, 3727, 6.262841701507568, 5\n",
            "81, 3139, 7.372101783752441, 6\n",
            "56, 1940, 7.377905368804932, 8\n",
            "81, 3449, 6.281635284423828, 6\n",
            "76, 202, 7.275365829467773, 7\n",
            "19, 1352, 6.0377912521362305, 2\n",
            "81, 144, 7.546921730041504, 8\n",
            "31, 2320, 6.319094657897949, 8\n",
            "4, 238, 9.02273178100586, 8\n",
            "149, 4134, 4.922890663146973, 6\n",
            "156, 3979, 5.291029453277588, 8\n",
            "6, 22, 7.26676082611084, 7\n",
            "110, 202, 7.127614974975586, 9\n",
            "82, 5422, 6.169698715209961, 8\n",
            "234, 41, 7.053689002990723, 6\n",
            "89, 3191, 8.299084663391113, 8\n",
            "151, 1815, 8.037859916687012, 9\n",
            "7, 185, 7.56213903427124, 9\n",
            "226, 724, 7.199319839477539, 6\n",
            "167, 1151, 4.990604400634766, 4\n",
            "149, 1388, 6.7581706047058105, 9\n",
            "164, 10, 8.533829689025879, 7\n",
            "187, 4332, 6.988497734069824, 9\n",
            "36, 4640, 8.389381408691406, 8\n",
            "167, 767, 5.741296291351318, 8\n",
            "89, 39, 8.22712230682373, 5\n",
            "35, 1815, 9.227557182312012, 8\n",
            "41, 266, 5.151646614074707, 6\n",
            "39, 42, 7.445197105407715, 8\n",
            "37, 11, 9.282679557800293, 10\n",
            "94, 3049, 7.867295265197754, 9\n",
            "172, 5725, 5.6406168937683105, 8\n",
            "79, 21, 6.4247026443481445, 4\n",
            "163, 809, 7.626920700073242, 7\n",
            "58, 279, 8.381951332092285, 7\n",
            "114, 605, 7.557601451873779, 4\n",
            "156, 5764, 6.340076923370361, 8\n",
            "180, 825, 8.371744155883789, 7\n",
            "24, 578, 9.356459617614746, 10\n",
            "4, 45, 7.390126705169678, 6\n",
            "74, 1346, 7.140442848205566, 7\n",
            "137, 1539, 7.788075923919678, 9\n",
            "149, 199, 6.81903076171875, 8\n",
            "221, 758, 8.055037498474121, 7\n",
            "191, 1041, 6.156166076660156, 6\n",
            "15, 4265, 8.014795303344727, 7\n",
            "44, 874, 8.655176162719727, 7\n",
            "153, 3380, 8.441606521606445, 8\n",
            "228, 150, 7.416875839233398, 9\n",
            "156, 124, 6.8407392501831055, 7\n",
            "149, 3945, 5.952619552612305, 8\n",
            "197, 3855, 6.7891082763671875, 7\n",
            "213, 114, 9.343367576599121, 9\n",
            "124, 35, 8.467198371887207, 8\n",
            "24, 4328, 7.821431636810303, 9\n",
            "156, 2816, 4.645269870758057, 7\n",
            "111, 4555, 5.877492904663086, 7\n",
            "156, 5655, 6.278913974761963, 7\n",
            "156, 2040, 5.789018630981445, 8\n",
            "111, 4499, 9.062368392944336, 9\n",
            "89, 545, 8.541268348693848, 8\n",
            "233, 3384, 7.261092662811279, 4\n",
            "96, 659, 8.537482261657715, 8\n",
            "89, 4244, 7.6413984298706055, 9\n",
            "111, 1887, 5.954538822174072, 7\n",
            "219, 4228, 8.109485626220703, 9\n",
            "102, 25, 10.11769962310791, 5\n",
            "218, 654, 7.469771385192871, 8\n",
            "81, 2448, 7.622891902923584, 6\n",
            "89, 462, 7.1750383377075195, 7\n",
            "175, 2113, 8.285454750061035, 8\n",
            "118, 1388, 6.900235176086426, 8\n",
            "86, 1773, 6.414289951324463, 8\n",
            "56, 734, 8.090449333190918, 5\n",
            "110, 232, 6.360795974731445, 6\n",
            "201, 795, 6.871011734008789, 6\n",
            "174, 1254, 7.564001560211182, 8\n",
            "180, 730, 6.957816123962402, 7\n",
            "175, 784, 8.500299453735352, 10\n",
            "148, 2107, 7.875185966491699, 7\n",
            "81, 5773, 7.219682693481445, 9\n",
            "0, 189, 5.980523109436035, 4\n",
            "97, 3471, 9.408258438110352, 8\n",
            "114, 132, 5.39530611038208, 7\n",
            "210, 419, 7.7269439697265625, 7\n",
            "75, 825, 7.900402069091797, 8\n",
            "111, 3344, 7.83148193359375, 9\n",
            "1, 2852, 6.970361232757568, 7\n",
            "6, 1643, 6.146722316741943, 7\n",
            "149, 449, 7.193808555603027, 7\n",
            "212, 3801, 5.497089385986328, 6\n",
            "104, 899, 8.358418464660645, 9\n",
            "162, 2219, 7.691337585449219, 7\n",
            "119, 5287, 8.350759506225586, 8\n",
            "171, 146, 7.264944553375244, 8\n",
            "89, 423, 9.150127410888672, 9\n",
            "151, 2591, 8.238075256347656, 9\n",
            "27, 2373, 7.0196309089660645, 7\n",
            "219, 3701, 8.952315330505371, 9\n",
            "107, 1032, 7.951138496398926, 7\n",
            "118, 2113, 7.739729404449463, 9\n",
            "226, 4616, 8.7478666305542, 9\n",
            "148, 57, 8.400186538696289, 10\n",
            "21, 2144, 5.786534309387207, 4\n",
            "234, 3169, 7.364513397216797, 7\n",
            "168, 2513, 7.76612663269043, 6\n",
            "104, 827, 9.228986740112305, 8\n",
            "112, 4785, 8.025464057922363, 7\n",
            "112, 5460, 8.76229476928711, 9\n",
            "27, 3955, 7.522892951965332, 7\n",
            "99, 4330, 9.298332214355469, 9\n",
            "223, 5366, 7.119222640991211, 8\n",
            "223, 3520, 5.893349647521973, 7\n",
            "162, 674, 5.632923603057861, 5\n",
            "230, 744, 6.447896957397461, 6\n",
            "61, 1446, 7.193303108215332, 7\n",
            "197, 141, 9.091915130615234, 10\n",
            "59, 245, 8.25207233428955, 8\n",
            "90, 2592, 7.728168487548828, 9\n",
            "118, 3350, 7.980739593505859, 10\n",
            "168, 639, 6.743453025817871, 7\n",
            "41, 180, 5.3144097328186035, 5\n",
            "107, 2915, 8.541184425354004, 8\n",
            "190, 1442, 7.483935356140137, 5\n",
            "93, 428, 8.455202102661133, 9\n",
            "174, 254, 7.707467555999756, 7\n",
            "153, 401, 8.928882598876953, 7\n",
            "81, 5594, 7.517226696014404, 9\n",
            "54, 1343, 7.333697319030762, 7\n",
            "81, 1792, 7.061176776885986, 8\n",
            "128, 146, 7.485434532165527, 8\n",
            "81, 2880, 7.0886549949646, 6\n",
            "222, 1379, 7.120287895202637, 9\n",
            "28, 1006, 6.014959335327148, 4\n",
            "148, 3064, 6.864223480224609, 9\n",
            "4, 2155, 7.769260406494141, 9\n",
            "233, 5195, 7.071507453918457, 7\n",
            "39, 238, 8.99786376953125, 8\n",
            "168, 4800, 5.021809101104736, 6\n",
            "190, 526, 7.474607467651367, 8\n",
            "111, 4578, 5.955992698669434, 7\n",
            "219, 4388, 8.248968124389648, 9\n",
            "224, 345, 7.38287353515625, 8\n",
            "151, 1338, 5.765383720397949, 7\n",
            "7, 1325, 7.390982627868652, 7\n",
            "81, 3127, 6.035723686218262, 6\n",
            "118, 780, 5.32261848449707, 3\n",
            "191, 697, 7.851433753967285, 7\n",
            "230, 30, 7.8761396408081055, 8\n",
            "155, 2628, 8.373947143554688, 7\n",
            "4, 5, 8.510597229003906, 7\n",
            "199, 365, 8.068964004516602, 6\n",
            "6, 2293, 4.586226463317871, 5\n",
            "199, 1564, 7.604611396789551, 6\n",
            "139, 3663, 7.951148986816406, 7\n",
            "191, 3370, 7.069902420043945, 6\n",
            "89, 3866, 8.906035423278809, 10\n",
            "122, 397, 7.897479057312012, 8\n",
            "122, 478, 7.080275058746338, 8\n",
            "118, 218, 6.025528907775879, 8\n",
            "118, 3925, 5.948513984680176, 7\n",
            "222, 1325, 7.910245418548584, 9\n",
            "88, 1330, 8.115511894226074, 9\n",
            "178, 5606, 5.745438575744629, 8\n",
            "104, 3168, 8.217230796813965, 9\n",
            "35, 550, 7.407701015472412, 7\n",
            "32, 366, 9.779104232788086, 10\n",
            "94, 212, 8.94866943359375, 9\n",
            "181, 660, 8.80571460723877, 9\n",
            "213, 647, 8.056412696838379, 8\n",
            "7, 14, 6.977478981018066, 7\n",
            "174, 954, 6.672512531280518, 8\n",
            "156, 175, 6.399991989135742, 7\n",
            "191, 1143, 8.457352638244629, 7\n",
            "162, 3530, 7.678394317626953, 7\n",
            "133, 1301, 8.035399436950684, 9\n",
            "129, 1346, 6.456175804138184, 7\n",
            "111, 2154, 7.123021125793457, 9\n",
            "235, 628, 4.776910781860352, 1\n",
            "12, 166, 7.18994140625, 8\n",
            "89, 234, 7.086531162261963, 8\n",
            "146, 643, 6.440674304962158, 7\n",
            "133, 180, 7.218021869659424, 8\n",
            "111, 918, 7.457734107971191, 7\n",
            "98, 0, 9.075628280639648, 10\n",
            "170, 491, 8.576666831970215, 8\n",
            "81, 5395, 7.706275939941406, 6\n",
            "117, 131, 8.360899925231934, 10\n",
            "85, 5768, 8.404903411865234, 7\n",
            "133, 775, 8.404186248779297, 8\n",
            "190, 3045, 5.273637294769287, 8\n",
            "168, 2354, 6.570960521697998, 7\n",
            "157, 242, 7.002340316772461, 9\n",
            "186, 2352, 7.575504302978516, 7\n",
            "83, 613, 7.7368364334106445, 10\n",
            "89, 1092, 7.168956279754639, 7\n",
            "179, 200, 6.244264125823975, 6\n",
            "107, 3348, 7.197676658630371, 7\n",
            "149, 112, 6.6480255126953125, 6\n",
            "187, 316, 6.59953498840332, 6\n",
            "229, 286, 7.161309719085693, 8\n",
            "231, 1379, 7.024565696716309, 7\n",
            "149, 957, 7.229768753051758, 7\n",
            "59, 342, 7.920204162597656, 7\n",
            "85, 5723, 6.815547943115234, 6\n",
            "27, 235, 5.541265487670898, 7\n",
            "24, 505, 7.1892476081848145, 9\n",
            "149, 2121, 7.630943775177002, 4\n",
            "6, 175, 7.534828186035156, 7\n",
            "31, 680, 6.140316486358643, 7\n",
            "220, 115, 8.389215469360352, 9\n",
            "226, 5285, 8.969707489013672, 7\n",
            "32, 15, 9.311193466186523, 8\n",
            "162, 3490, 6.955597400665283, 7\n",
            "134, 2738, 5.467606067657471, 8\n",
            "74, 88, 6.908112049102783, 7\n",
            "117, 53, 10.110835075378418, 10\n",
            "0, 244, 6.855945587158203, 9\n",
            "89, 1683, 8.698078155517578, 8\n",
            "9, 118, 7.358730792999268, 7\n",
            "168, 11, 7.920956611633301, 7\n",
            "223, 5055, 7.6455979347229, 9\n",
            "156, 4243, 6.8094658851623535, 7\n",
            "83, 420, 8.136083602905273, 9\n",
            "60, 374, 7.521146774291992, 10\n",
            "110, 114, 9.223288536071777, 8\n",
            "224, 3300, 8.99304485321045, 9\n",
            "57, 536, 6.692571640014648, 7\n",
            "212, 5664, 6.137317657470703, 7\n",
            "118, 542, 5.731799125671387, 7\n",
            "107, 3836, 7.548069953918457, 7\n",
            "111, 2372, 8.38174057006836, 5\n",
            "111, 5740, 6.837263584136963, 7\n",
            "111, 3315, 9.028892517089844, 9\n",
            "104, 4659, 9.10334587097168, 8\n",
            "168, 833, 5.341192245483398, 5\n",
            "211, 562, 6.667710781097412, 7\n",
            "153, 753, 8.832195281982422, 8\n",
            "68, 3081, 6.599644660949707, 5\n",
            "184, 134, 7.397451400756836, 7\n",
            "156, 2825, 6.225006580352783, 7\n",
            "111, 4722, 8.315690994262695, 6\n",
            "79, 526, 6.879446983337402, 8\n",
            "107, 4880, 7.021365165710449, 7\n",
            "180, 942, 7.805306434631348, 5\n",
            "66, 76, 6.815828800201416, 9\n",
            "196, 181, 9.11542797088623, 8\n",
            "172, 2641, 6.2645063400268555, 6\n",
            "74, 428, 7.370992660522461, 8\n",
            "81, 601, 6.70753288269043, 8\n",
            "161, 710, 8.958627700805664, 10\n",
            "152, 1343, 7.973377704620361, 8\n",
            "151, 1056, 5.963452339172363, 6\n",
            "97, 723, 11.768802642822266, 10\n",
            "117, 238, 10.276586532592773, 10\n",
            "151, 2679, 6.385324001312256, 6\n",
            "6, 1571, 6.425575256347656, 9\n",
            "87, 28, 8.126083374023438, 9\n",
            "133, 114, 9.389856338500977, 8\n",
            "148, 239, 9.240226745605469, 9\n",
            "229, 714, 5.6384735107421875, 5\n",
            "193, 3323, 7.842389106750488, 8\n",
            "36, 5169, 7.275651931762695, 8\n",
            "65, 127, 6.600656509399414, 2\n",
            "84, 358, 8.16362476348877, 7\n",
            "179, 4270, 8.595778465270996, 9\n",
            "171, 1539, 7.777672290802002, 8\n",
            "167, 1507, 6.841235160827637, 5\n",
            "190, 3139, 7.74174690246582, 6\n",
            "220, 507, 8.31406021118164, 8\n",
            "0, 137, 8.024333953857422, 9\n",
            "168, 145, 6.372941970825195, 6\n",
            "116, 127, 8.157052040100098, 9\n",
            "81, 2711, 6.197022438049316, 8\n",
            "206, 2579, 5.73294734954834, 8\n",
            "27, 2984, 6.217964172363281, 8\n",
            "190, 1225, 6.2926530838012695, 6\n",
            "89, 1146, 8.018251419067383, 7\n",
            "82, 115, 8.992990493774414, 10\n",
            "76, 477, 7.246794700622559, 7\n",
            "32, 1071, 7.243152618408203, 9\n",
            "218, 1018, 5.168394088745117, 7\n",
            "54, 80, 9.214887619018555, 3\n",
            "81, 4121, 6.703690528869629, 6\n",
            "151, 1284, 6.630573272705078, 7\n",
            "118, 2270, 6.441122055053711, 7\n",
            "162, 2752, 7.988164901733398, 9\n",
            "224, 633, 7.147009372711182, 6\n",
            "230, 83, 6.609002590179443, 8\n",
            "145, 52, 8.954729080200195, 6\n",
            "232, 1223, 7.108151435852051, 7\n",
            "117, 1330, 10.08208179473877, 10\n",
            "133, 1777, 8.02914047241211, 8\n",
            "74, 184, 7.198587894439697, 6\n",
            "197, 1943, 6.959011077880859, 10\n",
            "32, 1387, 8.212553024291992, 9\n",
            "122, 828, 6.219099998474121, 8\n",
            "138, 21, 8.540644645690918, 7\n",
            "196, 130, 9.837100982666016, 10\n",
            "143, 731, 6.62335205078125, 8\n",
            "168, 1400, 3.6844124794006348, 3\n",
            "205, 2776, 6.032181262969971, 6\n",
            "230, 427, 8.030412673950195, 7\n",
            "3, 2524, 9.135555267333984, 8\n",
            "89, 876, 7.981985092163086, 6\n",
            "82, 215, 7.694744110107422, 8\n",
            "138, 409, 8.756270408630371, 9\n",
            "18, 5364, 8.279560089111328, 10\n",
            "173, 3390, 6.980792999267578, 6\n",
            "192, 3765, 8.074722290039062, 8\n",
            "150, 22, 8.096620559692383, 9\n",
            "190, 637, 7.38227653503418, 7\n",
            "81, 5154, 6.9486846923828125, 7\n",
            "22, 750, 8.165642738342285, 8\n",
            "118, 2272, 6.788222312927246, 6\n",
            "163, 1301, 7.9377121925354, 6\n",
            "15, 3838, 7.660811424255371, 9\n",
            "156, 654, 6.428231716156006, 6\n",
            "194, 882, 7.821713924407959, 8\n",
            "61, 1930, 7.053536891937256, 6\n",
            "134, 5223, 4.413413047790527, 6\n",
            "86, 908, 8.46756649017334, 8\n",
            "38, 986, 8.588253021240234, 8\n",
            "111, 762, 8.092668533325195, 8\n",
            "96, 180, 6.730635166168213, 6\n",
            "188, 1683, 8.083203315734863, 6\n",
            "85, 3430, 8.050680160522461, 9\n",
            "173, 3035, 8.736894607543945, 8\n",
            "199, 30, 6.516233921051025, 6\n",
            "215, 51, 7.780783176422119, 9\n",
            "81, 3898, 7.7182183265686035, 6\n",
            "74, 1362, 6.395769119262695, 5\n",
            "81, 4835, 9.155869483947754, 9\n",
            "191, 178, 8.24799919128418, 6\n",
            "104, 183, 8.54106616973877, 10\n",
            "105, 1361, 8.583396911621094, 9\n",
            "170, 1276, 9.726470947265625, 7\n",
            "122, 445, 7.288961887359619, 8\n",
            "188, 36, 5.601749420166016, 7\n",
            "192, 2272, 8.13731861114502, 8\n",
            "160, 403, 6.365200042724609, 9\n",
            "32, 569, 8.845480918884277, 10\n",
            "96, 246, 5.1565985679626465, 8\n",
            "183, 202, 7.552381992340088, 8\n",
            "81, 5562, 6.360287666320801, 6\n",
            "11, 365, 8.278685569763184, 7\n",
            "111, 5786, 7.193115234375, 6\n",
            "185, 52, 8.041852951049805, 8\n",
            "44, 423, 9.19776439666748, 8\n",
            "95, 701, 7.929519176483154, 7\n",
            "74, 168, 6.381956577301025, 7\n",
            "230, 238, 9.004858016967773, 10\n",
            "96, 199, 8.120046615600586, 7\n",
            "94, 373, 7.804502964019775, 8\n",
            "151, 294, 6.404450416564941, 4\n",
            "206, 99, 8.525712013244629, 8\n",
            "73, 706, 4.170350551605225, 6\n",
            "128, 2639, 6.7063517570495605, 6\n",
            "39, 746, 9.29830551147461, 8\n",
            "149, 4944, 7.146828651428223, 7\n",
            "94, 143, 7.88408088684082, 7\n",
            "73, 532, 5.354061603546143, 7\n",
            "7, 156, 5.715204238891602, 6\n",
            "107, 1539, 7.970023155212402, 9\n",
            "104, 5414, 7.779376983642578, 10\n",
            "4, 286, 7.842268943786621, 7\n",
            "89, 2652, 7.074718475341797, 9\n",
            "28, 116, 8.985586166381836, 10\n",
            "148, 1554, 4.798110008239746, 2\n",
            "162, 1799, 6.718173027038574, 6\n",
            "69, 25, 8.672468185424805, 10\n",
            "165, 114, 8.779397964477539, 10\n",
            "11, 25, 9.151052474975586, 9\n",
            "73, 814, 5.3740949630737305, 6\n",
            "109, 4879, 7.725508689880371, 9\n",
            "162, 507, 7.856206893920898, 6\n",
            "2, 529, 6.33159875869751, 5\n",
            "55, 1658, 10.284050941467285, 10\n",
            "233, 3609, 7.224061965942383, 8\n",
            "111, 1481, 5.7769012451171875, 7\n",
            "148, 2354, 7.014290809631348, 7\n",
            "147, 24, 7.386232852935791, 10\n",
            "174, 138, 7.557425498962402, 8\n",
            "73, 682, 5.307697296142578, 9\n",
            "190, 1815, 8.121986389160156, 7\n",
            "73, 2227, 5.583678245544434, 7\n",
            "11, 163, 7.540131092071533, 8\n",
            "210, 1764, 9.215299606323242, 9\n",
            "198, 99, 8.934131622314453, 9\n",
            "148, 385, 7.040996074676514, 8\n",
            "193, 640, 7.706988334655762, 7\n",
            "118, 2026, 6.102038860321045, 7\n",
            "65, 4330, 8.530170440673828, 8\n",
            "38, 537, 8.969539642333984, 8\n",
            "124, 40, 7.238628387451172, 9\n",
            "186, 1167, 6.7516984939575195, 7\n",
            "234, 5307, 6.741774559020996, 8\n",
            "148, 157, 6.697124481201172, 7\n",
            "74, 643, 6.672853469848633, 9\n",
            "166, 1742, 7.290162086486816, 7\n",
            "220, 38, 8.769552230834961, 9\n",
            "232, 33, 7.716908931732178, 9\n",
            "76, 5300, 6.1222243309021, 6\n",
            "89, 981, 7.530950546264648, 8\n",
            "162, 5173, 8.663956642150879, 8\n",
            "111, 3779, 5.740984916687012, 7\n",
            "180, 1932, 6.776304244995117, 4\n",
            "166, 610, 7.223360061645508, 7\n",
            "216, 701, 8.011507034301758, 6\n",
            "81, 4734, 6.709988117218018, 7\n",
            "166, 145, 7.796342849731445, 7\n",
            "148, 1197, 8.925268173217773, 8\n",
            "172, 5408, 7.884416580200195, 6\n",
            "138, 792, 7.439549446105957, 8\n",
            "121, 244, 8.384556770324707, 8\n",
            "107, 1480, 7.767047882080078, 7\n",
            "22, 202, 7.608009338378906, 7\n",
            "104, 1634, 7.987376689910889, 9\n",
            "89, 989, 7.4982452392578125, 8\n",
            "47, 504, 5.9371538162231445, 9\n",
            "129, 750, 8.290898323059082, 10\n",
            "120, 116, 9.242645263671875, 10\n",
            "111, 101, 6.868335247039795, 9\n",
            "2, 245, 7.3653974533081055, 10\n",
            "173, 2541, 7.4859771728515625, 6\n",
            "149, 2868, 6.530113697052002, 2\n",
            "123, 743, 6.2642011642456055, 6\n",
            "153, 291, 8.938287734985352, 10\n",
            "149, 1950, 5.249660491943359, 7\n",
            "103, 46, 7.507049083709717, 7\n",
            "41, 6, 8.089866638183594, 9\n",
            "118, 4438, 6.618702411651611, 8\n",
            "172, 5362, 8.689108848571777, 8\n",
            "81, 3315, 8.224774360656738, 6\n",
            "212, 5597, 7.1472344398498535, 7\n",
            "75, 2748, 6.4940032958984375, 8\n",
            "125, 1358, 8.116799354553223, 9\n",
            "4, 4078, 7.595070838928223, 7\n",
            "209, 870, 8.066661834716797, 8\n",
            "81, 5371, 6.227863311767578, 7\n",
            "97, 1064, 9.606685638427734, 10\n",
            "89, 4247, 9.371623992919922, 10\n",
            "90, 1357, 7.698862075805664, 7\n",
            "149, 2629, 7.004863739013672, 10\n",
            "199, 876, 7.176320552825928, 5\n",
            "146, 604, 6.552309989929199, 7\n",
            "209, 292, 7.239050388336182, 5\n",
            "74, 891, 7.149078369140625, 6\n",
            "104, 2844, 8.84689712524414, 9\n",
            "165, 393, 8.2754487991333, 10\n",
            "151, 72, 7.814937591552734, 10\n",
            "20, 2156, 5.759751319885254, 6\n",
            "210, 561, 7.63394832611084, 8\n",
            "156, 4388, 6.913011074066162, 7\n",
            "124, 2, 9.392308235168457, 8\n",
            "6, 0, 8.205035209655762, 7\n",
            "149, 1342, 6.5575642585754395, 8\n",
            "107, 5287, 8.445002555847168, 7\n",
            "16, 759, 6.812519073486328, 5\n",
            "19, 1049, 6.215735912322998, 6\n",
            "42, 321, 8.908971786499023, 6\n",
            "223, 701, 8.631921768188477, 8\n",
            "81, 5130, 7.223783016204834, 7\n",
            "45, 1352, 7.609391689300537, 10\n",
            "122, 447, 7.389759063720703, 7\n",
            "168, 1427, 6.786665439605713, 4\n",
            "153, 2622, 9.51025104522705, 9\n",
            "90, 2269, 8.416146278381348, 9\n",
            "168, 4041, 5.865677833557129, 6\n",
            "185, 185, 8.285205841064453, 8\n",
            "111, 3883, 8.081016540527344, 8\n",
            "104, 3506, 9.120492935180664, 9\n",
            "191, 188, 6.8024749755859375, 6\n",
            "114, 14, 7.145018577575684, 7\n",
            "220, 484, 6.768655300140381, 8\n",
            "220, 175, 7.742445945739746, 7\n",
            "149, 2654, 6.868712425231934, 10\n",
            "185, 1330, 8.535489082336426, 7\n",
            "165, 825, 7.331836700439453, 9\n",
            "114, 317, 5.4776411056518555, 6\n",
            "156, 181, 7.656332492828369, 6\n",
            "134, 2017, 6.65358829498291, 5\n",
            "111, 3034, 6.703361511230469, 5\n",
            "125, 115, 8.67531681060791, 9\n",
            "168, 1718, 5.055469512939453, 6\n",
            "114, 1590, 7.314826011657715, 6\n",
            "68, 2664, 8.300579071044922, 10\n",
            "20, 3090, 6.2928314208984375, 8\n",
            "184, 498, 7.389666557312012, 10\n",
            "230, 145, 6.938736915588379, 8\n",
            "118, 2617, 6.871172904968262, 8\n",
            "226, 486, 7.883309841156006, 2\n",
            "121, 157, 7.19221830368042, 7\n",
            "213, 468, 8.62132453918457, 8\n",
            "231, 803, 7.8370561599731445, 5\n",
            "111, 480, 6.539945602416992, 7\n",
            "124, 156, 8.483756065368652, 9\n",
            "223, 839, 6.157810688018799, 4\n",
            "85, 5176, 8.407796859741211, 10\n",
            "27, 3254, 7.223777770996094, 5\n",
            "61, 1950, 6.456199645996094, 10\n",
            "81, 157, 6.714204788208008, 7\n",
            "209, 428, 6.757667541503906, 7\n",
            "89, 2270, 8.300612449645996, 9\n",
            "210, 965, 7.107277870178223, 7\n",
            "94, 3037, 8.790457725524902, 8\n",
            "90, 1467, 7.751825332641602, 9\n",
            "172, 5545, 6.460213661193848, 6\n",
            "7, 394, 7.033918380737305, 5\n",
            "91, 536, 8.721590995788574, 8\n",
            "111, 2031, 7.433018684387207, 6\n",
            "122, 99, 9.178916931152344, 7\n",
            "108, 308, 7.263021469116211, 5\n",
            "38, 1147, 7.267121315002441, 9\n",
            "56, 4415, 8.195478439331055, 8\n",
            "165, 811, 6.219609260559082, 4\n",
            "89, 298, 8.849477767944336, 10\n",
            "172, 2113, 8.518898010253906, 8\n",
            "196, 232, 6.7482500076293945, 6\n",
            "120, 604, 7.316070556640625, 7\n",
            "164, 1590, 8.872673988342285, 9\n",
            "148, 825, 7.8325629234313965, 9\n",
            "1, 117, 8.906396865844727, 8\n",
            "115, 87, 6.083461761474609, 8\n",
            "206, 1899, 6.836370468139648, 8\n",
            "162, 2696, 7.833347320556641, 9\n",
            "80, 197, 6.166387557983398, 7\n",
            "193, 4062, 7.116638660430908, 8\n",
            "108, 541, 8.084220886230469, 7\n",
            "94, 80, 8.857215881347656, 10\n",
            "131, 1480, 7.599493980407715, 5\n",
            "225, 10, 7.2265777587890625, 9\n",
            "7, 2517, 5.664764404296875, 5\n",
            "230, 1580, 6.174245357513428, 5\n",
            "133, 716, 7.995826721191406, 7\n",
            "97, 4088, 10.322755813598633, 9\n",
            "118, 356, 6.190088272094727, 6\n",
            "192, 2455, 9.437440872192383, 9\n",
            "229, 76, 6.771490097045898, 9\n",
            "74, 2650, 7.232430458068848, 6\n",
            "122, 647, 7.781957626342773, 7\n",
            "205, 356, 6.336876392364502, 5\n",
            "105, 2992, 7.969107151031494, 10\n",
            "117, 214, 9.671723365783691, 7\n",
            "86, 1815, 7.953001022338867, 9\n",
            "176, 437, 5.428816318511963, 8\n",
            "55, 215, 11.18783187866211, 10\n",
            "104, 195, 9.295391082763672, 8\n",
            "89, 3475, 10.3798189163208, 10\n",
            "111, 2688, 5.301857948303223, 8\n",
            "162, 2779, 8.83743667602539, 9\n",
            "97, 691, 11.164328575134277, 10\n",
            "89, 5, 8.649563789367676, 8\n",
            "5, 486, 9.278218269348145, 8\n",
            "128, 2407, 8.69542407989502, 10\n",
            "188, 2477, 8.390233039855957, 7\n",
            "73, 97, 6.187990188598633, 6\n",
            "162, 4288, 8.559865951538086, 9\n",
            "220, 217, 7.712156772613525, 8\n",
            "162, 3441, 6.9918413162231445, 8\n",
            "61, 2775, 8.411314010620117, 7\n",
            "188, 48, 7.46142578125, 8\n",
            "11, 216, 7.052791595458984, 6\n",
            "118, 106, 5.71650505065918, 5\n",
            "234, 4814, 5.670376777648926, 7\n",
            "210, 934, 6.803908348083496, 9\n",
            "111, 3365, 7.375509262084961, 7\n",
            "184, 5502, 6.384975433349609, 6\n",
            "156, 5657, 5.835680961608887, 7\n",
            "96, 498, 8.396736145019531, 9\n",
            "27, 163, 7.935916423797607, 8\n",
            "122, 158, 8.056923866271973, 9\n",
            "143, 4313, 7.213668346405029, 8\n",
            "197, 3728, 8.230947494506836, 7\n",
            "89, 967, 7.372919082641602, 8\n",
            "151, 51, 7.598187446594238, 7\n",
            "201, 5261, 8.129996299743652, 5\n",
            "129, 445, 6.886415004730225, 8\n",
            "31, 233, 6.76853609085083, 7\n",
            "22, 2649, 6.868890762329102, 7\n",
            "234, 53, 7.227685928344727, 10\n",
            "63, 901, 6.922615051269531, 9\n",
            "136, 426, 6.580389022827148, 7\n",
            "174, 327, 6.00018310546875, 8\n",
            "185, 0, 9.005608558654785, 7\n",
            "112, 3148, 8.274642944335938, 7\n",
            "97, 3810, 7.176538944244385, 8\n",
            "190, 804, 6.091827392578125, 7\n",
            "10, 338, 9.034394264221191, 8\n",
            "233, 322, 7.0466108322143555, 6\n",
            "78, 691, 10.20810317993164, 10\n",
            "168, 3280, 6.292054176330566, 5\n",
            "89, 484, 7.328890323638916, 7\n",
            "233, 756, 5.647000312805176, 4\n",
            "191, 81, 7.131346702575684, 9\n",
            "111, 1306, 7.624598503112793, 9\n",
            "190, 1770, 6.259394645690918, 6\n",
            "134, 5362, 7.880688190460205, 6\n",
            "199, 2486, 6.368841171264648, 7\n",
            "172, 5707, 6.072751998901367, 7\n",
            "172, 2391, 6.1180644035339355, 6\n",
            "206, 1965, 5.938196182250977, 6\n",
            "79, 419, 6.110957622528076, 7\n",
            "27, 3998, 8.805315971374512, 8\n",
            "111, 2122, 7.45429801940918, 10\n",
            "212, 2134, 7.116091728210449, 6\n",
            "213, 491, 8.704581260681152, 8\n",
            "149, 5126, 7.2521281242370605, 7\n",
            "57, 1055, 6.322144508361816, 7\n",
            "16, 194, 6.624434471130371, 9\n",
            "229, 1573, 7.255812644958496, 5\n",
            "32, 1067, 8.420966148376465, 8\n",
            "4, 199, 7.674703598022461, 9\n",
            "164, 2140, 6.001463413238525, 8\n",
            "111, 676, 6.406112194061279, 8\n",
            "172, 5556, 8.011443138122559, 8\n",
            "202, 643, 7.820075988769531, 9\n",
            "129, 772, 7.815512180328369, 6\n",
            "231, 1072, 6.4268693923950195, 6\n",
            "186, 1144, 7.841186046600342, 8\n",
            "118, 158, 7.7997283935546875, 6\n",
            "172, 2235, 6.94643497467041, 7\n",
            "121, 2828, 8.052416801452637, 7\n",
            "176, 882, 6.174335479736328, 5\n",
            "111, 5510, 6.637931823730469, 6\n",
            "118, 1726, 6.894393444061279, 8\n",
            "118, 647, 7.251703262329102, 4\n",
            "146, 602, 7.493402481079102, 4\n",
            "90, 502, 8.155720710754395, 9\n",
            "99, 139, 7.560947418212891, 7\n",
            "208, 1378, 6.869978904724121, 7\n",
            "124, 296, 7.751424789428711, 7\n",
            "220, 1792, 6.657166481018066, 8\n",
            "66, 311, 5.145346164703369, 6\n",
            "197, 53, 8.627429008483887, 9\n",
            "65, 2347, 7.152543544769287, 7\n",
            "37, 4219, 6.3869309425354, 9\n",
            "166, 370, 7.473147869110107, 8\n",
            "31, 127, 7.4014739990234375, 8\n",
            "149, 2269, 6.987540245056152, 8\n",
            "175, 824, 7.365412712097168, 9\n",
            "90, 2375, 8.431049346923828, 7\n",
            "65, 4870, 5.21723747253418, 7\n",
            "118, 2959, 7.4912109375, 7\n",
            "73, 872, 5.858545303344727, 7\n",
            "79, 239, 9.07192325592041, 9\n",
            "81, 5237, 6.382726669311523, 7\n",
            "151, 2518, 6.345517158508301, 7\n",
            "99, 53, 8.588409423828125, 9\n",
            "162, 3701, 8.654684066772461, 9\n",
            "216, 202, 6.986212730407715, 9\n",
            "228, 568, 8.258180618286133, 8\n",
            "9, 454, 7.235973358154297, 7\n",
            "81, 4322, 7.0563507080078125, 5\n",
            "73, 1560, 5.904360771179199, 9\n",
            "156, 578, 7.066535949707031, 8\n",
            "223, 4277, 6.935541152954102, 7\n",
            "164, 1321, 8.169739723205566, 9\n",
            "111, 3370, 7.642161846160889, 8\n",
            "162, 578, 8.175158500671387, 7\n",
            "59, 115, 10.126891136169434, 9\n",
            "201, 40, 7.358210563659668, 8\n",
            "32, 37, 7.145482063293457, 9\n",
            "111, 2899, 7.0091352462768555, 6\n",
            "83, 419, 7.967347621917725, 9\n",
            "39, 52, 9.16246223449707, 8\n",
            "81, 197, 6.977387428283691, 7\n",
            "157, 1441, 6.297633647918701, 7\n",
            "90, 700, 7.33856725692749, 8\n",
            "147, 202, 7.400973320007324, 10\n",
            "171, 77, 7.6371870040893555, 8\n",
            "73, 468, 6.75783634185791, 7\n",
            "6, 2540, 6.1642961502075195, 8\n",
            "27, 20, 8.275686264038086, 6\n",
            "229, 3186, 7.888092041015625, 8\n",
            "113, 943, 6.141426086425781, 7\n",
            "168, 3068, 4.925911903381348, 7\n",
            "156, 4998, 5.273011684417725, 6\n",
            "81, 156, 6.885229110717773, 7\n",
            "104, 5536, 7.990843296051025, 9\n",
            "149, 117, 8.26491928100586, 8\n",
            "202, 1478, 6.701166152954102, 5\n",
            "151, 2163, 6.050778388977051, 6\n",
            "156, 5789, 6.203105926513672, 6\n",
            "188, 1468, 6.464234352111816, 7\n",
            "134, 813, 5.985791206359863, 6\n",
            "111, 3549, 7.463833332061768, 9\n",
            "39, 375, 7.439449310302734, 7\n",
            "173, 342, 7.9195451736450195, 6\n",
            "111, 872, 7.372956275939941, 8\n",
            "104, 10, 8.960493087768555, 9\n",
            "172, 4308, 7.846151351928711, 6\n",
            "81, 2121, 7.664101600646973, 6\n",
            "107, 5544, 5.381067752838135, 5\n",
            "91, 2145, 7.98448371887207, 8\n",
            "111, 5050, 7.811002254486084, 9\n",
            "151, 2806, 5.692193984985352, 6\n",
            "22, 3543, 8.2307710647583, 7\n",
            "172, 3187, 6.649685859680176, 8\n",
            "153, 2172, 7.335010528564453, 8\n",
            "124, 1862, 7.843067169189453, 5\n",
            "149, 5261, 5.640030384063721, 2\n",
            "168, 1493, 5.566959381103516, 5\n",
            "75, 585, 5.462493896484375, 7\n",
            "111, 1036, 7.05967378616333, 5\n",
            "149, 404, 6.461315155029297, 6\n",
            "90, 597, 6.915688514709473, 7\n",
            "36, 201, 8.822928428649902, 7\n",
            "85, 72, 8.257752418518066, 7\n",
            "118, 260, 6.16195011138916, 5\n",
            "59, 3740, 8.227867126464844, 8\n",
            "224, 20, 8.600854873657227, 7\n",
            "57, 687, 6.974074363708496, 7\n",
            "23, 3, 7.857151985168457, 9\n",
            "74, 58, 6.607292652130127, 6\n",
            "151, 2121, 7.168449401855469, 6\n",
            "111, 587, 6.388128280639648, 5\n",
            "94, 118, 8.149864196777344, 8\n",
            "222, 2951, 7.975773811340332, 8\n",
            "212, 2628, 7.633894443511963, 9\n",
            "168, 3818, 4.599337100982666, 2\n",
            "172, 4248, 6.9421305656433105, 8\n",
            "165, 175, 7.064058303833008, 10\n",
            "164, 769, 8.082236289978027, 10\n",
            "188, 1469, 7.136453151702881, 7\n",
            "40, 0, 9.734865188598633, 9\n",
            "2, 181, 9.636064529418945, 8\n",
            "72, 167, 6.863903999328613, 5\n",
            "209, 309, 7.531473636627197, 8\n",
            "223, 2265, 5.864717960357666, 6\n",
            "63, 825, 6.357271671295166, 8\n",
            "104, 337, 8.419435501098633, 7\n",
            "35, 398, 9.04877758026123, 9\n",
            "188, 20, 7.788043022155762, 7\n",
            "1, 4619, 5.623054504394531, 7\n",
            "20, 2801, 5.629425048828125, 7\n",
            "218, 1259, 6.808405876159668, 6\n",
            "230, 425, 6.089592933654785, 8\n",
            "210, 1494, 7.1481733322143555, 7\n",
            "191, 612, 6.4143595695495605, 6\n",
            "210, 1243, 8.510746002197266, 10\n",
            "223, 5152, 6.294783592224121, 6\n",
            "5, 176, 7.896904468536377, 8\n",
            "162, 26, 8.669595718383789, 8\n",
            "81, 4161, 6.655700206756592, 6\n",
            "206, 2775, 6.938932418823242, 8\n",
            "211, 361, 8.023366928100586, 9\n",
            "94, 166, 8.706544876098633, 9\n",
            "164, 943, 6.013545989990234, 8\n",
            "153, 3168, 9.112264633178711, 8\n",
            "40, 4502, 9.760089874267578, 7\n",
            "196, 495, 7.675765514373779, 7\n",
            "151, 292, 6.931697845458984, 7\n",
            "173, 2229, 7.851012229919434, 7\n",
            "7, 2051, 5.730792999267578, 5\n",
            "104, 218, 7.941145896911621, 9\n",
            "32, 542, 8.569190979003906, 8\n",
            "118, 568, 6.60576057434082, 8\n",
            "203, 223, 6.113786697387695, 3\n",
            "21, 2295, 6.001296043395996, 7\n",
            "3, 51, 7.276227951049805, 7\n",
            "33, 233, 7.577016353607178, 9\n",
            "107, 4434, 6.37177038192749, 7\n",
            "9, 1429, 8.460977554321289, 8\n",
            "217, 353, 8.038357734680176, 7\n",
            "232, 447, 8.793407440185547, 8\n",
            "15, 1316, 9.592207908630371, 8\n",
            "81, 1747, 6.6969780921936035, 5\n",
            "24, 4308, 9.137057304382324, 9\n",
            "178, 1845, 7.2669525146484375, 8\n",
            "148, 384, 6.524737358093262, 7\n",
            "162, 4405, 7.951688766479492, 9\n",
            "133, 746, 9.493669509887695, 9\n",
            "28, 138, 6.092480659484863, 7\n",
            "174, 517, 7.518019199371338, 7\n",
            "162, 679, 5.759275436401367, 6\n",
            "111, 4447, 8.149423599243164, 6\n",
            "199, 4531, 8.19109058380127, 10\n",
            "35, 439, 8.478301048278809, 10\n",
            "75, 1337, 4.669217586517334, 5\n",
            "28, 213, 6.0649237632751465, 7\n",
            "172, 5735, 7.110342979431152, 5\n",
            "193, 738, 5.785301208496094, 9\n",
            "118, 1771, 7.859766006469727, 7\n",
            "180, 2254, 7.273941993713379, 5\n",
            "212, 3930, 7.100187301635742, 5\n",
            "120, 784, 8.798318862915039, 10\n",
            "61, 2820, 7.339966773986816, 6\n",
            "61, 3095, 7.483400821685791, 6\n",
            "191, 3733, 7.218263149261475, 7\n",
            "210, 215, 8.837723731994629, 8\n",
            "162, 2994, 7.141143798828125, 6\n",
            "168, 376, 3.9237194061279297, 1\n",
            "89, 1801, 7.466436386108398, 6\n",
            "126, 2659, 9.33003044128418, 8\n",
            "211, 10, 8.879033088684082, 9\n",
            "1, 3523, 6.783173561096191, 7\n",
            "118, 139, 6.753695011138916, 6\n",
            "171, 355, 7.502984046936035, 9\n",
            "66, 205, 5.710824012756348, 5\n",
            "85, 4288, 9.734994888305664, 9\n",
            "192, 3259, 7.700409412384033, 8\n",
            "146, 38, 7.964714050292969, 10\n",
            "7, 2266, 5.023355960845947, 6\n",
            "156, 3658, 4.794354438781738, 4\n",
            "179, 3682, 7.554561614990234, 8\n",
            "219, 5150, 8.453373908996582, 8\n",
            "0, 197, 6.140092372894287, 5\n",
            "176, 610, 4.505828380584717, 5\n",
            "153, 397, 8.270954132080078, 9\n",
            "156, 5154, 5.272277355194092, 6\n",
            "81, 2248, 6.226017475128174, 6\n",
            "112, 796, 8.034697532653809, 6\n",
            "89, 1033, 8.335845947265625, 9\n",
            "125, 1756, 7.529227256774902, 8\n",
            "192, 181, 9.213418960571289, 9\n",
            "178, 3441, 6.92764949798584, 7\n",
            "4, 3983, 5.972139358520508, 5\n",
            "111, 5648, 7.824087619781494, 8\n",
            "133, 243, 9.962324142456055, 8\n",
            "49, 1480, 7.972639083862305, 8\n",
            "151, 434, 7.204197406768799, 9\n",
            "104, 5709, 9.267874717712402, 10\n",
            "89, 3548, 7.300813674926758, 8\n",
            "58, 869, 7.6479387283325195, 5\n",
            "28, 201, 6.91636848449707, 8\n",
            "44, 72, 8.839517593383789, 9\n",
            "214, 811, 7.362185001373291, 10\n",
            "117, 26, 9.64881706237793, 10\n",
            "199, 337, 6.4550886154174805, 3\n",
            "186, 1908, 6.832043647766113, 7\n",
            "201, 801, 7.267261981964111, 8\n",
            "223, 2016, 5.432369232177734, 4\n",
            "222, 891, 8.020636558532715, 9\n",
            "151, 2781, 6.264601230621338, 7\n",
            "230, 575, 6.437154769897461, 7\n",
            "74, 1361, 8.537396430969238, 8\n",
            "156, 2553, 6.301211357116699, 5\n",
            "66, 1, 7.9393181800842285, 8\n",
            "180, 1169, 8.386451721191406, 8\n",
            "192, 414, 7.305919647216797, 8\n",
            "158, 488, 7.703072547912598, 7\n",
            "114, 3113, 6.999759674072266, 7\n",
            "81, 3229, 7.405998229980469, 6\n",
            "172, 3145, 7.569366931915283, 7\n",
            "104, 121, 8.449559211730957, 7\n",
            "16, 51, 7.775232315063477, 8\n",
            "165, 1316, 7.806874752044678, 7\n",
            "61, 1998, 7.618099212646484, 8\n",
            "108, 679, 5.958834171295166, 9\n",
            "172, 4133, 8.01850414276123, 6\n",
            "221, 38, 8.405892372131348, 8\n",
            "81, 5423, 6.700259208679199, 6\n",
            "38, 1327, 7.811134338378906, 8\n",
            "0, 237, 6.234259605407715, 7\n",
            "35, 181, 9.277092933654785, 8\n",
            "192, 1331, 8.90473747253418, 8\n",
            "81, 1481, 5.222415447235107, 8\n",
            "7, 1353, 7.693068981170654, 9\n",
            "58, 273, 7.303350448608398, 6\n",
            "228, 156, 7.493463516235352, 7\n",
            "216, 226, 7.1186981201171875, 6\n",
            "168, 58, 6.364242076873779, 5\n",
            "176, 633, 6.123918533325195, 7\n",
            "7, 2903, 5.034809589385986, 6\n",
            "151, 17, 6.5371294021606445, 9\n",
            "118, 34, 7.428302764892578, 5\n",
            "19, 223, 5.317681312561035, 4\n",
            "43, 249, 6.150907516479492, 8\n",
            "206, 2654, 6.592103958129883, 8\n",
            "18, 5489, 5.6302947998046875, 7\n",
            "172, 298, 8.336044311523438, 8\n",
            "151, 2740, 5.896838188171387, 6\n",
            "175, 1331, 7.344430923461914, 8\n",
            "148, 800, 7.003694534301758, 6\n",
            "114, 1197, 7.914146900177002, 7\n",
            "168, 4057, 6.110271453857422, 6\n",
            "119, 69, 7.81874942779541, 10\n",
            "7, 147, 6.377918243408203, 5\n",
            "190, 2258, 5.785739898681641, 5\n",
            "39, 531, 8.554781913757324, 7\n",
            "100, 830, 7.340659141540527, 8\n",
            "70, 827, 8.143356323242188, 8\n",
            "133, 2792, 6.894074440002441, 8\n",
            "156, 5605, 4.403822422027588, 8\n",
            "131, 1054, 7.082293510437012, 8\n",
            "188, 1774, 8.27259635925293, 9\n",
            "114, 562, 4.682769775390625, 5\n",
            "122, 212, 8.135891914367676, 6\n",
            "168, 3185, 7.617987155914307, 7\n",
            "16, 4782, 6.6449689865112305, 4\n",
            "39, 80, 8.2711181640625, 9\n",
            "172, 5254, 7.962786674499512, 7\n",
            "7, 2247, 8.761974334716797, 8\n",
            "108, 1301, 7.875743389129639, 8\n",
            "187, 1011, 7.229928970336914, 8\n",
            "111, 3872, 7.6658220291137695, 7\n",
            "111, 4536, 6.265079975128174, 7\n",
            "183, 242, 7.752473831176758, 4\n",
            "19, 827, 6.951993942260742, 7\n",
            "105, 2256, 6.923128128051758, 8\n",
            "168, 1944, 5.633242607116699, 6\n",
            "199, 1365, 6.802150249481201, 8\n",
            "124, 1229, 7.473392486572266, 9\n",
            "147, 376, 4.220697402954102, 1\n",
            "191, 3646, 7.25541877746582, 7\n",
            "128, 3658, 6.0208563804626465, 3\n",
            "138, 794, 7.5366668701171875, 8\n",
            "113, 113, 8.920144081115723, 10\n",
            "125, 1092, 7.002773284912109, 8\n",
            "190, 1659, 6.351498603820801, 5\n",
            "6, 40, 6.01584529876709, 7\n",
            "5, 3600, 9.112102508544922, 9\n",
            "111, 437, 7.0011162757873535, 6\n",
            "89, 3094, 8.612957000732422, 9\n",
            "174, 86, 7.2752251625061035, 7\n",
            "68, 47, 8.479172706604004, 4\n",
            "222, 43, 7.8117780685424805, 9\n",
            "7, 676, 5.137057304382324, 6\n",
            "19, 207, 7.160825729370117, 5\n",
            "153, 3312, 7.683083534240723, 8\n",
            "191, 2159, 8.2635498046875, 8\n",
            "26, 51, 7.919537544250488, 10\n",
            "168, 552, 5.518418312072754, 5\n",
            "134, 4508, 5.541989326477051, 5\n",
            "149, 4886, 5.000443458557129, 2\n",
            "162, 5693, 6.415138244628906, 7\n",
            "148, 2588, 5.724499702453613, 4\n",
            "111, 961, 7.705151557922363, 6\n",
            "151, 1072, 5.681434631347656, 7\n",
            "88, 28, 8.086878776550293, 10\n",
            "156, 142, 6.907089710235596, 4\n",
            "111, 2875, 5.562711238861084, 7\n",
            "81, 754, 7.015887260437012, 6\n",
            "128, 395, 7.9012041091918945, 7\n",
            "223, 2017, 7.341299057006836, 7\n",
            "223, 146, 6.147150039672852, 6\n",
            "190, 1773, 6.455696105957031, 8\n",
            "108, 105, 6.338959693908691, 7\n",
            "111, 3313, 8.5215425491333, 9\n",
            "9, 379, 6.6568403244018555, 6\n",
            "190, 3230, 7.360462188720703, 5\n",
            "44, 1480, 8.303423881530762, 9\n",
            "73, 1833, 4.756361961364746, 6\n",
            "35, 2160, 7.798281192779541, 10\n",
            "175, 28, 9.34954833984375, 9\n",
            "168, 685, 5.01265287399292, 7\n",
            "172, 3292, 7.993311405181885, 7\n",
            "93, 286, 8.370915412902832, 10\n",
            "111, 3575, 7.47997522354126, 7\n",
            "45, 1351, 6.786586761474609, 10\n",
            "116, 24, 8.569733619689941, 10\n",
            "199, 98, 7.19915771484375, 7\n",
            "81, 4493, 6.871834754943848, 6\n",
            "90, 640, 8.775691032409668, 10\n",
            "229, 1767, 7.441222667694092, 9\n",
            "87, 2, 8.73878002166748, 9\n",
            "168, 3944, 6.168756484985352, 6\n",
            "202, 1683, 7.833282470703125, 9\n",
            "206, 100, 8.209465026855469, 6\n",
            "111, 1351, 5.5947065353393555, 8\n",
            "172, 3384, 7.272044658660889, 7\n",
            "111, 4623, 8.014572143554688, 7\n",
            "156, 5209, 5.7541608810424805, 6\n",
            "234, 244, 6.805848598480225, 6\n",
            "104, 1111, 7.796337127685547, 10\n",
            "143, 2311, 6.862404823303223, 7\n",
            "117, 3475, 9.533440589904785, 10\n",
            "146, 244, 6.867442607879639, 6\n",
            "125, 2095, 7.78497838973999, 7\n",
            "190, 1455, 6.952943801879883, 8\n",
            "16, 610, 5.818528175354004, 8\n",
            "89, 2275, 7.771176338195801, 8\n",
            "224, 425, 7.458775043487549, 9\n",
            "28, 118, 7.493907928466797, 6\n",
            "96, 495, 8.008063316345215, 8\n",
            "75, 2398, 7.5554022789001465, 8\n",
            "151, 2798, 7.252497673034668, 8\n",
            "42, 146, 8.0846586227417, 7\n",
            "162, 55, 7.324037551879883, 8\n",
            "124, 1657, 8.698453903198242, 8\n",
            "112, 3500, 8.69540786743164, 8\n",
            "178, 5680, 7.564790725708008, 9\n",
            "118, 1935, 7.314545631408691, 5\n",
            "136, 353, 8.578789710998535, 8\n",
            "137, 2687, 8.689693450927734, 10\n",
            "40, 873, 7.726851940155029, 9\n",
            "56, 1231, 7.778138637542725, 8\n",
            "104, 2315, 6.915265083312988, 8\n",
            "192, 3200, 8.537179946899414, 8\n",
            "156, 2113, 7.2297682762146, 7\n",
            "107, 943, 6.128904819488525, 7\n",
            "79, 28, 8.305828094482422, 6\n",
            "196, 405, 7.0778703689575195, 7\n",
            "26, 10, 7.605955123901367, 7\n",
            "1, 4012, 6.767720699310303, 5\n",
            "194, 273, 7.050346374511719, 7\n",
            "197, 2980, 6.811251640319824, 7\n",
            "129, 60, 7.96054744720459, 8\n",
            "36, 4130, 8.612574577331543, 8\n",
            "191, 2611, 7.491031646728516, 9\n",
            "188, 2741, 8.27414608001709, 9\n",
            "234, 5289, 6.292792320251465, 9\n",
            "190, 1039, 7.118556022644043, 7\n",
            "59, 2003, 8.23797607421875, 9\n",
            "151, 171, 7.198429107666016, 7\n",
            "40, 81, 8.545646667480469, 9\n",
            "194, 1590, 9.2688570022583, 10\n",
            "115, 398, 7.8946638107299805, 4\n",
            "199, 504, 5.550607681274414, 7\n",
            "156, 4160, 5.804868698120117, 7\n",
            "108, 242, 7.45658016204834, 8\n",
            "27, 2807, 8.531388282775879, 10\n",
            "118, 3049, 6.878142356872559, 8\n",
            "71, 51, 6.293062686920166, 7\n",
            "151, 840, 7.81046724319458, 7\n",
            "66, 1099, 7.41697359085083, 7\n",
            "61, 1342, 8.083223342895508, 7\n",
            "84, 99, 9.619452476501465, 9\n",
            "165, 3434, 8.589166641235352, 10\n",
            "3, 1456, 8.312206268310547, 9\n",
            "218, 358, 7.098194122314453, 6\n",
            "125, 2573, 8.32024097442627, 7\n",
            "61, 1539, 8.323708534240723, 9\n",
            "226, 3265, 6.9202094078063965, 7\n",
            "47, 549, 8.262709617614746, 8\n",
            "82, 5017, 6.4102911949157715, 8\n",
            "180, 289, 6.705747127532959, 10\n",
            "55, 711, 8.909490585327148, 10\n",
            "134, 2627, 4.286144733428955, 5\n",
            "171, 3554, 5.42429780960083, 5\n",
            "202, 60, 8.978487014770508, 10\n",
            "208, 2660, 6.370343208312988, 10\n",
            "124, 1259, 8.723209381103516, 9\n",
            "81, 38, 8.460187911987305, 6\n",
            "12, 26, 8.636382102966309, 7\n",
            "153, 1358, 8.011523246765137, 10\n",
            "124, 154, 9.47597599029541, 8\n",
            "168, 2008, 5.561805725097656, 4\n",
            "123, 287, 5.269779682159424, 5\n",
            "172, 2729, 7.192281246185303, 6\n",
            "205, 127, 6.937880992889404, 7\n",
            "168, 959, 6.730710983276367, 6\n",
            "168, 3110, 6.748038291931152, 7\n",
            "111, 5779, 6.401062488555908, 6\n",
            "107, 5275, 6.135818004608154, 7\n",
            "131, 2113, 8.158312797546387, 10\n",
            "135, 52, 8.618220329284668, 8\n",
            "163, 335, 6.296319961547852, 6\n",
            "111, 5419, 7.47123908996582, 7\n",
            "199, 181, 8.128715515136719, 10\n",
            "111, 3745, 7.0791473388671875, 7\n",
            "123, 1094, 6.191332817077637, 10\n",
            "148, 337, 5.803213596343994, 9\n",
            "94, 2056, 8.883852005004883, 10\n",
            "224, 2406, 8.463167190551758, 9\n",
            "137, 1665, 9.480205535888672, 9\n",
            "234, 5362, 7.618692874908447, 7\n",
            "148, 2611, 7.746891498565674, 6\n",
            "40, 163, 8.864893913269043, 9\n",
            "39, 120, 7.122975826263428, 8\n",
            "194, 830, 7.178049087524414, 7\n",
            "172, 851, 7.3233184814453125, 7\n",
            "123, 765, 6.851934432983398, 6\n",
            "56, 4706, 6.261468887329102, 8\n",
            "133, 2027, 9.160501480102539, 8\n",
            "82, 5359, 7.6387939453125, 7\n",
            "6, 1180, 6.745058059692383, 2\n",
            "206, 2744, 6.33111047744751, 7\n",
            "36, 3262, 8.12560749053955, 7\n",
            "53, 1448, 6.572157382965088, 10\n",
            "197, 1054, 7.624985694885254, 8\n",
            "82, 80, 7.500066757202148, 5\n",
            "81, 5199, 7.155351638793945, 8\n",
            "168, 3550, 6.491080284118652, 6\n",
            "151, 1532, 6.026031970977783, 6\n",
            "16, 2849, 7.842535018920898, 7\n",
            "122, 558, 6.717597961425781, 7\n",
            "67, 232, 4.674569606781006, 4\n",
            "151, 356, 7.22702693939209, 7\n",
            "84, 25, 9.165332794189453, 8\n",
            "70, 643, 7.428037643432617, 9\n",
            "157, 2504, 7.809133529663086, 9\n",
            "107, 5566, 5.787355899810791, 7\n",
            "121, 80, 8.698347091674805, 8\n",
            "96, 40, 7.757411003112793, 7\n",
            "153, 3323, 8.81171703338623, 7\n",
            "199, 1108, 6.900997161865234, 6\n",
            "70, 417, 8.7451171875, 6\n",
            "172, 2676, 8.479988098144531, 8\n",
            "191, 681, 6.236933708190918, 5\n",
            "225, 1729, 6.763879776000977, 9\n",
            "86, 1970, 5.405886173248291, 7\n",
            "149, 4416, 6.363739013671875, 5\n",
            "168, 4941, 5.432306289672852, 5\n",
            "100, 753, 7.152263641357422, 7\n",
            "125, 180, 7.217862606048584, 7\n",
            "15, 202, 8.17032241821289, 8\n",
            "56, 437, 7.901132583618164, 8\n",
            "45, 3171, 8.045045852661133, 10\n",
            "172, 5399, 8.334691047668457, 7\n",
            "40, 19, 8.71665096282959, 7\n",
            "4, 272, 6.705049514770508, 8\n",
            "99, 875, 8.583410263061523, 7\n",
            "170, 850, 8.16089916229248, 8\n",
            "12, 271, 7.556099891662598, 6\n",
            "168, 2848, 5.31704044342041, 6\n",
            "87, 52, 7.646771430969238, 8\n",
            "55, 375, 10.516949653625488, 10\n",
            "53, 317, 6.309624671936035, 3\n",
            "118, 569, 5.678572654724121, 8\n",
            "149, 4593, 5.46956729888916, 4\n",
            "82, 5145, 6.242181301116943, 6\n",
            "81, 18, 8.37961196899414, 8\n",
            "171, 1500, 5.809927463531494, 5\n",
            "61, 438, 7.390528202056885, 8\n",
            "20, 3914, 5.340991020202637, 8\n",
            "137, 3172, 6.823782920837402, 9\n",
            "81, 2266, 6.789734840393066, 5\n",
            "66, 1546, 8.929182052612305, 6\n",
            "85, 43, 6.479528427124023, 6\n",
            "81, 3994, 6.8308210372924805, 5\n",
            "9, 660, 8.182641983032227, 8\n",
            "153, 3475, 9.316076278686523, 10\n",
            "226, 3872, 9.227812767028809, 9\n",
            "137, 480, 7.344139575958252, 6\n",
            "81, 4240, 7.265921115875244, 7\n",
            "197, 468, 7.631279945373535, 10\n",
            "7, 2795, 5.635646343231201, 5\n",
            "65, 64, 7.948713302612305, 10\n",
            "107, 5782, 6.8780927658081055, 6\n",
            "221, 1, 8.993976593017578, 10\n",
            "12, 1815, 8.576098442077637, 8\n",
            "210, 1521, 7.076823711395264, 9\n",
            "82, 4295, 6.185977935791016, 8\n",
            "210, 603, 8.104609489440918, 9\n",
            "73, 2248, 5.089920997619629, 5\n",
            "223, 5428, 6.3906660079956055, 6\n",
            "81, 4651, 7.922311782836914, 6\n",
            "138, 44, 7.264299392700195, 8\n",
            "65, 3125, 5.738641738891602, 7\n",
            "156, 20, 6.728633880615234, 7\n",
            "136, 201, 8.45238971710205, 8\n",
            "118, 472, 8.224381446838379, 8\n",
            "7, 1391, 5.999843120574951, 5\n",
            "111, 1558, 6.8816070556640625, 9\n",
            "149, 146, 6.887784957885742, 5\n",
            "40, 4880, 7.699598789215088, 8\n",
            "111, 3314, 7.139738082885742, 9\n",
            "167, 124, 6.656471252441406, 5\n",
            "81, 3573, 6.09771203994751, 5\n",
            "131, 40, 6.87898063659668, 9\n",
            "111, 2518, 6.544296741485596, 7\n",
            "172, 5550, 6.363267421722412, 8\n",
            "212, 244, 6.749452590942383, 8\n",
            "14, 539, 7.797643184661865, 9\n",
            "221, 201, 8.496184349060059, 10\n",
            "149, 1089, 6.360033988952637, 6\n",
            "151, 38, 8.229573249816895, 10\n",
            "172, 2675, 7.035693168640137, 8\n",
            "186, 153, 7.885671615600586, 9\n",
            "60, 61, 7.063479423522949, 10\n",
            "162, 2669, 6.354155540466309, 6\n",
            "146, 1638, 5.324955940246582, 5\n",
            "115, 612, 6.4108076095581055, 7\n",
            "90, 72, 9.442302703857422, 10\n",
            "172, 2147, 7.1958441734313965, 3\n",
            "96, 1477, 7.519499778747559, 9\n",
            "89, 107, 8.20632266998291, 9\n",
            "193, 3526, 8.294178009033203, 9\n",
            "196, 403, 6.982672691345215, 9\n",
            "89, 2467, 8.428387641906738, 9\n",
            "35, 2855, 8.62559700012207, 10\n",
            "68, 3401, 7.5189032554626465, 9\n",
            "40, 3489, 9.256251335144043, 10\n",
            "65, 2330, 7.117940902709961, 8\n",
            "172, 3148, 6.591404914855957, 7\n",
            "207, 4330, 8.38086986541748, 10\n",
            "81, 4139, 6.234321594238281, 6\n",
            "40, 3499, 7.490717887878418, 7\n",
            "133, 841, 7.652955532073975, 8\n",
            "172, 4918, 5.399325370788574, 6\n",
            "163, 226, 6.358478546142578, 6\n",
            "163, 30, 6.483275413513184, 6\n",
            "146, 1660, 5.215210914611816, 6\n",
            "117, 3594, 8.463136672973633, 9\n",
            "123, 706, 5.099508285522461, 6\n",
            "81, 3162, 6.1704559326171875, 6\n",
            "207, 2746, 6.797298431396484, 7\n",
            "163, 381, 5.871282577514648, 6\n",
            "149, 3839, 5.77740478515625, 5\n",
            "172, 4821, 5.301833629608154, 6\n",
            "118, 132, 5.497457027435303, 6\n",
            "207, 4289, 7.82468318939209, 8\n",
            "201, 3769, 9.797786712646484, 8\n",
            "63, 53, 7.1729278564453125, 7\n",
            "143, 50, 6.043891906738281, 5\n",
            "148, 2048, 7.386871814727783, 8\n",
            "172, 4086, 8.654619216918945, 7\n",
            "66, 763, 7.059535026550293, 7\n",
            "118, 2833, 6.845974922180176, 8\n",
            "107, 68, 8.267768859863281, 8\n",
            "137, 2929, 8.523521423339844, 9\n",
            "187, 3489, 7.138166904449463, 10\n",
            "149, 1908, 5.374067306518555, 7\n",
            "212, 202, 6.270569801330566, 9\n",
            "192, 746, 10.514764785766602, 10\n",
            "151, 2617, 6.7780961990356445, 8\n",
            "95, 11, 8.037364959716797, 10\n",
            "178, 170, 6.971672058105469, 9\n",
            "190, 2142, 7.517925262451172, 6\n",
            "31, 1751, 6.29742431640625, 5\n",
            "153, 3292, 7.9736223220825195, 9\n",
            "131, 2973, 7.092531681060791, 6\n",
            "41, 411, 6.566277503967285, 7\n",
            "174, 2, 8.827679634094238, 10\n",
            "111, 3124, 6.465602397918701, 7\n",
            "151, 58, 7.113252639770508, 9\n",
            "32, 807, 8.720172882080078, 7\n",
            "111, 787, 6.596952438354492, 7\n",
            "61, 1891, 6.709266662597656, 5\n",
            "123, 974, 5.977439880371094, 10\n",
            "79, 80, 6.884225845336914, 4\n",
            "96, 5, 7.673941612243652, 10\n",
            "35, 3906, 6.43046760559082, 9\n",
            "118, 3065, 7.897294521331787, 7\n",
            "168, 1777, 5.877725601196289, 6\n",
            "220, 4636, 7.7843241691589355, 8\n",
            "121, 775, 8.149773597717285, 7\n",
            "174, 137, 9.00739860534668, 8\n",
            "188, 506, 6.694427490234375, 6\n",
            "202, 66, 8.658956527709961, 10\n",
            "178, 608, 6.439043998718262, 6\n",
            "6, 2017, 7.234237194061279, 7\n",
            "176, 1448, 6.347485542297363, 8\n",
            "209, 381, 7.52099609375, 7\n",
            "104, 5708, 8.591365814208984, 10\n",
            "153, 279, 8.158243179321289, 10\n",
            "81, 3117, 7.8193135261535645, 8\n",
            "234, 212, 7.88455867767334, 9\n",
            "7, 2741, 7.634538173675537, 7\n",
            "54, 1068, 8.815095901489258, 7\n",
            "116, 382, 8.308691024780273, 7\n",
            "188, 2272, 7.197829723358154, 6\n",
            "51, 371, 6.265599250793457, 6\n",
            "11, 734, 7.170551300048828, 7\n",
            "76, 4388, 8.195513725280762, 7\n",
            "18, 215, 8.765223503112793, 9\n",
            "81, 5755, 6.505619049072266, 6\n",
            "111, 4383, 5.7667236328125, 8\n",
            "56, 850, 8.604759216308594, 9\n",
            "202, 1869, 8.637527465820312, 5\n",
            "231, 2284, 6.229223251342773, 8\n",
            "140, 954, 6.471432685852051, 10\n",
            "121, 2679, 6.8876237869262695, 8\n",
            "121, 154, 8.13192081451416, 5\n",
            "25, 596, 7.114319801330566, 8\n",
            "35, 201, 9.224326133728027, 6\n",
            "149, 3508, 8.997976303100586, 6\n",
            "117, 2750, 9.868003845214844, 10\n",
            "187, 79, 7.2996416091918945, 10\n",
            "60, 212, 9.374567031860352, 8\n",
            "163, 870, 6.810351371765137, 7\n",
            "233, 803, 7.137096405029297, 9\n",
            "118, 2486, 7.427353858947754, 7\n",
            "125, 701, 9.16839599609375, 8\n",
            "27, 4153, 8.647415161132812, 8\n",
            "123, 690, 6.465116024017334, 5\n",
            "126, 201, 7.760345935821533, 10\n",
            "172, 962, 6.3358659744262695, 9\n",
            "75, 2801, 6.232996463775635, 7\n",
            "90, 751, 5.7966742515563965, 9\n",
            "172, 374, 6.728721618652344, 7\n",
            "97, 175, 10.58702564239502, 10\n",
            "192, 2392, 8.485678672790527, 9\n",
            "162, 1353, 8.716259956359863, 8\n",
            "179, 8, 7.978830337524414, 9\n",
            "61, 92, 8.062199592590332, 9\n",
            "151, 216, 5.965989112854004, 7\n",
            "162, 3355, 5.676270961761475, 7\n",
            "39, 16, 8.059024810791016, 7\n",
            "118, 639, 6.899457931518555, 7\n",
            "111, 3025, 7.953176498413086, 8\n",
            "76, 1090, 6.280733585357666, 6\n",
            "148, 790, 6.441483497619629, 6\n",
            "1, 4326, 5.138736724853516, 4\n",
            "20, 2454, 6.7101664543151855, 7\n",
            "148, 3, 7.283246994018555, 8\n",
            "104, 2395, 7.8033294677734375, 9\n",
            "74, 2779, 8.340423583984375, 9\n",
            "168, 406, 6.219513893127441, 5\n",
            "115, 353, 7.185593128204346, 6\n",
            "175, 1147, 7.754653453826904, 6\n",
            "233, 3769, 8.772912979125977, 8\n",
            "16, 1333, 6.986116409301758, 4\n",
            "133, 289, 8.158303260803223, 8\n",
            "223, 1824, 8.265695571899414, 9\n",
            "24, 168, 7.356219291687012, 7\n",
            "143, 4704, 7.703096389770508, 7\n",
            "39, 116, 9.190320014953613, 8\n",
            "105, 2227, 7.179110527038574, 9\n",
            "7, 307, 7.817010879516602, 6\n",
            "117, 23, 8.466401100158691, 10\n",
            "95, 25, 8.730559349060059, 9\n",
            "7, 311, 4.488746643066406, 6\n",
            "149, 4595, 6.97524356842041, 9\n",
            "172, 5289, 8.0404691696167, 7\n",
            "105, 548, 7.53709077835083, 9\n",
            "213, 26, 7.957725524902344, 8\n",
            "167, 1301, 6.551267623901367, 6\n",
            "0, 908, 8.750917434692383, 7\n",
            "162, 3573, 6.0074381828308105, 7\n",
            "89, 2123, 7.63593864440918, 8\n",
            "168, 1388, 6.801895618438721, 8\n",
            "111, 875, 8.133929252624512, 9\n",
            "84, 3983, 6.440324783325195, 5\n",
            "164, 128, 6.361238956451416, 8\n",
            "91, 3489, 8.886777877807617, 7\n",
            "118, 3537, 7.655757904052734, 10\n",
            "35, 1001, 9.28919506072998, 9\n",
            "157, 29, 5.5755181312561035, 6\n",
            "173, 2191, 7.96209192276001, 6\n",
            "111, 3999, 6.028098106384277, 6\n",
            "217, 2352, 7.284524917602539, 8\n",
            "118, 3676, 5.917332649230957, 6\n",
            "207, 2, 8.178634643554688, 8\n",
            "27, 1666, 7.883414268493652, 8\n",
            "82, 4792, 5.3773884773254395, 5\n",
            "190, 2442, 6.541311740875244, 2\n",
            "204, 29, 6.724631309509277, 6\n",
            "8, 243, 9.308345794677734, 9\n",
            "24, 1456, 8.363295555114746, 10\n",
            "81, 4252, 7.067854881286621, 7\n",
            "197, 213, 6.974791526794434, 7\n",
            "172, 2372, 7.8677077293396, 7\n",
            "198, 2017, 7.575210094451904, 7\n",
            "172, 2822, 5.277665138244629, 4\n",
            "222, 2628, 7.655221939086914, 7\n",
            "134, 4450, 6.2467522621154785, 6\n",
            "111, 2049, 7.333765506744385, 8\n",
            "79, 175, 6.17594575881958, 8\n",
            "38, 210, 9.100730895996094, 9\n",
            "171, 244, 7.306822776794434, 5\n",
            "202, 1145, 6.952699661254883, 9\n",
            "196, 241, 7.7985382080078125, 7\n",
            "27, 746, 9.134150505065918, 9\n",
            "76, 4750, 5.016035079956055, 4\n",
            "122, 280, 7.913374423980713, 7\n",
            "122, 1144, 7.287184715270996, 7\n",
            "111, 126, 6.435599327087402, 7\n",
            "212, 360, 7.271900653839111, 5\n",
            "190, 2122, 7.593878746032715, 5\n",
            "209, 676, 6.85880708694458, 6\n",
            "36, 2852, 7.279024124145508, 6\n",
            "62, 372, 6.624112129211426, 7\n",
            "81, 2962, 6.502220153808594, 5\n",
            "213, 694, 7.312231063842773, 8\n",
            "179, 72, 7.1231889724731445, 8\n",
            "230, 338, 8.310853958129883, 5\n",
            "27, 3156, 6.605011940002441, 7\n",
            "134, 5669, 7.014001846313477, 7\n",
            "93, 803, 8.519699096679688, 8\n",
            "129, 1200, 8.028070449829102, 8\n",
            "163, 134, 6.65424919128418, 5\n",
            "111, 2475, 6.049198627471924, 7\n",
            "153, 1040, 8.326353073120117, 7\n",
            "199, 198, 7.387408256530762, 2\n",
            "87, 746, 9.736125946044922, 7\n",
            "86, 1688, 7.270912170410156, 8\n",
            "201, 1330, 8.536118507385254, 10\n",
            "132, 308, 9.246182441711426, 10\n",
            "202, 1453, 7.864283561706543, 9\n",
            "226, 447, 7.993164539337158, 8\n",
            "90, 573, 8.012974739074707, 9\n",
            "26, 220, 8.370692253112793, 7\n",
            "1, 2762, 4.671177864074707, 2\n",
            "107, 5424, 7.589920997619629, 8\n",
            "199, 901, 6.941928863525391, 8\n",
            "138, 27, 8.674962997436523, 9\n",
            "187, 4832, 5.383084774017334, 4\n",
            "40, 229, 8.689468383789062, 9\n",
            "107, 679, 5.913793087005615, 7\n",
            "65, 144, 7.841658592224121, 9\n",
            "151, 3425, 5.610665321350098, 5\n",
            "7, 10, 7.186408996582031, 6\n",
            "65, 4977, 6.042477607727051, 8\n",
            "66, 68, 7.224030494689941, 1\n",
            "190, 3588, 6.9051055908203125, 6\n",
            "119, 244, 7.118746757507324, 6\n",
            "111, 497, 7.108639240264893, 8\n",
            "81, 567, 5.120987415313721, 7\n",
            "168, 174, 6.6128764152526855, 4\n",
            "81, 3214, 8.418166160583496, 6\n",
            "35, 2614, 8.912405967712402, 9\n",
            "59, 100, 9.263084411621094, 6\n",
            "178, 4491, 6.555509567260742, 8\n",
            "77, 856, 8.244171142578125, 7\n",
            "168, 411, 6.963901042938232, 8\n",
            "89, 2810, 7.692408561706543, 8\n",
            "55, 1732, 9.322699546813965, 10\n",
            "42, 512, 8.524333953857422, 7\n",
            "148, 2857, 7.473791122436523, 7\n",
            "114, 2317, 6.506636619567871, 3\n",
            "234, 1539, 7.26715087890625, 6\n",
            "190, 1316, 8.108147621154785, 7\n",
            "107, 5167, 6.982650279998779, 5\n",
            "81, 3300, 7.451502323150635, 8\n",
            "81, 430, 6.650688171386719, 6\n",
            "107, 4886, 6.001569747924805, 7\n",
            "99, 178, 8.195000648498535, 9\n",
            "76, 1833, 5.763671875, 5\n",
            "118, 659, 7.569352149963379, 6\n",
            "58, 797, 8.615285873413086, 7\n",
            "120, 1286, 7.155475616455078, 8\n",
            "111, 2248, 6.884842872619629, 3\n",
            "156, 166, 5.373550891876221, 6\n",
            "173, 775, 7.83210563659668, 5\n",
            "111, 2723, 6.564181804656982, 8\n",
            "31, 3142, 5.981084823608398, 6\n",
            "7, 2787, 5.339319229125977, 6\n",
            "208, 124, 7.563699245452881, 2\n",
            "104, 5721, 7.539219856262207, 10\n",
            "166, 35, 8.566926956176758, 9\n",
            "10, 2915, 9.489404678344727, 8\n",
            "56, 4364, 8.052321434020996, 8\n",
            "234, 201, 6.620945930480957, 7\n",
            "47, 1546, 9.565000534057617, 9\n",
            "133, 2304, 7.569339275360107, 8\n",
            "161, 512, 8.661630630493164, 9\n",
            "61, 536, 8.252092361450195, 10\n",
            "38, 2140, 7.630148410797119, 9\n",
            "39, 98, 8.450535774230957, 10\n",
            "111, 1123, 6.684332847595215, 6\n",
            "3, 1330, 8.55387020111084, 9\n",
            "214, 292, 7.796422958374023, 8\n",
            "65, 1213, 6.471469879150391, 5\n",
            "220, 3842, 7.392253875732422, 7\n",
            "151, 1638, 5.523043632507324, 6\n",
            "71, 884, 5.285012722015381, 2\n",
            "212, 4912, 8.751134872436523, 8\n",
            "27, 245, 6.9505133628845215, 9\n",
            "186, 1018, 5.92055606842041, 9\n",
            "148, 2015, 6.989316940307617, 6\n",
            "202, 2801, 7.63801383972168, 8\n",
            "210, 1280, 6.388721466064453, 10\n",
            "165, 137, 7.793838024139404, 4\n",
            "172, 5249, 6.181258678436279, 7\n",
            "205, 4779, 6.825417995452881, 8\n",
            "124, 886, 8.389673233032227, 7\n",
            "101, 53, 7.879298210144043, 8\n",
            "226, 5112, 8.881325721740723, 10\n",
            "74, 446, 5.816801071166992, 6\n",
            "183, 2504, 8.310845375061035, 9\n",
            "183, 5107, 8.066784858703613, 9\n",
            "168, 2420, 7.6157989501953125, 10\n",
            "75, 134, 6.714953422546387, 5\n",
            "193, 4544, 6.56854248046875, 5\n",
            "165, 784, 8.432989120483398, 7\n",
            "111, 607, 6.497968673706055, 7\n",
            "81, 2629, 7.5457611083984375, 7\n",
            "73, 44, 4.8458356857299805, 6\n",
            "74, 355, 8.017901420593262, 6\n",
            "7, 754, 6.553441047668457, 5\n",
            "230, 224, 6.63427734375, 8\n",
            "134, 4927, 4.03225564956665, 6\n",
            "5, 359, 7.908183574676514, 7\n",
            "193, 3064, 6.8727006912231445, 6\n",
            "209, 447, 8.033073425292969, 10\n",
            "171, 212, 7.813849925994873, 8\n",
            "190, 597, 4.9221038818359375, 5\n",
            "107, 894, 7.5367584228515625, 7\n",
            "118, 1648, 6.30827522277832, 10\n",
            "11, 2783, 7.341531276702881, 6\n",
            "73, 792, 4.900291919708252, 6\n",
            "133, 1476, 8.681328773498535, 8\n",
            "33, 693, 9.14992904663086, 8\n",
            "134, 4721, 5.322588920593262, 7\n",
            "230, 242, 7.898677825927734, 8\n",
            "163, 2, 7.324983596801758, 8\n",
            "89, 3663, 8.477177619934082, 9\n",
            "56, 220, 9.546426773071289, 9\n",
            "81, 5153, 6.473649978637695, 7\n",
            "131, 156, 6.801626205444336, 7\n",
            "111, 3345, 6.665087699890137, 8\n",
            "133, 2484, 8.464531898498535, 9\n",
            "224, 10, 8.38037109375, 7\n",
            "153, 2690, 8.098820686340332, 8\n",
            "179, 214, 8.478679656982422, 8\n",
            "166, 157, 7.880936622619629, 7\n",
            "45, 80, 8.63067626953125, 7\n",
            "25, 2113, 7.484976291656494, 6\n",
            "68, 111, 7.231167316436768, 8\n",
            "151, 86, 7.352224349975586, 7\n",
            "207, 2729, 7.304592132568359, 7\n",
            "234, 5236, 7.044923782348633, 5\n",
            "107, 2876, 7.4239501953125, 7\n",
            "144, 143, 7.068424224853516, 8\n",
            "128, 2500, 8.954553604125977, 9\n",
            "133, 863, 7.666313648223877, 8\n",
            "219, 3711, 6.9495649337768555, 7\n",
            "135, 73, 6.591472625732422, 8\n",
            "168, 28, 7.795128345489502, 5\n",
            "89, 305, 7.578579902648926, 8\n",
            "190, 1950, 5.537484645843506, 5\n",
            "157, 3496, 6.938032627105713, 4\n",
            "111, 3110, 7.6937642097473145, 8\n",
            "41, 478, 6.633973121643066, 6\n",
            "107, 537, 7.789610385894775, 9\n",
            "89, 3543, 8.868098258972168, 10\n",
            "153, 678, 7.617338180541992, 8\n",
            "7, 2377, 4.719882011413574, 7\n",
            "114, 217, 6.524079322814941, 8\n",
            "162, 29, 6.493850231170654, 7\n",
            "221, 171, 8.424739837646484, 9\n",
            "39, 12, 8.242502212524414, 7\n",
            "70, 286, 8.323896408081055, 9\n",
            "111, 1688, 7.60559606552124, 9\n",
            "74, 111, 5.961869716644287, 7\n",
            "228, 237, 6.908926963806152, 6\n",
            "167, 10, 6.3667168617248535, 5\n",
            "16, 3547, 6.799030303955078, 7\n",
            "222, 3095, 8.211535453796387, 7\n",
            "201, 789, 7.002765655517578, 10\n",
            "197, 895, 8.20581340789795, 7\n",
            "209, 215, 8.321166038513184, 10\n",
            "233, 2576, 6.96720552444458, 4\n",
            "188, 887, 7.002176284790039, 7\n",
            "4, 2510, 8.478584289550781, 6\n",
            "151, 2598, 8.00400161743164, 6\n",
            "137, 981, 6.729007720947266, 7\n",
            "143, 35, 7.453011512756348, 7\n",
            "91, 803, 8.382476806640625, 7\n",
            "7, 909, 5.0921173095703125, 5\n",
            "229, 240, 8.065631866455078, 8\n",
            "143, 2779, 8.609381675720215, 10\n",
            "161, 162, 8.602679252624512, 9\n",
            "137, 370, 6.806868553161621, 9\n",
            "107, 361, 7.585566520690918, 6\n",
            "74, 1736, 7.404755115509033, 7\n",
            "223, 5074, 5.950284957885742, 8\n",
            "128, 69, 7.834484100341797, 8\n",
            "111, 1911, 6.914302825927734, 7\n",
            "99, 0, 8.733375549316406, 9\n",
            "35, 29, 7.179060935974121, 6\n",
            "110, 347, 7.082674026489258, 6\n",
            "104, 3999, 8.33416748046875, 8\n",
            "208, 687, 7.780117988586426, 8\n",
            "81, 124, 7.182894706726074, 7\n",
            "56, 3728, 9.54224967956543, 8\n",
            "81, 322, 7.493006229400635, 6\n",
            "213, 1465, 8.084857940673828, 9\n",
            "229, 115, 7.490328311920166, 9\n",
            "223, 171, 6.885178565979004, 5\n",
            "1, 2594, 4.672621250152588, 4\n",
            "59, 184, 8.863978385925293, 10\n",
            "234, 337, 6.351989269256592, 6\n",
            "137, 2920, 7.871886253356934, 8\n",
            "89, 995, 9.381659507751465, 6\n",
            "207, 52, 7.7293596267700195, 10\n",
            "153, 993, 8.590160369873047, 8\n",
            "1, 3961, 5.675125598907471, 3\n",
            "171, 53, 8.078817367553711, 10\n",
            "220, 286, 7.643084526062012, 8\n",
            "172, 3028, 5.884321212768555, 6\n",
            "61, 746, 9.179466247558594, 9\n",
            "149, 1821, 6.502157211303711, 4\n",
            "172, 4509, 6.132836818695068, 7\n",
            "172, 4527, 6.5244903564453125, 7\n",
            "111, 5701, 6.267268657684326, 10\n",
            "77, 412, 7.535282135009766, 5\n",
            "59, 1361, 9.316524505615234, 10\n",
            "36, 1970, 5.58783483505249, 5\n",
            "228, 428, 8.445748329162598, 10\n",
            "162, 44, 6.094916343688965, 5\n",
            "137, 421, 9.243057250976562, 8\n",
            "143, 4424, 8.581287384033203, 8\n",
            "104, 5202, 8.351290702819824, 9\n",
            "220, 2108, 8.0501070022583, 8\n",
            "187, 571, 6.0245561599731445, 5\n",
            "208, 60, 8.678886413574219, 8\n",
            "91, 756, 6.820545196533203, 6\n",
            "104, 2590, 9.090484619140625, 10\n",
            "134, 1682, 6.233914375305176, 9\n",
            "178, 5106, 6.78841495513916, 8\n",
            "94, 169, 8.174691200256348, 7\n",
            "14, 640, 7.927700996398926, 6\n",
            "190, 271, 6.971391677856445, 5\n",
            "131, 150, 6.838556289672852, 7\n",
            "27, 2, 8.122803688049316, 10\n",
            "89, 3737, 9.06818675994873, 9\n",
            "219, 3005, 8.365628242492676, 8\n",
            "44, 244, 8.593242645263672, 9\n",
            "226, 506, 7.6684465408325195, 3\n",
            "68, 716, 7.528349876403809, 10\n",
            "31, 203, 7.502773284912109, 7\n",
            "81, 264, 6.575325965881348, 7\n",
            "81, 4381, 5.1939496994018555, 5\n",
            "185, 5236, 8.437150001525879, 9\n",
            "23, 286, 7.363194465637207, 4\n",
            "157, 2793, 8.814309120178223, 4\n",
            "214, 199, 7.504020690917969, 8\n",
            "188, 60, 8.523336410522461, 10\n",
            "174, 741, 6.292847156524658, 8\n",
            "217, 660, 6.7834014892578125, 7\n",
            "81, 5114, 7.822878837585449, 7\n",
            "134, 150, 5.80798864364624, 9\n",
            "233, 1446, 7.078303337097168, 6\n",
            "97, 3716, 9.140593528747559, 2\n",
            "234, 1091, 6.507233619689941, 5\n",
            "61, 1098, 6.575199127197266, 8\n",
            "199, 782, 6.137948513031006, 7\n",
            "100, 38, 8.426417350769043, 7\n",
            "221, 361, 7.744427680969238, 8\n",
            "90, 2145, 9.318461418151855, 9\n",
            "143, 269, 7.386959075927734, 7\n",
            "201, 797, 8.097424507141113, 7\n",
            "41, 751, 3.206512928009033, 3\n",
            "179, 716, 6.382507801055908, 7\n",
            "190, 3584, 6.521697044372559, 6\n",
            "85, 437, 6.634642601013184, 7\n",
            "35, 1092, 6.497567176818848, 6\n",
            "42, 743, 9.046670913696289, 10\n",
            "86, 2159, 8.452556610107422, 8\n",
            "84, 3888, 6.676543235778809, 7\n",
            "117, 212, 9.174164772033691, 9\n",
            "118, 1515, 6.275842189788818, 8\n",
            "222, 1539, 8.142071723937988, 9\n",
            "107, 4382, 7.375614166259766, 7\n",
            "81, 833, 5.512786388397217, 6\n",
            "73, 1766, 7.183818340301514, 5\n",
            "28, 746, 8.847028732299805, 8\n",
            "168, 1612, 6.780485153198242, 6\n",
            "210, 828, 6.863299369812012, 7\n",
            "82, 531, 7.847537994384766, 9\n",
            "89, 4580, 8.879108428955078, 10\n",
            "168, 4502, 7.624435901641846, 6\n",
            "201, 427, 9.556467056274414, 7\n",
            "216, 308, 6.746962547302246, 5\n",
            "151, 2608, 6.425498008728027, 7\n",
            "226, 3626, 6.638838768005371, 7\n",
            "85, 5764, 7.947834014892578, 8\n",
            "180, 150, 7.615265846252441, 9\n",
            "98, 800, 7.730242729187012, 6\n",
            "61, 721, 6.065633296966553, 7\n",
            "232, 31, 6.850193023681641, 8\n",
            "31, 2084, 8.277246475219727, 7\n",
            "134, 3728, 6.949366569519043, 5\n",
            "118, 426, 5.773150444030762, 6\n",
            "167, 1001, 6.9066009521484375, 5\n",
            "134, 2027, 6.798042297363281, 8\n",
            "219, 4379, 7.639100074768066, 9\n",
            "176, 247, 5.852479934692383, 7\n",
            "180, 2652, 6.578229904174805, 7\n",
            "162, 483, 6.707301139831543, 7\n",
            "208, 112, 7.544949531555176, 5\n",
            "167, 1018, 4.019853115081787, 4\n",
            "148, 750, 8.222108840942383, 9\n",
            "175, 4600, 8.726722717285156, 9\n",
            "60, 392, 9.174325942993164, 8\n",
            "168, 2558, 7.33071756362915, 5\n",
            "7, 923, 4.389565944671631, 4\n",
            "117, 839, 8.838287353515625, 9\n",
            "202, 1208, 9.215606689453125, 7\n",
            "100, 590, 8.748046875, 9\n",
            "226, 4617, 7.671839237213135, 8\n",
            "64, 393, 9.779699325561523, 10\n",
            "168, 1946, 5.600841522216797, 6\n",
            "156, 358, 6.54755973815918, 6\n",
            "193, 826, 7.350110054016113, 8\n",
            "231, 1348, 5.613217353820801, 5\n",
            "111, 2196, 6.521933555603027, 9\n",
            "89, 108, 7.878457069396973, 9\n",
            "111, 2367, 7.3481316566467285, 6\n",
            "149, 3935, 6.985428333282471, 7\n",
            "81, 2654, 7.233453750610352, 6\n",
            "12, 245, 6.950026512145996, 8\n",
            "66, 828, 5.118250846862793, 7\n",
            "18, 4162, 7.19467830657959, 5\n",
            "151, 2627, 5.878129005432129, 7\n",
            "115, 897, 6.39639139175415, 8\n",
            "84, 4096, 8.89132022857666, 6\n",
            "143, 740, 5.041830539703369, 5\n",
            "134, 4245, 8.641818046569824, 6\n",
            "149, 92, 7.263991355895996, 7\n",
            "226, 5111, 7.71987771987915, 10\n",
            "124, 991, 7.017671585083008, 7\n",
            "214, 3872, 7.785004138946533, 7\n",
            "233, 3172, 6.54836368560791, 6\n",
            "54, 167, 9.056079864501953, 6\n",
            "9, 50, 6.913539886474609, 6\n",
            "226, 3797, 7.59100866317749, 7\n",
            "115, 826, 6.441470623016357, 7\n",
            "74, 20, 7.558592796325684, 6\n",
            "151, 438, 6.294154644012451, 6\n",
            "96, 141, 8.349929809570312, 10\n",
            "210, 1695, 7.6128249168396, 5\n",
            "226, 3111, 6.7734246253967285, 8\n",
            "131, 393, 8.411351203918457, 5\n",
            "162, 1391, 6.801244735717773, 7\n",
            "11, 322, 8.123345375061035, 8\n",
            "36, 212, 8.732792854309082, 7\n",
            "207, 69, 7.640941619873047, 7\n",
            "89, 4571, 8.379530906677246, 9\n",
            "111, 4352, 7.096958160400391, 8\n",
            "168, 1602, 6.572926044464111, 6\n",
            "104, 1350, 9.01700210571289, 10\n",
            "172, 4413, 7.514263153076172, 7\n",
            "126, 3434, 9.702014923095703, 9\n",
            "121, 72, 8.584486961364746, 9\n",
            "137, 217, 9.139570236206055, 9\n",
            "118, 1291, 6.244001388549805, 7\n",
            "206, 448, 7.37129020690918, 6\n",
            "111, 377, 7.208859443664551, 8\n",
            "4, 536, 7.870276927947998, 9\n",
            "222, 73, 7.37714958190918, 10\n",
            "151, 1780, 6.73326301574707, 6\n",
            "108, 115, 8.138075828552246, 9\n",
            "81, 2664, 7.195330619812012, 8\n",
            "118, 2250, 7.5320210456848145, 4\n",
            "172, 4080, 8.365954399108887, 7\n",
            "107, 1305, 6.938077926635742, 7\n",
            "155, 753, 8.064830780029297, 9\n",
            "130, 292, 6.294824123382568, 7\n",
            "35, 4008, 6.677106857299805, 9\n",
            "202, 631, 8.366737365722656, 10\n",
            "156, 4706, 4.752864837646484, 7\n",
            "131, 870, 6.275926113128662, 8\n",
            "168, 2625, 6.1373610496521, 5\n",
            "33, 435, 7.480511665344238, 8\n",
            "156, 3281, 6.968443393707275, 5\n",
            "43, 393, 7.9626688957214355, 7\n",
            "230, 819, 5.5233378410339355, 5\n",
            "188, 1290, 6.668640613555908, 7\n",
            "184, 2608, 6.695453643798828, 8\n",
            "156, 4183, 5.812709808349609, 7\n",
            "111, 4438, 7.398209095001221, 6\n",
            "1, 3657, 6.079680442810059, 5\n",
            "108, 827, 7.588767051696777, 9\n",
            "190, 171, 7.212252140045166, 9\n",
            "172, 2487, 6.733428001403809, 7\n",
            "153, 2171, 8.216208457946777, 6\n",
            "73, 216, 5.042398452758789, 3\n",
            "134, 3064, 5.569293022155762, 6\n",
            "89, 1331, 8.963142395019531, 8\n",
            "119, 469, 7.393422603607178, 8\n",
            "193, 2716, 5.966826915740967, 1\n",
            "193, 3113, 6.707496643066406, 8\n",
            "114, 766, 5.670459747314453, 7\n",
            "220, 2718, 7.736988544464111, 8\n",
            "38, 373, 6.813813209533691, 8\n",
            "74, 2592, 6.796075344085693, 6\n",
            "56, 4795, 8.850025177001953, 7\n",
            "81, 5173, 7.864564418792725, 6\n",
            "66, 491, 7.96407413482666, 7\n",
            "27, 2317, 7.385850429534912, 7\n",
            "124, 1275, 9.155597686767578, 9\n",
            "61, 23, 8.23351764678955, 9\n",
            "111, 4206, 7.573349475860596, 5\n",
            "116, 828, 8.091026306152344, 7\n",
            "108, 114, 9.152454376220703, 9\n",
            "93, 24, 8.351007461547852, 9\n",
            "199, 804, 5.576539039611816, 4\n",
            "111, 1222, 6.059754371643066, 7\n",
            "61, 2855, 7.255772113800049, 10\n",
            "191, 224, 6.445496559143066, 8\n",
            "230, 743, 7.201848983764648, 8\n",
            "146, 2649, 5.4291582107543945, 4\n",
            "172, 5614, 7.8434576988220215, 7\n",
            "104, 5713, 8.302605628967285, 7\n",
            "178, 5101, 6.785162925720215, 8\n",
            "162, 1091, 6.6672749519348145, 7\n",
            "60, 0, 9.046415328979492, 10\n",
            "174, 79, 8.029678344726562, 6\n",
            "151, 687, 7.9155592918396, 10\n",
            "206, 2533, 5.637091636657715, 5\n",
            "7, 910, 7.487620830535889, 6\n",
            "85, 2741, 8.07197093963623, 8\n",
            "53, 662, 7.766968727111816, 7\n",
            "180, 290, 7.726502418518066, 7\n",
            "93, 113, 9.063310623168945, 7\n",
            "162, 2111, 6.489400863647461, 3\n",
            "124, 188, 8.876972198486328, 7\n",
            "59, 73, 7.389740943908691, 7\n",
            "226, 1774, 8.654862403869629, 10\n",
            "222, 321, 8.89081859588623, 9\n",
            "225, 1330, 7.769434452056885, 7\n",
            "148, 2641, 7.0378217697143555, 5\n",
            "66, 158, 8.267620086669922, 8\n",
            "196, 138, 7.214498519897461, 8\n",
            "33, 429, 8.639870643615723, 7\n",
            "180, 972, 8.957039833068848, 7\n",
            "172, 4477, 7.607170104980469, 8\n",
            "172, 3673, 4.730249881744385, 7\n",
            "209, 101, 7.600825309753418, 4\n",
            "213, 447, 7.909199237823486, 8\n",
            "81, 5419, 7.659332752227783, 7\n",
            "117, 202, 9.039257049560547, 7\n",
            "111, 4920, 7.088687896728516, 6\n",
            "172, 4457, 6.060813903808594, 6\n",
            "207, 98, 7.029213905334473, 5\n",
            "226, 2003, 8.594732284545898, 9\n",
            "188, 53, 8.64421272277832, 10\n",
            "76, 20, 7.797135353088379, 9\n",
            "112, 1834, 7.030371189117432, 7\n",
            "138, 166, 7.361102104187012, 9\n",
            "44, 716, 8.541004180908203, 7\n",
            "32, 831, 7.843727111816406, 7\n",
            "168, 318, 6.893848419189453, 7\n",
            "173, 2579, 8.18330192565918, 10\n",
            "171, 1179, 5.0970540046691895, 5\n",
            "61, 575, 6.9914045333862305, 8\n",
            "17, 2407, 9.606818199157715, 10\n",
            "89, 1361, 9.913684844970703, 9\n",
            "1, 3301, 7.012172222137451, 6\n",
            "233, 5617, 7.25379753112793, 7\n",
            "174, 591, 9.282774925231934, 7\n",
            "104, 213, 8.74356746673584, 10\n",
            "176, 1643, 5.727630615234375, 5\n",
            "47, 86, 7.183636665344238, 7\n",
            "111, 1839, 6.8483428955078125, 6\n",
            "54, 2, 9.242408752441406, 6\n",
            "73, 115, 7.537465572357178, 6\n",
            "0, 1627, 9.728105545043945, 7\n",
            "118, 3636, 6.705915927886963, 8\n",
            "193, 2705, 7.978471755981445, 8\n",
            "82, 3324, 8.405224800109863, 6\n",
            "196, 166, 7.322783470153809, 7\n",
            "231, 108, 6.70211124420166, 9\n",
            "217, 791, 6.165216445922852, 5\n",
            "89, 468, 8.963666915893555, 9\n",
            "135, 47, 7.637054443359375, 9\n",
            "118, 5334, 7.633636951446533, 9\n",
            "104, 428, 9.315054893493652, 10\n",
            "90, 2265, 8.117877960205078, 9\n",
            "151, 151, 5.847245693206787, 5\n",
            "124, 1080, 7.163135528564453, 7\n",
            "81, 3310, 6.627800941467285, 5\n",
            "111, 661, 8.21260929107666, 7\n",
            "191, 768, 6.723047733306885, 6\n",
            "156, 2919, 6.601670265197754, 8\n",
            "0, 1263, 5.649896621704102, 6\n",
            "193, 2736, 7.062449932098389, 8\n",
            "190, 579, 7.473425388336182, 6\n",
            "74, 2014, 6.681103706359863, 5\n",
            "117, 532, 8.863873481750488, 8\n",
            "76, 3402, 5.842151641845703, 9\n",
            "81, 486, 7.2657389640808105, 6\n",
            "97, 3315, 10.209083557128906, 10\n",
            "73, 710, 6.6549859046936035, 6\n",
            "4, 3858, 8.032538414001465, 7\n",
            "231, 1998, 7.429567337036133, 5\n",
            "171, 779, 6.830402374267578, 8\n",
            "16, 124, 7.054518699645996, 8\n",
            "35, 365, 9.637238502502441, 4\n",
            "219, 882, 7.691030502319336, 7\n",
            "176, 2589, 5.925631999969482, 3\n",
            "205, 1351, 5.410491943359375, 6\n",
            "107, 3730, 6.601624488830566, 6\n",
            "151, 780, 6.46311092376709, 8\n",
            "193, 1887, 6.470184326171875, 6\n",
            "202, 124, 8.779845237731934, 10\n",
            "212, 5737, 6.078372001647949, 8\n",
            "186, 1135, 6.411266326904297, 5\n",
            "162, 2765, 7.302012920379639, 4\n",
            "76, 3773, 6.425337791442871, 7\n",
            "206, 1964, 5.457015514373779, 6\n",
            "112, 1793, 7.589589595794678, 8\n",
            "163, 470, 6.646384239196777, 7\n",
            "125, 80, 8.218520164489746, 6\n",
            "81, 2888, 7.536596298217773, 8\n",
            "151, 31, 6.571634769439697, 5\n",
            "91, 491, 9.343878746032715, 8\n",
            "89, 304, 7.884507179260254, 9\n",
            "122, 522, 7.279558181762695, 7\n",
            "223, 4915, 5.466029167175293, 6\n",
            "223, 1539, 7.236396789550781, 8\n",
            "82, 28, 8.817774772644043, 9\n",
            "134, 4209, 5.057721138000488, 5\n",
            "181, 286, 9.464491844177246, 10\n",
            "85, 5590, 8.169825553894043, 9\n",
            "65, 2227, 6.759040832519531, 7\n",
            "27, 2644, 7.001754283905029, 8\n",
            "118, 2741, 7.2029314041137695, 8\n",
            "193, 197, 6.348700523376465, 5\n",
            "190, 53, 7.902225017547607, 6\n",
            "123, 108, 6.579407215118408, 9\n",
            "124, 1256, 8.030290603637695, 7\n",
            "228, 223, 7.306166648864746, 9\n",
            "56, 961, 8.253885269165039, 9\n",
            "180, 292, 7.411496639251709, 10\n",
            "151, 3484, 8.682846069335938, 9\n",
            "121, 42, 7.2818379402160645, 9\n",
            "118, 592, 5.974966526031494, 7\n",
            "208, 610, 6.992353439331055, 6\n",
            "210, 403, 6.978676795959473, 7\n",
            "40, 166, 8.346214294433594, 9\n",
            "81, 5606, 6.602808952331543, 7\n",
            "168, 4778, 5.1942033767700195, 7\n",
            "148, 327, 5.144323825836182, 6\n",
            "105, 29, 6.53184700012207, 9\n",
            "85, 5707, 7.919145584106445, 8\n",
            "133, 2466, 8.222017288208008, 7\n",
            "89, 4073, 6.103482246398926, 9\n",
            "172, 4211, 6.387683868408203, 8\n",
            "151, 1566, 6.885662078857422, 6\n",
            "96, 1594, 6.583205223083496, 7\n",
            "193, 47, 7.364632606506348, 9\n",
            "104, 3362, 7.60421895980835, 9\n",
            "204, 166, 7.23565673828125, 8\n",
            "168, 2578, 7.135490417480469, 6\n",
            "10, 1463, 6.937498569488525, 5\n",
            "77, 425, 7.239026069641113, 8\n",
            "197, 4025, 7.486990928649902, 8\n",
            "79, 393, 7.160128593444824, 8\n",
            "81, 3886, 7.016263961791992, 6\n",
            "81, 4067, 5.648647308349609, 6\n",
            "1, 392, 7.449185371398926, 7\n",
            "190, 3204, 7.527745246887207, 7\n",
            "144, 716, 9.072429656982422, 9\n",
            "36, 375, 6.685798645019531, 8\n",
            "157, 3110, 7.915956497192383, 8\n",
            "175, 1752, 6.96491813659668, 9\n",
            "213, 1054, 7.3913774490356445, 9\n",
            "36, 2798, 7.940101623535156, 7\n",
            "210, 887, 8.050495147705078, 8\n",
            "19, 294, 6.062680244445801, 6\n",
            "48, 421, 8.686633110046387, 6\n",
            "153, 3347, 8.486249923706055, 9\n",
            "190, 2916, 6.476532936096191, 3\n",
            "131, 38, 8.54619026184082, 8\n",
            "118, 150, 6.186032295227051, 8\n",
            "27, 4289, 7.180190086364746, 7\n",
            "131, 3448, 7.4061737060546875, 6\n",
            "229, 381, 5.4547834396362305, 8\n",
            "39, 11, 8.652499198913574, 10\n",
            "190, 736, 5.436850547790527, 6\n",
            "186, 923, 5.550874710083008, 1\n",
            "56, 2210, 7.674966812133789, 10\n",
            "68, 2732, 7.707869529724121, 9\n",
            "211, 1330, 10.274428367614746, 10\n",
            "162, 1315, 6.697148323059082, 7\n",
            "124, 893, 8.610296249389648, 10\n",
            "61, 3222, 5.6833672523498535, 8\n",
            "162, 2216, 7.46705961227417, 5\n",
            "81, 575, 6.14572811126709, 4\n",
            "196, 393, 8.59570026397705, 8\n",
            "40, 26, 9.497804641723633, 8\n",
            "148, 1448, 7.506848335266113, 10\n",
            "162, 2887, 6.902426719665527, 7\n",
            "184, 201, 7.861762046813965, 5\n",
            "175, 47, 7.221979141235352, 9\n",
            "107, 4269, 7.423239231109619, 7\n",
            "45, 10, 8.047714233398438, 8\n",
            "99, 172, 7.504408836364746, 8\n",
            "65, 25, 8.214251518249512, 10\n",
            "138, 128, 7.7022600173950195, 8\n",
            "91, 3924, 8.611055374145508, 9\n",
            "89, 2195, 9.229063034057617, 10\n",
            "172, 3634, 6.228793621063232, 7\n",
            "84, 3610, 6.940488815307617, 8\n",
            "156, 5499, 8.082773208618164, 8\n",
            "190, 3382, 6.311028480529785, 8\n",
            "148, 2305, 6.128005504608154, 5\n",
            "162, 3792, 8.665850639343262, 8\n",
            "107, 2778, 6.065552711486816, 7\n",
            "187, 442, 8.170499801635742, 8\n",
            "151, 2711, 6.080878257751465, 7\n",
            "148, 1156, 7.161220073699951, 6\n",
            "81, 5310, 5.310406684875488, 8\n",
            "116, 393, 9.41529369354248, 10\n",
            "91, 772, 8.71653938293457, 7\n",
            "124, 129, 7.869508743286133, 8\n",
            "186, 485, 8.468796730041504, 8\n",
            "134, 1472, 4.468592166900635, 5\n",
            "136, 158, 9.156501770019531, 7\n",
            "118, 1087, 6.2551374435424805, 6\n",
            "187, 29, 6.737009048461914, 7\n",
            "118, 531, 8.37736701965332, 10\n",
            "133, 274, 7.545821189880371, 7\n",
            "196, 1176, 7.048487663269043, 8\n",
            "211, 57, 9.345527648925781, 10\n",
            "153, 488, 9.274148941040039, 4\n",
            "19, 680, 4.964348793029785, 5\n",
            "89, 366, 9.40993881225586, 9\n",
            "146, 504, 4.615626335144043, 2\n",
            "61, 2505, 7.737054824829102, 9\n",
            "85, 3049, 7.490686416625977, 9\n",
            "67, 373, 5.746809005737305, 4\n",
            "43, 275, 5.888310432434082, 7\n",
            "165, 1286, 6.010509014129639, 5\n",
            "162, 2959, 7.324680805206299, 8\n",
            "0, 238, 9.076319694519043, 10\n",
            "164, 983, 6.939780235290527, 7\n",
            "90, 146, 8.350088119506836, 10\n",
            "16, 3281, 7.277734279632568, 6\n",
            "89, 210, 8.942073822021484, 8\n",
            "8, 123, 9.061513900756836, 8\n",
            "74, 298, 7.887202262878418, 8\n",
            "187, 261, 5.618553161621094, 4\n",
            "31, 3351, 7.562545299530029, 8\n",
            "188, 41, 7.793207168579102, 10\n",
            "224, 2353, 6.969770431518555, 7\n",
            "193, 212, 7.9742021560668945, 8\n",
            "146, 52, 7.721858501434326, 8\n",
            "192, 1, 9.46936321258545, 9\n",
            "146, 750, 8.25685977935791, 9\n",
            "171, 3384, 6.624959945678711, 9\n",
            "111, 47, 7.680514335632324, 9\n",
            "90, 737, 7.621659278869629, 10\n",
            "157, 845, 7.590399265289307, 6\n",
            "107, 10, 7.7212982177734375, 7\n",
            "90, 2239, 8.237569808959961, 8\n",
            "84, 3769, 9.080087661743164, 9\n",
            "81, 468, 7.7018938064575195, 8\n",
            "97, 92, 9.00937271118164, 10\n",
            "229, 252, 6.3644938468933105, 5\n",
            "81, 4488, 7.544351577758789, 7\n",
            "223, 1243, 6.394383430480957, 8\n",
            "122, 44, 7.053199291229248, 4\n",
            "234, 5560, 6.627585411071777, 9\n",
            "81, 3016, 6.511765003204346, 6\n",
            "59, 2479, 7.2867865562438965, 5\n",
            "73, 144, 6.524147033691406, 6\n",
            "4, 3716, 7.9091057777404785, 7\n",
            "156, 1099, 6.122981071472168, 8\n",
            "197, 1477, 7.0407257080078125, 8\n",
            "220, 4903, 7.422071933746338, 8\n",
            "193, 16, 6.9201555252075195, 8\n",
            "63, 955, 7.561296463012695, 8\n",
            "174, 278, 6.491775989532471, 5\n",
            "149, 5178, 6.739645004272461, 8\n",
            "118, 903, 6.659296989440918, 8\n",
            "151, 2818, 6.401330947875977, 6\n",
            "151, 3037, 6.979557037353516, 8\n",
            "131, 111, 5.925723552703857, 2\n",
            "73, 963, 3.6901845932006836, 6\n",
            "180, 854, 7.03781795501709, 7\n",
            "131, 167, 7.177326679229736, 8\n",
            "124, 882, 7.439849376678467, 7\n",
            "149, 2781, 5.369462013244629, 6\n",
            "129, 1316, 7.644801139831543, 6\n",
            "96, 110, 7.037919998168945, 9\n",
            "7, 2721, 6.139087200164795, 6\n",
            "149, 4082, 6.170188903808594, 5\n",
            "74, 2160, 6.7395124435424805, 6\n",
            "174, 171, 8.620245933532715, 5\n",
            "81, 4432, 6.406895160675049, 7\n",
            "192, 1180, 9.41865062713623, 7\n",
            "193, 1820, 8.053329467773438, 10\n",
            "222, 353, 8.841936111450195, 10\n",
            "162, 2650, 7.473890781402588, 7\n",
            "230, 790, 6.3623366355896, 6\n",
            "162, 3025, 7.718804359436035, 8\n",
            "153, 3018, 8.62084674835205, 8\n",
            "168, 1165, 5.789658546447754, 4\n",
            "218, 427, 8.380593299865723, 7\n",
            "131, 2984, 5.82444429397583, 4\n",
            "32, 776, 7.054744243621826, 9\n",
            "230, 803, 8.412940979003906, 5\n",
            "222, 149, 7.4330339431762695, 9\n",
            "76, 226, 6.974758148193359, 6\n",
            "229, 1477, 5.924941062927246, 6\n",
            "190, 567, 5.417402267456055, 8\n",
            "12, 2192, 7.2307305335998535, 7\n",
            "112, 5737, 6.354701995849609, 7\n",
            "111, 3581, 8.791923522949219, 10\n",
            "104, 4530, 7.991034507751465, 9\n",
            "112, 791, 7.300220966339111, 7\n",
            "81, 4418, 5.612039566040039, 6\n",
            "125, 734, 7.134840488433838, 8\n",
            "7, 2340, 6.848654747009277, 7\n",
            "157, 3719, 6.781612873077393, 6\n",
            "211, 31, 8.208675384521484, 10\n",
            "111, 102, 5.570278167724609, 7\n",
            "229, 38, 7.850747585296631, 7\n",
            "111, 5153, 6.804075241088867, 8\n",
            "91, 1301, 8.008426666259766, 5\n",
            "156, 3245, 8.941864013671875, 8\n",
            "104, 5497, 7.9044647216796875, 9\n",
            "123, 783, 5.983555316925049, 4\n",
            "220, 1087, 7.4701433181762695, 8\n",
            "68, 414, 7.526003837585449, 5\n",
            "99, 3537, 9.58340072631836, 9\n",
            "205, 472, 8.206287384033203, 6\n",
            "220, 665, 8.530145645141602, 7\n",
            "156, 4874, 4.818885326385498, 7\n",
            "166, 356, 8.699546813964844, 8\n",
            "19, 3, 6.708295822143555, 8\n",
            "156, 4440, 6.906424522399902, 5\n",
            "203, 24, 7.537330150604248, 10\n",
            "38, 224, 8.249176979064941, 6\n",
            "172, 19, 7.081707000732422, 6\n",
            "118, 1315, 5.99666690826416, 4\n",
            "22, 42, 6.500434398651123, 6\n",
            "134, 3641, 5.739272117614746, 7\n",
            "82, 52, 7.996763706207275, 9\n",
            "196, 165, 8.30176067352295, 7\n",
            "188, 1958, 6.119564056396484, 4\n",
            "158, 286, 8.452560424804688, 8\n",
            "123, 262, 5.810460090637207, 10\n",
            "172, 4370, 5.812678337097168, 7\n",
            "131, 3137, 6.630003929138184, 9\n",
            "157, 48, 7.434932708740234, 5\n",
            "74, 29, 6.591301918029785, 8\n",
            "171, 220, 7.851621627807617, 10\n",
            "91, 4354, 8.734874725341797, 10\n",
            "226, 5558, 7.801514625549316, 9\n",
            "120, 224, 6.420009613037109, 7\n",
            "7, 2916, 5.166224956512451, 6\n",
            "107, 4949, 7.502923965454102, 7\n",
            "61, 2921, 8.68191909790039, 9\n",
            "125, 569, 7.054337501525879, 8\n",
            "151, 2056, 8.045695304870605, 9\n",
            "128, 766, 6.567524433135986, 8\n",
            "81, 3764, 6.469235897064209, 7\n",
            "149, 2622, 7.530593395233154, 8\n",
            "32, 1911, 8.533114433288574, 8\n",
            "223, 59, 6.059266090393066, 7\n",
            "61, 123, 7.452502250671387, 7\n",
            "73, 186, 5.471587657928467, 3\n",
            "96, 229, 8.657075881958008, 7\n",
            "81, 175, 7.689071178436279, 8\n",
            "151, 426, 6.201204299926758, 4\n",
            "196, 48, 8.322084426879883, 9\n",
            "206, 2873, 6.10141658782959, 6\n",
            "115, 241, 6.66877555847168, 7\n",
            "27, 3722, 6.985743999481201, 7\n",
            "151, 52, 8.174931526184082, 8\n",
            "171, 2958, 7.1279754638671875, 8\n",
            "153, 3969, 8.175156593322754, 8\n",
            "219, 3829, 6.566067695617676, 8\n",
            "148, 2630, 6.6033124923706055, 6\n",
            "168, 4540, 6.943636894226074, 7\n",
            "152, 207, 9.200267791748047, 9\n",
            "0, 417, 7.499501705169678, 9\n",
            "11, 419, 7.199754238128662, 7\n",
            "205, 1594, 5.194409370422363, 5\n",
            "171, 2405, 8.200368881225586, 9\n",
            "125, 1665, 9.527018547058105, 7\n",
            "134, 4531, 8.231111526489258, 10\n",
            "190, 2448, 7.639907360076904, 7\n",
            "164, 796, 8.23344612121582, 10\n",
            "98, 861, 7.865763187408447, 5\n",
            "233, 758, 7.566205978393555, 7\n",
            "63, 784, 7.060070514678955, 9\n",
            "81, 3741, 7.567624092102051, 6\n",
            "148, 1776, 4.842846870422363, 6\n",
            "18, 5174, 8.230788230895996, 7\n",
            "122, 907, 7.547611236572266, 8\n",
            "94, 1369, 8.902198791503906, 8\n",
            "181, 494, 8.116930961608887, 9\n",
            "27, 2352, 7.726477146148682, 9\n",
            "39, 201, 7.9633307456970215, 9\n",
            "149, 88, 5.948564529418945, 5\n",
            "97, 3788, 9.484199523925781, 10\n",
            "219, 790, 6.947811126708984, 6\n",
            "89, 664, 6.80368709564209, 6\n",
            "53, 50, 6.685463905334473, 7\n",
            "148, 417, 8.677532196044922, 10\n",
            "218, 33, 7.034111022949219, 7\n",
            "162, 1637, 7.953787326812744, 7\n",
            "221, 798, 6.859207630157471, 7\n",
            "212, 470, 7.787003517150879, 5\n",
            "172, 5458, 7.016146659851074, 7\n",
            "108, 150, 7.629720211029053, 2\n",
            "202, 42, 7.135919094085693, 10\n",
            "7, 2750, 8.149523735046387, 7\n",
            "172, 3588, 7.241331100463867, 6\n",
            "54, 430, 7.86862850189209, 9\n",
            "70, 437, 7.115912437438965, 7\n",
            "0, 228, 6.854235649108887, 7\n",
            "65, 156, 6.648815155029297, 8\n",
            "168, 2589, 6.6313934326171875, 5\n",
            "149, 4879, 7.192893981933594, 7\n",
            "212, 5198, 7.379777908325195, 3\n",
            "193, 3828, 8.075039863586426, 8\n",
            "133, 2739, 7.986469268798828, 8\n",
            "119, 200, 6.549084186553955, 6\n",
            "224, 286, 8.045342445373535, 4\n",
            "188, 2709, 6.932923316955566, 5\n",
            "172, 701, 8.642518997192383, 9\n",
            "107, 2762, 5.117500305175781, 7\n",
            "42, 784, 9.281916618347168, 10\n",
            "149, 3408, 6.378310680389404, 6\n",
            "86, 202, 8.339221954345703, 7\n",
            "111, 4669, 6.919126033782959, 8\n",
            "138, 52, 9.640987396240234, 9\n",
            "81, 4858, 6.017923355102539, 7\n",
            "75, 479, 7.294984340667725, 9\n",
            "123, 990, 4.852496147155762, 5\n",
            "193, 4297, 7.504633903503418, 8\n",
            "35, 4120, 7.4374237060546875, 9\n",
            "175, 4147, 6.750946998596191, 5\n",
            "163, 53, 7.632061958312988, 8\n",
            "105, 360, 8.049299240112305, 9\n",
            "226, 3605, 7.8773603439331055, 8\n",
            "114, 9, 8.914630889892578, 7\n",
            "9, 484, 7.218626499176025, 9\n",
            "116, 86, 7.442914009094238, 7\n",
            "59, 2616, 7.13560152053833, 6\n",
            "81, 2755, 6.967886924743652, 7\n",
            "149, 200, 5.275059223175049, 5\n",
            "75, 2675, 6.448279857635498, 9\n",
            "47, 133, 7.309224605560303, 8\n",
            "176, 496, 6.081089973449707, 7\n",
            "224, 4, 6.872071266174316, 7\n",
            "87, 2324, 5.831019878387451, 9\n",
            "22, 11, 8.397689819335938, 8\n",
            "144, 79, 7.470602989196777, 7\n",
            "162, 851, 7.17315149307251, 7\n",
            "220, 1917, 6.730944633483887, 7\n",
            "16, 292, 6.981667518615723, 9\n",
            "134, 3023, 6.205375671386719, 7\n",
            "117, 42, 8.110629081726074, 9\n",
            "147, 4636, 6.538435459136963, 8\n",
            "114, 2121, 7.244935989379883, 6\n",
            "156, 2408, 6.3663330078125, 6\n",
            "21, 1556, 4.413257598876953, 3\n",
            "66, 178, 8.261714935302734, 9\n",
            "134, 127, 5.971525192260742, 5\n",
            "224, 609, 6.945462226867676, 8\n",
            "148, 214, 8.31576156616211, 10\n",
            "28, 809, 7.780816555023193, 5\n",
            "27, 4022, 6.514824867248535, 8\n",
            "222, 78, 7.465147972106934, 9\n",
            "111, 1714, 7.493621826171875, 6\n",
            "172, 244, 7.3245368003845215, 6\n",
            "89, 948, 7.813565731048584, 8\n",
            "180, 1055, 7.4804534912109375, 1\n",
            "168, 2560, 5.15286922454834, 5\n",
            "53, 10, 7.885485649108887, 9\n",
            "146, 1331, 6.505800247192383, 4\n",
            "131, 784, 8.904727935791016, 8\n",
            "149, 2652, 5.49372673034668, 4\n",
            "234, 1286, 6.075315475463867, 7\n",
            "234, 3066, 6.701010704040527, 8\n",
            "74, 528, 6.693094253540039, 4\n",
            "122, 245, 7.829767227172852, 7\n",
            "153, 180, 8.210787773132324, 8\n",
            "229, 1049, 7.149393081665039, 8\n",
            "113, 403, 6.680035591125488, 7\n",
            "118, 1925, 6.823929786682129, 6\n",
            "90, 2645, 7.984400749206543, 6\n",
            "11, 53, 8.050172805786133, 9\n",
            "104, 3480, 8.20244026184082, 8\n",
            "85, 272, 6.771092414855957, 7\n",
            "61, 3137, 7.368481159210205, 8\n",
            "153, 2051, 7.629734992980957, 9\n",
            "104, 1141, 8.200040817260742, 9\n",
            "7, 2190, 5.1876420974731445, 5\n",
            "160, 827, 6.2973480224609375, 8\n",
            "197, 1425, 6.436802387237549, 6\n",
            "189, 203, 7.638928413391113, 8\n",
            "131, 3460, 7.00361442565918, 8\n",
            "171, 1450, 6.127689361572266, 8\n",
            "148, 769, 7.147664546966553, 6\n",
            "68, 3553, 7.407083511352539, 7\n",
            "38, 734, 7.866939544677734, 9\n",
            "111, 3175, 6.889380931854248, 7\n",
            "134, 3573, 5.495847225189209, 6\n",
            "131, 216, 5.721242904663086, 6\n",
            "111, 392, 8.040081024169922, 8\n",
            "133, 2805, 7.629513740539551, 8\n",
            "174, 474, 7.126657485961914, 7\n",
            "168, 296, 6.0592570304870605, 6\n",
            "7, 201, 6.851977348327637, 6\n",
            "233, 4093, 7.606042861938477, 10\n",
            "73, 173, 4.468600273132324, 5\n",
            "65, 61, 5.351655006408691, 8\n",
            "133, 111, 7.827996253967285, 8\n",
            "166, 1179, 5.928406715393066, 7\n",
            "156, 984, 5.866172790527344, 6\n",
            "205, 484, 5.794415473937988, 7\n",
            "65, 4192, 8.519231796264648, 8\n",
            "158, 224, 7.383610248565674, 8\n",
            "109, 47, 8.277443885803223, 8\n",
            "149, 2840, 6.7370147705078125, 4\n",
            "69, 26, 8.607114791870117, 8\n",
            "79, 1472, 5.0395402908325195, 7\n",
            "107, 158, 8.310681343078613, 7\n",
            "13, 141, 10.325342178344727, 9\n",
            "61, 1566, 7.993645668029785, 8\n",
            "94, 416, 8.579418182373047, 8\n",
            "24, 3924, 8.599759101867676, 8\n",
            "20, 483, 6.087514877319336, 1\n",
            "90, 2257, 8.625210762023926, 6\n",
            "87, 10, 8.202415466308594, 10\n",
            "221, 321, 8.237343788146973, 7\n",
            "115, 923, 4.847192764282227, 6\n",
            "191, 21, 7.599330902099609, 8\n",
            "123, 413, 6.1255693435668945, 5\n",
            "162, 791, 6.649383068084717, 7\n",
            "15, 2113, 9.247847557067871, 10\n",
            "216, 210, 6.507020950317383, 6\n",
            "121, 89, 7.602921009063721, 9\n",
            "81, 220, 8.475848197937012, 9\n",
            "212, 3228, 6.771868705749512, 8\n",
            "117, 20, 10.344562530517578, 6\n",
            "53, 226, 7.631767272949219, 5\n",
            "180, 323, 7.285042762756348, 10\n",
            "137, 1461, 7.393916130065918, 8\n",
            "96, 568, 7.887625694274902, 7\n",
            "202, 1644, 8.836811065673828, 8\n",
            "123, 789, 5.995553016662598, 6\n",
            "82, 5300, 6.698193550109863, 6\n",
            "161, 374, 7.1768717765808105, 9\n",
            "61, 2822, 6.035728454589844, 7\n",
            "134, 5024, 5.7418084144592285, 5\n",
            "89, 1330, 9.245745658874512, 10\n",
            "126, 24, 7.901190757751465, 8\n",
            "0, 2017, 8.097001075744629, 8\n",
            "89, 34, 7.9235453605651855, 8\n",
            "134, 2591, 7.260164737701416, 8\n",
            "223, 0, 7.876686096191406, 10\n",
            "81, 80, 8.078995704650879, 9\n",
            "146, 704, 5.709921836853027, 5\n",
            "111, 4030, 5.596106052398682, 6\n",
            "229, 1763, 8.151420593261719, 5\n",
            "41, 244, 5.921217918395996, 7\n",
            "125, 1007, 7.253081798553467, 10\n",
            "138, 22, 7.825983047485352, 8\n",
            "172, 1682, 6.831655979156494, 8\n",
            "171, 409, 6.7590250968933105, 7\n",
            "94, 44, 7.537786960601807, 7\n",
            "81, 781, 7.359066963195801, 6\n",
            "217, 2590, 7.956422805786133, 8\n",
            "26, 366, 7.740111351013184, 8\n",
            "104, 4108, 9.003095626831055, 9\n",
            "104, 5320, 9.831563949584961, 10\n",
            "231, 1497, 6.267677307128906, 9\n",
            "171, 4038, 6.032403945922852, 6\n",
            "92, 417, 7.521585464477539, 6\n",
            "104, 3561, 9.088560104370117, 5\n",
            "61, 40, 7.660088062286377, 8\n",
            "111, 5231, 5.741084098815918, 7\n",
            "137, 2448, 8.336774826049805, 8\n",
            "177, 366, 8.902886390686035, 9\n",
            "168, 1590, 7.54144287109375, 5\n",
            "162, 2311, 6.913338661193848, 7\n",
            "180, 335, 7.301345348358154, 9\n",
            "64, 1098, 8.985443115234375, 10\n",
            "68, 3472, 7.678651332855225, 7\n",
            "56, 524, 8.834810256958008, 10\n",
            "194, 265, 8.469141006469727, 10\n",
            "84, 4488, 8.128210067749023, 8\n",
            "153, 4795, 8.710888862609863, 9\n",
            "169, 1346, 7.342092514038086, 9\n",
            "171, 1111, 5.882723808288574, 2\n",
            "178, 4248, 6.918869972229004, 9\n",
            "40, 3457, 7.817183494567871, 8\n",
            "7, 2158, 6.268556118011475, 5\n",
            "122, 292, 6.73350191116333, 8\n",
            "134, 5458, 6.2541046142578125, 7\n",
            "229, 356, 5.9985504150390625, 6\n",
            "160, 393, 9.42624282836914, 10\n",
            "218, 633, 6.438987731933594, 7\n",
            "111, 1958, 6.31240701675415, 7\n",
            "156, 3025, 6.047944068908691, 7\n",
            "74, 839, 7.140222549438477, 7\n",
            "230, 813, 8.210127830505371, 4\n",
            "125, 203, 7.23829460144043, 8\n",
            "205, 2550, 6.969433307647705, 6\n",
            "172, 5672, 6.8056640625, 7\n",
            "4, 240, 8.275751113891602, 8\n",
            "190, 3000, 7.366048812866211, 7\n",
            "180, 677, 8.625411987304688, 10\n",
            "178, 2890, 8.295106887817383, 6\n",
            "7, 391, 7.484137535095215, 10\n",
            "81, 5343, 5.861660003662109, 7\n",
            "104, 4907, 7.513059616088867, 9\n",
            "74, 2637, 6.679933547973633, 7\n",
            "192, 427, 10.123405456542969, 10\n",
            "70, 171, 8.600790023803711, 9\n",
            "61, 114, 10.323461532592773, 9\n",
            "81, 2920, 6.27042818069458, 6\n",
            "104, 4721, 8.438149452209473, 10\n",
            "128, 839, 7.644531726837158, 7\n",
            "1, 3290, 6.884426593780518, 8\n",
            "87, 24, 8.958736419677734, 10\n",
            "222, 2003, 7.774754524230957, 10\n",
            "61, 1961, 8.195645332336426, 10\n",
            "7, 2012, 5.915249824523926, 7\n",
            "151, 2907, 6.184564590454102, 6\n",
            "228, 323, 6.715047836303711, 7\n",
            "172, 514, 8.21690845489502, 7\n",
            "89, 294, 7.687129974365234, 10\n",
            "55, 542, 9.465774536132812, 10\n",
            "164, 994, 7.780797004699707, 6\n",
            "172, 3301, 7.761789798736572, 8\n",
            "78, 12, 9.012821197509766, 10\n",
            "162, 3636, 7.89578914642334, 8\n",
            "166, 724, 7.272912979125977, 9\n",
            "66, 24, 6.952791213989258, 8\n",
            "45, 3629, 7.95391321182251, 10\n",
            "124, 124, 7.647163391113281, 8\n",
            "193, 3186, 9.155627250671387, 10\n",
            "184, 851, 7.714411735534668, 9\n",
            "75, 2676, 8.756027221679688, 10\n",
            "89, 3753, 7.9785566329956055, 10\n",
            "210, 1655, 7.2300310134887695, 6\n",
            "22, 3866, 6.816195011138916, 7\n",
            "84, 2113, 8.263138771057129, 8\n",
            "148, 2159, 7.6359357833862305, 8\n",
            "126, 115, 8.426966667175293, 8\n",
            "133, 2535, 7.805629730224609, 8\n",
            "234, 4858, 6.068271636962891, 5\n",
            "229, 229, 7.451655387878418, 7\n",
            "121, 2539, 6.864986419677734, 6\n",
            "111, 2645, 6.3042402267456055, 6\n",
            "176, 640, 5.963327884674072, 7\n",
            "7, 2671, 6.037365436553955, 4\n",
            "203, 1077, 5.739014625549316, 8\n",
            "149, 3430, 8.053621292114258, 9\n",
            "218, 1011, 7.021004676818848, 7\n",
            "188, 167, 7.0553178787231445, 6\n",
            "191, 103, 5.7616682052612305, 7\n",
            "167, 1325, 7.3315935134887695, 6\n",
            "146, 2352, 6.681623935699463, 8\n",
            "122, 877, 6.209928035736084, 8\n",
            "12, 2304, 7.450029373168945, 7\n",
            "73, 1331, 5.8585004806518555, 6\n",
            "22, 3434, 9.604291915893555, 9\n",
            "61, 2754, 7.407474994659424, 7\n",
            "81, 5214, 6.202788829803467, 7\n",
            "107, 5191, 6.806268692016602, 6\n",
            "192, 338, 9.836373329162598, 10\n",
            "168, 3989, 5.619582176208496, 5\n",
            "122, 947, 7.491484642028809, 8\n",
            "89, 322, 8.479473114013672, 10\n",
            "149, 0, 8.41309642791748, 7\n",
            "220, 4250, 7.033227920532227, 7\n",
            "224, 793, 7.054469585418701, 7\n",
            "222, 2798, 8.516256332397461, 9\n",
            "111, 2017, 8.295951843261719, 10\n",
            "81, 3796, 7.284936904907227, 6\n",
            "234, 5460, 7.670042037963867, 9\n",
            "171, 353, 8.008445739746094, 10\n",
            "199, 279, 7.134543418884277, 6\n",
            "168, 3018, 7.445412635803223, 6\n",
            "75, 967, 5.232845306396484, 4\n",
            "151, 2112, 6.337801933288574, 8\n",
            "166, 469, 9.771509170532227, 8\n",
            "7, 403, 6.084011077880859, 6\n",
            "40, 724, 8.155065536499023, 7\n",
            "122, 531, 7.802997589111328, 10\n",
            "39, 165, 8.167985916137695, 8\n",
            "111, 3288, 7.595515727996826, 9\n",
            "118, 9, 9.055294036865234, 8\n",
            "176, 1073, 5.3695902824401855, 6\n",
            "148, 2352, 7.402191638946533, 8\n",
            "156, 3448, 5.728254318237305, 6\n",
            "211, 2352, 9.82568645477295, 9\n",
            "118, 3191, 6.172243118286133, 7\n",
            "11, 812, 6.354926109313965, 8\n",
            "24, 309, 9.358929634094238, 10\n",
            "93, 458, 8.215604782104492, 6\n",
            "11, 92, 7.627778053283691, 8\n",
            "87, 124, 8.351598739624023, 10\n",
            "210, 1360, 7.993826866149902, 8\n",
            "140, 228, 6.375785827636719, 9\n",
            "134, 178, 7.572901248931885, 5\n",
            "222, 2963, 8.216217041015625, 7\n",
            "27, 3550, 7.008504867553711, 7\n",
            "153, 2812, 7.660576343536377, 9\n",
            "179, 99, 8.607464790344238, 10\n",
            "149, 2563, 5.691003322601318, 7\n",
            "229, 14, 7.326860427856445, 9\n",
            "1, 2196, 6.160340309143066, 6\n",
            "104, 3240, 7.680562973022461, 8\n",
            "214, 2750, 7.540678024291992, 8\n",
            "172, 4666, 6.629805088043213, 5\n",
            "85, 243, 8.592016220092773, 7\n",
            "68, 28, 9.524188995361328, 3\n",
            "112, 5703, 8.417110443115234, 9\n",
            "7, 814, 6.684104919433594, 5\n",
            "222, 2916, 7.10647439956665, 8\n",
            "104, 5402, 7.718507766723633, 9\n",
            "118, 2539, 6.3301520347595215, 6\n",
            "156, 2749, 8.146411895751953, 8\n",
            "24, 420, 8.198081016540527, 7\n",
            "214, 1911, 7.153576374053955, 8\n",
            "191, 264, 6.678273677825928, 7\n",
            "113, 23, 9.360910415649414, 9\n",
            "224, 18, 8.604793548583984, 9\n",
            "4, 3975, 7.966886520385742, 7\n",
            "156, 4242, 8.08348560333252, 6\n",
            "193, 2665, 7.0223164558410645, 8\n",
            "156, 3608, 5.398910999298096, 6\n",
            "180, 2138, 6.969766616821289, 4\n",
            "228, 186, 8.069031715393066, 8\n",
            "123, 580, 5.725787162780762, 3\n",
            "62, 1771, 8.382942199707031, 9\n",
            "107, 201, 7.916720390319824, 9\n",
            "165, 422, 6.706850051879883, 7\n",
            "107, 5520, 8.550289154052734, 7\n",
            "149, 4177, 7.491913795471191, 5\n",
            "14, 100, 8.825556755065918, 8\n",
            "89, 3313, 10.273422241210938, 10\n",
            "107, 684, 6.120270252227783, 5\n",
            "74, 447, 7.945882320404053, 7\n",
            "134, 5199, 6.58555793762207, 6\n",
            "144, 135, 8.590293884277344, 7\n",
            "122, 450, 6.964565277099609, 7\n",
            "111, 5524, 6.89914608001709, 8\n",
            "22, 212, 7.847267150878906, 9\n",
            "234, 1774, 7.275106430053711, 6\n",
            "172, 4085, 6.353748321533203, 7\n",
            "207, 50, 5.901232719421387, 1\n",
            "65, 3778, 5.832228660583496, 7\n",
            "196, 366, 7.929202556610107, 9\n",
            "197, 937, 7.142607688903809, 6\n",
            "66, 458, 6.842235565185547, 6\n",
            "196, 1450, 7.135705947875977, 7\n",
            "181, 207, 9.026520729064941, 9\n",
            "118, 1389, 5.0439934730529785, 6\n",
            "151, 360, 7.548439025878906, 6\n",
            "117, 417, 9.05512523651123, 10\n",
            "27, 3947, 9.80494499206543, 9\n",
            "202, 716, 7.842704772949219, 7\n",
            "151, 2524, 7.410816192626953, 9\n",
            "224, 51, 7.78048038482666, 8\n",
            "149, 355, 7.194028854370117, 9\n",
            "134, 181, 7.776381015777588, 9\n",
            "3, 141, 9.416970252990723, 10\n",
            "4, 1387, 7.364817142486572, 8\n",
            "123, 176, 7.2030348777771, 4\n",
            "178, 11, 7.457840919494629, 5\n",
            "91, 130, 9.416143417358398, 10\n",
            "148, 235, 5.752382755279541, 7\n",
            "128, 216, 6.861973762512207, 4\n",
            "131, 1446, 6.716794490814209, 6\n",
            "125, 3020, 7.715654373168945, 6\n",
            "187, 4953, 5.712987899780273, 8\n",
            "81, 150, 7.08336877822876, 6\n",
            "82, 243, 8.277215957641602, 9\n",
            "47, 507, 7.640647888183594, 7\n",
            "156, 5634, 7.1536865234375, 6\n",
            "28, 147, 7.02488374710083, 7\n",
            "149, 5062, 6.231462001800537, 6\n",
            "183, 181, 7.893294334411621, 7\n",
            "221, 167, 7.459061622619629, 8\n",
            "164, 1794, 8.68768310546875, 6\n",
            "125, 529, 7.2805681228637695, 8\n",
            "202, 486, 9.132355690002441, 7\n",
            "104, 1288, 7.233301162719727, 8\n",
            "211, 98, 8.195937156677246, 9\n",
            "105, 2069, 7.2928667068481445, 8\n",
            "115, 359, 6.761290550231934, 7\n",
            "73, 26, 6.844130516052246, 8\n",
            "188, 29, 6.401976108551025, 6\n",
            "192, 3540, 7.421717643737793, 9\n",
            "105, 1003, 9.293878555297852, 9\n",
            "144, 486, 8.515652656555176, 7\n",
            "212, 5716, 6.453927040100098, 9\n",
            "72, 168, 6.367561340332031, 5\n",
            "115, 505, 4.984408378601074, 8\n",
            "45, 3033, 8.906922340393066, 10\n",
            "25, 290, 6.189826965332031, 6\n",
            "31, 417, 9.96631908416748, 8\n",
            "96, 1947, 7.063454627990723, 9\n",
            "172, 1535, 7.7049407958984375, 8\n",
            "123, 51, 7.171906471252441, 8\n",
            "36, 1627, 10.123117446899414, 9\n",
            "210, 901, 8.734498977661133, 10\n",
            "82, 239, 8.699962615966797, 9\n",
            "168, 4253, 5.60845947265625, 6\n",
            "222, 3792, 8.941555976867676, 8\n",
            "161, 174, 8.445048332214355, 6\n",
            "232, 77, 7.9104413986206055, 8\n",
            "66, 1453, 6.110125541687012, 5\n",
            "136, 2439, 8.518653869628906, 9\n",
            "156, 2779, 7.25467586517334, 8\n",
            "192, 891, 9.061912536621094, 9\n",
            "91, 186, 7.8705596923828125, 8\n",
            "105, 2016, 6.9803361892700195, 8\n",
            "223, 2701, 7.476226806640625, 7\n",
            "118, 2347, 7.709373950958252, 7\n",
            "166, 133, 8.4273042678833, 8\n",
            "230, 160, 6.008903980255127, 6\n",
            "103, 165, 8.210143089294434, 6\n",
            "220, 3032, 8.522409439086914, 8\n",
            "90, 1532, 7.467324256896973, 6\n",
            "107, 4253, 6.387889385223389, 6\n",
            "97, 3728, 9.856512069702148, 8\n",
            "2, 20, 8.73185920715332, 4\n",
            "55, 1573, 10.651933670043945, 10\n",
            "230, 356, 7.000057697296143, 8\n",
            "37, 3179, 7.386104583740234, 7\n",
            "135, 232, 6.506372928619385, 4\n",
            "163, 244, 7.240118980407715, 7\n",
            "202, 2369, 7.300809860229492, 10\n",
            "212, 243, 8.576066017150879, 8\n",
            "163, 122, 7.0623064041137695, 8\n",
            "234, 3245, 8.420493125915527, 8\n",
            "156, 3629, 5.435041427612305, 5\n",
            "224, 228, 7.036518573760986, 10\n",
            "171, 678, 6.433599948883057, 6\n",
            "108, 25, 8.748936653137207, 10\n",
            "111, 4833, 8.399123191833496, 9\n",
            "156, 5576, 4.8234148025512695, 7\n",
            "23, 166, 6.901338577270508, 7\n",
            "107, 5508, 6.70205020904541, 7\n",
            "124, 1031, 9.321298599243164, 9\n",
            "175, 4143, 6.380228519439697, 5\n",
            "178, 4094, 6.726088523864746, 8\n",
            "216, 2196, 5.498130798339844, 8\n",
            "224, 2753, 6.945239067077637, 7\n",
            "210, 347, 7.448760032653809, 7\n",
            "149, 369, 5.8126654624938965, 6\n",
            "81, 4888, 7.427565097808838, 9\n",
            "153, 3854, 7.014645576477051, 10\n",
            "110, 99, 9.09585189819336, 10\n",
            "111, 1947, 7.147336959838867, 8\n",
            "118, 448, 7.663140773773193, 7\n",
            "175, 1311, 7.221905708312988, 9\n",
            "156, 3027, 6.699914932250977, 7\n",
            "134, 4043, 5.938098907470703, 6\n",
            "179, 215, 8.45743465423584, 9\n",
            "197, 771, 7.148405075073242, 8\n",
            "157, 53, 8.116545677185059, 9\n",
            "97, 4043, 8.435831069946289, 9\n",
            "230, 2312, 6.318572998046875, 7\n",
            "205, 984, 6.809670925140381, 6\n",
            "146, 2521, 5.78769588470459, 5\n",
            "235, 1326, 5.860854148864746, 6\n",
            "115, 1094, 5.659134864807129, 7\n",
            "129, 76, 6.717160701751709, 8\n",
            "82, 3751, 6.614444732666016, 10\n",
            "194, 1766, 9.88328742980957, 10\n",
            "197, 3384, 7.601343631744385, 7\n",
            "230, 954, 6.202014923095703, 9\n",
            "31, 292, 7.082015514373779, 8\n",
            "172, 4610, 6.93087911605835, 5\n",
            "133, 26, 9.17733097076416, 8\n",
            "222, 1098, 7.23256778717041, 9\n",
            "208, 120, 7.405336380004883, 9\n",
            "114, 647, 7.971851348876953, 9\n",
            "188, 429, 7.602704048156738, 7\n",
            "119, 175, 7.857037544250488, 8\n",
            "131, 423, 7.835221767425537, 7\n",
            "11, 485, 9.51769733428955, 6\n",
            "81, 5548, 5.639294147491455, 5\n",
            "180, 1118, 6.170353889465332, 4\n",
            "65, 2408, 7.5806427001953125, 6\n",
            "85, 5045, 8.44916820526123, 9\n",
            "122, 133, 7.166892051696777, 7\n",
            "193, 53, 8.28143310546875, 8\n",
            "111, 2549, 8.120952606201172, 7\n",
            "81, 2364, 5.311440944671631, 6\n",
            "58, 378, 10.080526351928711, 8\n",
            "206, 2478, 6.457046031951904, 6\n",
            "168, 4353, 4.988827705383301, 5\n",
            "4, 811, 7.559446334838867, 9\n",
            "19, 1758, 6.027196884155273, 4\n",
            "81, 4864, 5.864837646484375, 6\n",
            "149, 3888, 5.701894760131836, 8\n",
            "104, 1608, 10.065593719482422, 10\n",
            "197, 393, 8.712607383728027, 8\n",
            "187, 1328, 7.070713520050049, 9\n",
            "107, 2327, 5.730362892150879, 7\n",
            "4, 2659, 9.249610900878906, 9\n",
            "205, 410, 6.162398815155029, 5\n",
            "224, 424, 8.42773723602295, 8\n",
            "190, 1238, 6.981464385986328, 10\n",
            "160, 1088, 5.599069595336914, 8\n",
            "104, 76, 8.493509292602539, 8\n",
            "149, 2408, 7.233110427856445, 7\n",
            "168, 993, 7.368544578552246, 10\n",
            "107, 4878, 8.027973175048828, 7\n",
            "151, 21, 6.84276819229126, 7\n",
            "223, 3110, 6.533359527587891, 7\n",
            "73, 143, 5.861793518066406, 5\n",
            "229, 1539, 7.66973876953125, 6\n",
            "35, 438, 8.06406021118164, 7\n",
            "118, 1284, 5.8917388916015625, 7\n",
            "116, 321, 9.080938339233398, 9\n",
            "144, 14, 8.903847694396973, 9\n",
            "149, 3281, 7.918622016906738, 8\n",
            "229, 133, 6.477444648742676, 5\n",
            "87, 0, 7.991478443145752, 7\n",
            "129, 538, 6.237905502319336, 7\n",
            "223, 3905, 6.715845584869385, 7\n",
            "31, 3281, 7.285811424255371, 7\n",
            "210, 52, 9.477278709411621, 9\n",
            "185, 5162, 6.398138523101807, 7\n",
            "0, 1325, 7.635481357574463, 7\n",
            "111, 376, 4.557218074798584, 3\n",
            "104, 646, 8.665254592895508, 9\n",
            "143, 207, 7.904787063598633, 8\n",
            "0, 196, 5.724348068237305, 7\n",
            "7, 2272, 6.016294002532959, 6\n",
            "147, 5192, 5.463931560516357, 8\n",
            "28, 5, 6.877816200256348, 6\n",
            "107, 2055, 6.565585136413574, 7\n",
            "175, 2435, 6.35569429397583, 10\n",
            "133, 2125, 8.05310344696045, 7\n",
            "27, 1665, 8.95905876159668, 7\n",
            "190, 518, 6.982719421386719, 4\n",
            "3, 1316, 8.765109062194824, 9\n",
            "206, 2003, 7.314390659332275, 7\n",
            "162, 308, 7.945993423461914, 7\n",
            "58, 789, 7.150487899780273, 6\n",
            "108, 2919, 8.383204460144043, 9\n",
            "87, 2190, 6.960605621337891, 7\n",
            "58, 796, 7.947974681854248, 5\n",
            "73, 1362, 5.967906475067139, 4\n",
            "111, 3531, 5.775378227233887, 8\n",
            "67, 47, 6.736539840698242, 8\n",
            "96, 811, 7.032093048095703, 7\n",
            "210, 1278, 7.714230537414551, 10\n",
            "111, 3482, 6.876201152801514, 8\n",
            "133, 235, 6.909168243408203, 8\n",
            "75, 449, 7.597667217254639, 4\n",
            "162, 3910, 5.500677108764648, 5\n",
            "213, 186, 8.210057258605957, 8\n",
            "171, 375, 6.221320629119873, 7\n",
            "31, 613, 6.263503551483154, 7\n",
            "180, 1206, 6.344062805175781, 6\n",
            "168, 26, 7.594725608825684, 7\n",
            "146, 851, 6.618799209594727, 8\n",
            "89, 486, 9.05757999420166, 7\n",
            "148, 2506, 6.7727556228637695, 7\n",
            "59, 3045, 6.374190330505371, 8\n",
            "163, 901, 6.415738105773926, 8\n",
            "56, 322, 8.515408515930176, 7\n",
            "96, 144, 8.126351356506348, 7\n",
            "224, 117, 9.97030258178711, 6\n",
            "40, 2476, 7.721920967102051, 8\n",
            "172, 127, 6.545317649841309, 7\n",
            "65, 4606, 5.705656051635742, 6\n",
            "61, 153, 8.985931396484375, 9\n",
            "111, 276, 6.025514602661133, 7\n",
            "197, 517, 7.182085990905762, 7\n",
            "104, 758, 9.249692916870117, 10\n",
            "172, 1573, 7.562543869018555, 7\n",
            "65, 2151, 6.924793243408203, 8\n",
            "112, 98, 8.379660606384277, 10\n",
            "179, 1340, 6.454405307769775, 6\n",
            "40, 2225, 8.504251480102539, 9\n",
            "59, 21, 8.073997497558594, 2\n",
            "104, 2320, 7.934146881103516, 10\n",
            "123, 660, 6.2837677001953125, 6\n",
            "107, 3541, 7.975029945373535, 7\n",
            "59, 1455, 8.154890060424805, 6\n",
            "45, 167, 7.9329962730407715, 8\n",
            "27, 3113, 7.230219841003418, 8\n",
            "190, 45, 6.945173263549805, 7\n",
            "134, 4659, 5.962242126464844, 5\n",
            "134, 3972, 6.494873523712158, 5\n",
            "168, 4577, 4.821023941040039, 5\n",
            "176, 1467, 5.18895149230957, 6\n",
            "153, 3289, 9.245299339294434, 9\n",
            "176, 3275, 7.188652038574219, 7\n",
            "77, 131, 6.4557600021362305, 8\n",
            "192, 2583, 7.431151866912842, 9\n",
            "1, 4610, 6.490115642547607, 8\n",
            "226, 47, 7.968513488769531, 8\n",
            "64, 28, 10.43475341796875, 10\n",
            "87, 468, 7.7071027755737305, 10\n",
            "85, 2432, 8.051647186279297, 8\n",
            "147, 46, 7.494936466217041, 5\n",
            "81, 180, 6.086190223693848, 6\n",
            "198, 428, 6.572758197784424, 9\n",
            "112, 2432, 10.061102867126465, 9\n",
            "0, 418, 6.178044319152832, 4\n",
            "224, 213, 6.632066249847412, 9\n",
            "20, 3251, 5.896213531494141, 6\n",
            "118, 2518, 6.1997857093811035, 6\n",
            "63, 2056, 7.0710015296936035, 8\n",
            "233, 4509, 6.468924522399902, 5\n",
            "99, 18, 8.746463775634766, 7\n",
            "156, 3957, 5.180727958679199, 6\n",
            "143, 2229, 7.986706733703613, 8\n",
            "156, 3513, 6.205038070678711, 8\n",
            "171, 1, 8.084163665771484, 9\n",
            "202, 2886, 7.703597068786621, 6\n",
            "226, 114, 8.918761253356934, 8\n",
            "195, 1397, 7.901862621307373, 8\n",
            "93, 754, 7.896124839782715, 10\n",
            "195, 871, 9.168058395385742, 7\n",
            "180, 509, 8.040645599365234, 6\n",
            "205, 4277, 7.624654769897461, 8\n",
            "111, 1961, 7.498388290405273, 8\n",
            "178, 2210, 7.122467517852783, 8\n",
            "230, 34, 6.6493754386901855, 8\n",
            "1, 3243, 5.204364776611328, 4\n",
            "27, 2830, 6.626676559448242, 7\n",
            "162, 602, 8.565590858459473, 8\n",
            "104, 157, 8.294139862060547, 9\n",
            "199, 487, 7.910769939422607, 5\n",
            "117, 181, 9.555980682373047, 9\n",
            "20, 3216, 4.739490032196045, 6\n",
            "124, 655, 8.943589210510254, 10\n",
            "156, 3328, 6.347250938415527, 7\n",
            "157, 2628, 6.6386213302612305, 7\n",
            "59, 428, 8.664463996887207, 8\n",
            "230, 754, 6.832163333892822, 10\n",
            "208, 660, 7.285831928253174, 8\n",
            "118, 5584, 7.699913024902344, 9\n",
            "190, 2971, 6.111335754394531, 7\n",
            "111, 5453, 6.317139625549316, 5\n",
            "155, 1327, 7.4709391593933105, 7\n",
            "220, 3434, 8.766214370727539, 9\n",
            "234, 5111, 7.18226957321167, 9\n",
            "191, 704, 6.650444984436035, 7\n",
            "5, 175, 8.434309959411621, 10\n",
            "175, 4359, 6.551388740539551, 9\n",
            "45, 982, 7.7726898193359375, 10\n",
            "111, 1730, 6.01632833480835, 7\n",
            "168, 1507, 7.560790061950684, 5\n",
            "7, 2352, 6.59968900680542, 6\n",
            "220, 661, 7.721428871154785, 8\n",
            "85, 4893, 7.133536338806152, 8\n",
            "220, 199, 7.609628677368164, 8\n",
            "192, 1545, 7.402704238891602, 8\n",
            "193, 2839, 6.2898688316345215, 5\n",
            "124, 783, 7.302605628967285, 6\n",
            "172, 2764, 6.612859725952148, 7\n",
            "196, 1179, 5.060554504394531, 7\n",
            "104, 678, 8.020676612854004, 9\n",
            "219, 5609, 7.9456305503845215, 7\n",
            "43, 508, 7.2772111892700195, 8\n",
            "90, 542, 8.01970386505127, 7\n",
            "74, 1374, 5.3214430809021, 6\n",
            "104, 1171, 8.316655158996582, 7\n",
            "13, 350, 7.931250095367432, 7\n",
            "104, 42, 8.29415512084961, 9\n",
            "225, 1829, 7.0349225997924805, 8\n",
            "85, 543, 7.676177024841309, 7\n",
            "178, 4056, 6.855840682983398, 8\n",
            "117, 2876, 8.28222370147705, 7\n",
            "219, 368, 6.329894065856934, 8\n",
            "117, 223, 9.222352981567383, 9\n",
            "7, 1388, 6.394099235534668, 6\n",
            "121, 0, 9.095489501953125, 9\n",
            "150, 181, 8.28722858428955, 9\n",
            "41, 142, 7.180557727813721, 7\n",
            "47, 9, 10.183570861816406, 10\n",
            "118, 2196, 6.150425910949707, 9\n",
            "111, 2764, 6.984670162200928, 7\n",
            "229, 114, 8.393837928771973, 9\n",
            "168, 3045, 5.645638465881348, 5\n",
            "168, 1194, 5.887342929840088, 7\n",
            "104, 3713, 7.93126916885376, 9\n",
            "148, 1573, 7.21640157699585, 6\n",
            "105, 1449, 8.210911750793457, 6\n",
            "94, 2862, 8.407730102539062, 10\n",
            "191, 1340, 6.30441951751709, 7\n",
            "134, 734, 5.873317241668701, 7\n",
            "156, 5641, 6.002022743225098, 8\n",
            "111, 1782, 7.212793827056885, 6\n",
            "172, 5217, 7.967216491699219, 7\n",
            "193, 2256, 5.803140163421631, 7\n",
            "0, 2124, 6.81271505355835, 8\n",
            "122, 142, 7.858448505401611, 6\n",
            "79, 11, 8.0451078414917, 10\n",
            "149, 512, 7.742434978485107, 8\n",
            "111, 5612, 6.406205654144287, 8\n",
            "81, 5488, 7.56336784362793, 6\n",
            "132, 1144, 7.565640449523926, 10\n",
            "123, 884, 5.148757457733154, 8\n",
            "185, 201, 8.312948226928711, 7\n",
            "194, 145, 7.686774253845215, 6\n",
            "96, 172, 7.12004280090332, 7\n",
            "223, 3300, 7.1844682693481445, 9\n",
            "223, 4789, 7.380901336669922, 10\n",
            "151, 1353, 7.642081260681152, 9\n",
            "107, 421, 7.7873125076293945, 9\n",
            "178, 5725, 5.481109142303467, 8\n",
            "172, 393, 8.702730178833008, 7\n",
            "220, 518, 7.39076566696167, 6\n",
            "209, 273, 7.031418323516846, 8\n",
            "89, 3649, 10.554214477539062, 9\n",
            "23, 30, 7.718927383422852, 8\n",
            "104, 1480, 8.603754997253418, 10\n",
            "108, 392, 9.076395034790039, 10\n",
            "55, 2312, 9.839162826538086, 10\n",
            "162, 3796, 8.408380508422852, 9\n",
            "186, 398, 8.29650592803955, 9\n",
            "81, 3313, 8.402195930480957, 8\n",
            "148, 2690, 7.429945945739746, 7\n",
            "231, 443, 6.37163782119751, 8\n",
            "122, 413, 6.774530410766602, 7\n",
            "42, 793, 7.335797309875488, 9\n",
            "172, 737, 7.22443962097168, 7\n",
            "58, 438, 7.960655212402344, 7\n",
            "153, 3432, 9.530559539794922, 7\n",
            "65, 695, 6.762790679931641, 4\n",
            "221, 73, 6.882107734680176, 7\n",
            "156, 2853, 6.845148086547852, 9\n",
            "61, 356, 6.873789310455322, 8\n",
            "163, 83, 5.613764762878418, 6\n",
            "208, 2295, 8.509005546569824, 9\n",
            "89, 397, 8.751635551452637, 9\n",
            "144, 536, 8.445151329040527, 8\n",
            "75, 22, 6.873325824737549, 10\n",
            "220, 2689, 8.918420791625977, 10\n",
            "174, 1124, 8.15060043334961, 7\n",
            "118, 2231, 4.926148414611816, 4\n",
            "111, 3866, 8.13274097442627, 8\n",
            "107, 4939, 5.576815128326416, 6\n",
            "133, 199, 8.420492172241211, 7\n",
            "149, 1947, 6.257006645202637, 7\n",
            "206, 231, 6.703339576721191, 8\n",
            "133, 323, 7.609274864196777, 8\n",
            "115, 383, 6.31894588470459, 6\n",
            "168, 764, 6.994502067565918, 8\n",
            "41, 381, 5.2946457862854, 6\n",
            "168, 812, 5.713726043701172, 6\n",
            "111, 4459, 8.520116806030273, 8\n",
            "104, 4784, 7.425444602966309, 9\n",
            "43, 427, 8.643172264099121, 10\n",
            "180, 3609, 8.418203353881836, 10\n",
            "81, 5764, 7.7453413009643555, 9\n",
            "111, 1977, 5.819846153259277, 6\n",
            "111, 5704, 7.723615646362305, 7\n",
            "15, 438, 8.190343856811523, 6\n",
            "148, 426, 6.401619911193848, 7\n",
            "156, 2651, 6.053036212921143, 8\n",
            "184, 4086, 9.668325424194336, 8\n",
            "162, 3772, 7.231973171234131, 8\n",
            "199, 974, 6.118154048919678, 8\n",
            "37, 1508, 7.769857883453369, 6\n",
            "175, 1879, 5.680459499359131, 5\n",
            "192, 33, 7.461837291717529, 9\n",
            "233, 4992, 7.275197982788086, 9\n",
            "73, 73, 4.977065563201904, 5\n",
            "146, 2107, 6.227568626403809, 6\n",
            "151, 956, 7.766699314117432, 7\n",
            "191, 31, 6.909104824066162, 8\n",
            "99, 154, 7.418961524963379, 7\n",
            "213, 120, 5.977726459503174, 6\n",
            "168, 4685, 6.0124897956848145, 7\n",
            "168, 630, 5.639514446258545, 5\n",
            "99, 4711, 5.925772666931152, 6\n",
            "146, 758, 7.243193626403809, 6\n",
            "121, 8, 8.626541137695312, 8\n",
            "65, 364, 8.281429290771484, 9\n",
            "69, 227, 7.284899711608887, 7\n",
            "41, 404, 6.802477836608887, 7\n",
            "232, 401, 8.01664924621582, 9\n",
            "188, 279, 7.317477226257324, 6\n",
            "0, 76, 6.645577907562256, 8\n",
            "89, 43, 8.559000015258789, 7\n",
            "104, 31, 8.761517524719238, 8\n",
            "1, 137, 7.762958526611328, 8\n",
            "111, 4801, 6.940258026123047, 8\n",
            "148, 2963, 6.719608306884766, 7\n",
            "89, 3, 8.683036804199219, 8\n",
            "148, 2451, 7.962925910949707, 7\n",
            "191, 640, 7.502936363220215, 9\n",
            "208, 185, 8.362700462341309, 10\n",
            "145, 41, 7.314313888549805, 7\n",
            "75, 2535, 5.826692581176758, 7\n",
            "66, 1168, 6.465541839599609, 7\n",
            "107, 73, 7.377233505249023, 8\n",
            "220, 656, 7.565354347229004, 8\n",
            "81, 4546, 5.453566551208496, 8\n",
            "1, 30, 6.670903205871582, 6\n",
            "156, 3821, 5.951769828796387, 4\n",
            "111, 3426, 7.360602378845215, 7\n",
            "85, 5107, 8.227849006652832, 10\n",
            "122, 235, 5.824371337890625, 4\n",
            "134, 4376, 5.818698883056641, 6\n",
            "9, 154, 7.43660831451416, 7\n",
            "223, 3896, 5.92237663269043, 7\n",
            "85, 51, 8.073846817016602, 8\n",
            "192, 864, 8.50931167602539, 6\n",
            "0, 177, 6.652138710021973, 7\n",
            "172, 113, 8.00080680847168, 8\n",
            "181, 51, 8.664923667907715, 9\n",
            "134, 5556, 6.7582902908325195, 6\n",
            "171, 3625, 6.246892929077148, 7\n",
            "28, 49, 5.936060905456543, 7\n",
            "125, 2189, 7.240530490875244, 7\n",
            "107, 3197, 6.540430068969727, 7\n",
            "208, 227, 6.471919059753418, 7\n",
            "153, 2328, 7.484766006469727, 7\n",
            "123, 768, 6.507307052612305, 10\n",
            "111, 548, 6.385994911193848, 6\n",
            "151, 1001, 7.631895542144775, 8\n",
            "153, 99, 9.447182655334473, 8\n",
            "178, 5256, 8.192633628845215, 8\n",
            "94, 3506, 8.032297134399414, 9\n",
            "6, 1773, 5.902548789978027, 7\n",
            "81, 4105, 6.40943717956543, 7\n",
            "162, 2758, 5.459613800048828, 9\n",
            "149, 2676, 7.866316795349121, 10\n",
            "164, 1516, 6.9799370765686035, 8\n",
            "74, 1685, 6.812104225158691, 8\n",
            "81, 1582, 5.879247665405273, 4\n",
            "41, 870, 5.800454616546631, 6\n",
            "212, 31, 6.6193132400512695, 8\n",
            "207, 3975, 8.39659595489502, 7\n",
            "41, 99, 8.79642105102539, 8\n",
            "168, 905, 7.133084297180176, 6\n",
            "87, 202, 7.647055149078369, 10\n",
            "73, 214, 6.718051910400391, 3\n",
            "125, 3055, 6.953752517700195, 7\n",
            "157, 3386, 7.405701637268066, 7\n",
            "85, 6, 9.495562553405762, 8\n",
            "7, 1077, 5.290740013122559, 4\n",
            "111, 3927, 6.010562896728516, 5\n",
            "32, 250, 7.314385414123535, 10\n",
            "53, 322, 7.589738368988037, 7\n",
            "118, 2195, 7.729525089263916, 8\n",
            "33, 80, 9.120498657226562, 8\n",
            "186, 156, 7.08113956451416, 8\n",
            "190, 2658, 6.130448341369629, 5\n",
            "219, 2108, 7.898645877838135, 6\n",
            "172, 5344, 5.670559406280518, 7\n",
            "90, 97, 7.871834754943848, 9\n",
            "231, 1449, 7.768335342407227, 4\n",
            "128, 2976, 7.002843856811523, 10\n",
            "61, 2228, 6.686384677886963, 8\n",
            "226, 5362, 9.418987274169922, 9\n",
            "214, 1346, 7.136497497558594, 9\n",
            "137, 76, 8.439759254455566, 8\n",
            "213, 960, 7.612140655517578, 7\n",
            "162, 2091, 7.07521915435791, 8\n",
            "61, 335, 7.704643726348877, 7\n",
            "111, 2432, 8.71035099029541, 9\n",
            "58, 866, 6.8069868087768555, 6\n",
            "205, 403, 6.34525203704834, 6\n",
            "171, 3137, 6.987367153167725, 8\n",
            "117, 31, 9.25441837310791, 7\n",
            "107, 2222, 7.085247039794922, 6\n",
            "96, 424, 8.571078300476074, 8\n",
            "178, 2473, 7.320442199707031, 7\n",
            "153, 3186, 8.832771301269531, 10\n",
            "117, 2779, 10.447823524475098, 8\n",
            "104, 4127, 8.273637771606445, 9\n",
            "90, 2591, 9.158796310424805, 8\n",
            "151, 2107, 7.064044952392578, 5\n",
            "7, 212, 7.686228275299072, 8\n",
            "27, 4032, 7.489146709442139, 7\n",
            "153, 3118, 7.942209243774414, 5\n",
            "195, 864, 7.821605682373047, 7\n",
            "190, 2993, 5.921627044677734, 7\n",
            "107, 5372, 6.914321422576904, 6\n",
            "125, 2154, 7.873987197875977, 8\n",
            "168, 832, 5.862890243530273, 5\n",
            "90, 1373, 7.184913635253906, 7\n",
            "185, 146, 7.934654235839844, 7\n",
            "56, 1003, 10.708710670471191, 9\n",
            "7, 750, 8.166034698486328, 8\n",
            "208, 1446, 7.292743682861328, 8\n",
            "39, 280, 8.400758743286133, 6\n",
            "231, 1450, 6.638380527496338, 8\n",
            "196, 1361, 9.916618347167969, 10\n",
            "107, 76, 7.244168758392334, 10\n",
            "68, 2122, 8.341331481933594, 10\n",
            "134, 3035, 7.073574066162109, 7\n",
            "90, 80, 9.199169158935547, 10\n",
            "7, 1999, 8.074238777160645, 7\n",
            "179, 2352, 6.803193092346191, 7\n",
            "175, 201, 8.331145286560059, 6\n",
            "81, 4324, 8.66601276397705, 6\n",
            "194, 429, 7.927006721496582, 7\n",
            "107, 4950, 6.553463935852051, 6\n",
            "118, 4431, 4.620834827423096, 7\n",
            "117, 409, 8.609346389770508, 10\n",
            "211, 827, 8.717540740966797, 7\n",
            "148, 14, 7.890912055969238, 9\n",
            "207, 2113, 7.2496490478515625, 7\n",
            "84, 4166, 6.8185272216796875, 7\n",
            "24, 28, 8.954870223999023, 9\n",
            "12, 403, 7.106203079223633, 7\n",
            "210, 59, 7.540193557739258, 8\n",
            "196, 701, 8.547358512878418, 8\n",
            "25, 183, 6.683403968811035, 6\n",
            "143, 1469, 7.443076133728027, 7\n",
            "151, 893, 7.504593372344971, 7\n",
            "3, 1627, 9.886287689208984, 9\n",
            "107, 2642, 7.152853965759277, 8\n",
            "107, 503, 7.146177291870117, 8\n",
            "149, 2834, 6.350377082824707, 8\n",
            "168, 610, 5.7023162841796875, 6\n",
            "220, 3870, 6.534964084625244, 7\n",
            "92, 3434, 7.908763885498047, 9\n",
            "116, 1171, 7.699912071228027, 7\n",
            "78, 750, 10.148567199707031, 10\n",
            "89, 172, 7.557025909423828, 9\n",
            "96, 734, 6.582842826843262, 10\n",
            "146, 273, 5.588212490081787, 6\n",
            "153, 4251, 7.423665523529053, 8\n",
            "148, 1581, 6.879133224487305, 1\n",
            "81, 5722, 5.988269805908203, 7\n",
            "161, 38, 8.496164321899414, 9\n",
            "56, 3847, 8.50545597076416, 7\n",
            "7, 3195, 5.236063480377197, 6\n",
            "172, 39, 6.008086204528809, 7\n",
            "32, 216, 8.18554973602295, 10\n",
            "136, 789, 7.295350074768066, 8\n",
            "212, 1748, 5.933588981628418, 6\n",
            "172, 4383, 5.806133270263672, 6\n",
            "231, 946, 7.753763675689697, 6\n",
            "187, 198, 7.085070610046387, 2\n",
            "44, 1049, 8.092040061950684, 8\n",
            "190, 1218, 6.104336261749268, 5\n",
            "107, 4304, 5.976527214050293, 7\n",
            "216, 243, 7.335652828216553, 7\n",
            "156, 983, 5.065700054168701, 5\n",
            "222, 1361, 9.178377151489258, 10\n",
            "74, 1660, 5.423872470855713, 7\n",
            "83, 746, 8.765214920043945, 10\n",
            "73, 1346, 6.517799377441406, 8\n",
            "10, 2080, 7.011091232299805, 9\n",
            "151, 2830, 5.92513370513916, 6\n",
            "209, 591, 8.838068008422852, 7\n",
            "89, 4109, 8.868270874023438, 8\n",
            "66, 1033, 7.424840927124023, 7\n",
            "168, 2840, 6.945916652679443, 6\n",
            "9, 113, 9.198025703430176, 10\n",
            "210, 1044, 6.949715614318848, 8\n",
            "81, 286, 7.558293342590332, 6\n",
            "125, 602, 8.461442947387695, 7\n",
            "184, 4455, 6.175802707672119, 5\n",
            "186, 2107, 7.766018867492676, 8\n",
            "148, 110, 6.303032875061035, 6\n",
            "226, 5326, 8.000511169433594, 10\n",
            "25, 359, 6.542112827301025, 4\n",
            "0, 215, 8.080029487609863, 8\n",
            "18, 355, 8.609322547912598, 8\n",
            "149, 3942, 7.3623247146606445, 8\n",
            "3, 3661, 8.715231895446777, 7\n",
            "89, 4595, 9.343795776367188, 8\n",
            "73, 58, 5.151365280151367, 8\n",
            "81, 44, 7.275830268859863, 7\n",
            "111, 3274, 6.391995429992676, 9\n",
            "89, 848, 7.3599772453308105, 8\n",
            "81, 5609, 7.216489791870117, 8\n",
            "118, 3493, 7.173423767089844, 7\n",
            "91, 1456, 8.955339431762695, 7\n",
            "223, 4827, 5.738132476806641, 5\n",
            "0, 172, 6.306367874145508, 8\n",
            "172, 4953, 6.1360344886779785, 7\n",
            "108, 145, 7.822582244873047, 8\n",
            "210, 400, 7.911844730377197, 7\n",
            "134, 4637, 6.308233261108398, 6\n",
            "217, 158, 8.547713279724121, 6\n",
            "53, 351, 8.533206939697266, 6\n",
            "81, 5197, 6.091691017150879, 6\n",
            "168, 4904, 5.280059814453125, 6\n",
            "111, 3402, 6.58544921875, 9\n",
            "234, 3507, 7.728376388549805, 8\n",
            "90, 395, 8.455167770385742, 10\n",
            "146, 429, 7.164928913116455, 7\n",
            "153, 1, 9.037338256835938, 9\n",
            "178, 2590, 7.318291664123535, 6\n",
            "190, 2633, 5.87021017074585, 7\n",
            "111, 5228, 6.694761276245117, 8\n",
            "153, 101, 8.365129470825195, 8\n",
            "107, 425, 7.222042560577393, 8\n",
            "232, 1330, 8.27328872680664, 9\n",
            "40, 1179, 6.192792892456055, 4\n",
            "81, 2992, 7.902146339416504, 10\n",
            "126, 393, 9.014715194702148, 9\n",
            "89, 529, 7.345252990722656, 8\n",
            "134, 110, 6.631551742553711, 6\n",
            "110, 0, 8.689728736877441, 10\n",
            "89, 2679, 7.602787494659424, 8\n",
            "151, 91, 7.528777122497559, 8\n",
            "133, 165, 8.743566513061523, 9\n",
            "111, 2262, 7.317831039428711, 7\n",
            "128, 2269, 7.769510746002197, 8\n",
            "5, 503, 7.287128925323486, 8\n",
            "160, 366, 8.3720064163208, 10\n",
            "68, 1489, 7.295774459838867, 10\n",
            "153, 2566, 8.88701057434082, 9\n",
            "111, 2197, 6.25654935836792, 6\n",
            "117, 1346, 8.617086410522461, 10\n",
            "63, 2347, 6.923914432525635, 8\n",
            "190, 280, 6.7712483406066895, 5\n",
            "148, 3653, 6.3148298263549805, 7\n",
            "172, 2354, 6.589798927307129, 8\n",
            "190, 383, 7.281378269195557, 6\n",
            "114, 2617, 6.889859199523926, 7\n",
            "36, 473, 8.70310115814209, 8\n",
            "122, 1009, 6.789790153503418, 8\n",
            "115, 2, 7.3329362869262695, 8\n",
            "188, 1961, 7.514769554138184, 8\n",
            "172, 2576, 6.905010223388672, 7\n",
            "118, 276, 4.972702980041504, 7\n",
            "199, 199, 7.154478073120117, 7\n",
            "195, 202, 8.533173561096191, 9\n",
            "44, 512, 9.582023620605469, 9\n",
            "78, 365, 9.813874244689941, 10\n",
            "213, 47, 7.662178039550781, 9\n",
            "65, 215, 7.4208831787109375, 8\n",
            "204, 1682, 7.9336042404174805, 8\n",
            "167, 100, 8.01754379272461, 5\n",
            "162, 3724, 6.561495780944824, 8\n",
            "199, 178, 7.994788646697998, 9\n",
            "192, 194, 8.29464054107666, 8\n",
            "35, 238, 9.78227424621582, 7\n",
            "163, 9, 7.857190132141113, 8\n",
            "134, 1092, 5.277725696563721, 6\n",
            "148, 127, 6.668826103210449, 8\n",
            "147, 5225, 5.823638916015625, 9\n",
            "191, 51, 7.586886405944824, 9\n",
            "133, 174, 8.45388412475586, 8\n",
            "134, 5064, 6.166796684265137, 5\n",
            "40, 5307, 8.978089332580566, 10\n",
            "151, 790, 6.716513156890869, 7\n",
            "125, 175, 8.286907196044922, 8\n",
            "81, 5254, 7.956058502197266, 6\n",
            "156, 2489, 7.120169639587402, 7\n",
            "156, 5681, 3.8100109100341797, 5\n",
            "234, 345, 6.775716781616211, 7\n",
            "184, 3129, 5.30942440032959, 5\n",
            "193, 201, 7.9403557777404785, 7\n",
            "81, 1451, 5.663405418395996, 6\n",
            "207, 117, 8.220804214477539, 9\n",
            "198, 925, 6.119414806365967, 6\n",
            "219, 3490, 6.581943511962891, 7\n",
            "61, 2359, 9.091541290283203, 8\n",
            "124, 636, 7.830362319946289, 10\n",
            "197, 142, 8.395234107971191, 8\n",
            "87, 242, 7.62440299987793, 8\n",
            "81, 498, 7.910633087158203, 7\n",
            "162, 2286, 6.437047004699707, 8\n",
            "202, 266, 7.605485916137695, 9\n",
            "157, 2986, 7.701586723327637, 6\n",
            "186, 273, 7.076123237609863, 8\n",
            "118, 2279, 5.368769645690918, 7\n",
            "89, 3137, 7.786206245422363, 9\n",
            "111, 20, 8.274636268615723, 10\n",
            "98, 790, 7.497223377227783, 8\n",
            "162, 2754, 6.713686943054199, 7\n",
            "114, 2391, 5.372219085693359, 6\n",
            "108, 1547, 7.74656343460083, 7\n",
            "133, 710, 8.735051155090332, 9\n",
            "194, 2, 8.829351425170898, 9\n",
            "61, 2830, 7.100883483886719, 6\n",
            "133, 186, 8.402164459228516, 8\n",
            "120, 3, 7.610763072967529, 8\n",
            "134, 1448, 6.288209915161133, 6\n",
            "133, 2824, 8.617961883544922, 9\n",
            "81, 1454, 6.426705837249756, 6\n",
            "133, 1769, 6.382433891296387, 7\n",
            "24, 3434, 9.864639282226562, 10\n",
            "134, 5102, 5.666837215423584, 6\n",
            "153, 2649, 7.767580032348633, 10\n",
            "21, 602, 7.2648773193359375, 9\n",
            "139, 6, 9.61408519744873, 10\n",
            "162, 874, 8.226475715637207, 8\n",
            "213, 429, 8.726536750793457, 9\n",
            "193, 3650, 6.84145975112915, 7\n",
            "188, 56, 7.4578857421875, 7\n",
            "220, 239, 8.808296203613281, 10\n",
            "7, 760, 4.618488311767578, 3\n",
            "168, 527, 5.722743034362793, 6\n",
            "0, 176, 7.662613391876221, 7\n",
            "81, 5116, 7.415658950805664, 8\n",
            "168, 1762, 5.560754776000977, 6\n",
            "137, 2880, 7.369832992553711, 8\n",
            "172, 4827, 6.54231071472168, 6\n",
            "99, 2833, 8.150675773620605, 7\n",
            "194, 1729, 7.617083549499512, 9\n",
            "210, 746, 9.893881797790527, 9\n",
            "128, 40, 6.289868354797363, 5\n",
            "168, 1171, 5.725069999694824, 5\n",
            "11, 1746, 5.8386101722717285, 9\n",
            "87, 381, 6.46795654296875, 6\n",
            "111, 171, 7.840163230895996, 7\n",
            "118, 928, 6.337584495544434, 6\n",
            "118, 3592, 5.8453545570373535, 7\n",
            "185, 4219, 6.316715717315674, 7\n",
            "212, 4665, 5.859490394592285, 8\n",
            "226, 2973, 7.901069164276123, 7\n",
            "124, 214, 8.691329002380371, 10\n",
            "190, 227, 6.015097141265869, 8\n",
            "81, 49, 6.71650505065918, 7\n",
            "170, 369, 7.401861190795898, 7\n",
            "131, 475, 6.7527852058410645, 7\n",
            "81, 5225, 6.541497230529785, 8\n",
            "66, 773, 6.144101619720459, 6\n",
            "210, 1898, 7.912453651428223, 9\n",
            "151, 170, 7.8791728019714355, 7\n",
            "161, 138, 8.275249481201172, 7\n",
            "118, 2831, 6.876484394073486, 7\n",
            "89, 2320, 8.157766342163086, 9\n",
            "213, 1043, 6.629702568054199, 7\n",
            "107, 112, 7.641162872314453, 8\n",
            "7, 310, 5.837119102478027, 6\n",
            "155, 716, 7.901033401489258, 10\n",
            "40, 220, 9.679644584655762, 9\n",
            "226, 5107, 9.051618576049805, 9\n",
            "27, 3573, 6.936112403869629, 8\n",
            "138, 981, 6.926018714904785, 7\n",
            "7, 222, 6.737621784210205, 5\n",
            "134, 1349, 6.795197010040283, 8\n",
            "94, 324, 7.77478551864624, 7\n",
            "100, 181, 8.802202224731445, 9\n",
            "206, 1457, 7.4692277908325195, 6\n",
            "27, 2595, 7.710248947143555, 8\n",
            "125, 744, 7.676845073699951, 8\n",
            "151, 498, 7.7177205085754395, 7\n",
            "226, 3330, 9.434389114379883, 8\n",
            "111, 5221, 8.731486320495605, 8\n",
            "195, 2014, 7.811633110046387, 9\n",
            "163, 475, 6.09221076965332, 6\n",
            "151, 566, 6.666754722595215, 6\n",
            "223, 5259, 5.911579132080078, 7\n",
            "126, 426, 6.76025390625, 5\n",
            "156, 5617, 6.238929271697998, 6\n",
            "76, 345, 6.352217197418213, 8\n",
            "212, 5675, 7.300734519958496, 7\n",
            "135, 10, 8.284272193908691, 8\n",
            "149, 3490, 6.3686299324035645, 5\n",
            "94, 2498, 7.1675920486450195, 9\n",
            "137, 1814, 7.384517669677734, 8\n",
            "41, 754, 5.934735298156738, 3\n",
            "104, 5289, 8.813214302062988, 9\n",
            "107, 5698, 5.887264728546143, 6\n",
            "150, 655, 7.695748805999756, 7\n",
            "172, 3905, 7.681690216064453, 8\n",
            "178, 5483, 7.954964637756348, 6\n",
            "104, 1330, 9.308639526367188, 10\n",
            "56, 4789, 8.688878059387207, 10\n",
            "156, 4036, 5.287117958068848, 8\n",
            "104, 2761, 8.181997299194336, 8\n",
            "112, 2107, 8.922633171081543, 6\n",
            "118, 3634, 6.004729270935059, 7\n",
            "164, 194, 8.34263801574707, 7\n",
            "90, 98, 9.403960227966309, 10\n",
            "184, 149, 6.597519874572754, 7\n",
            "77, 244, 6.820503234863281, 8\n",
            "111, 4697, 7.427083969116211, 8\n",
            "171, 584, 5.721993446350098, 8\n",
            "147, 70, 7.525118827819824, 7\n",
            "134, 4795, 6.545988082885742, 6\n",
            "168, 5030, 6.390674114227295, 7\n",
            "31, 1342, 7.41886043548584, 7\n",
            "104, 2974, 7.7606353759765625, 8\n",
            "151, 2904, 7.242421627044678, 6\n",
            "133, 428, 9.611727714538574, 9\n",
            "100, 166, 7.006628036499023, 8\n",
            "0, 173, 4.962788105010986, 5\n",
            "85, 111, 6.815473556518555, 6\n",
            "146, 291, 6.744607448577881, 10\n",
            "172, 2618, 7.815360069274902, 8\n",
            "233, 3897, 6.5034894943237305, 8\n",
            "168, 3771, 5.824034214019775, 6\n",
            "89, 3711, 8.576468467712402, 7\n",
            "16, 58, 7.238133907318115, 6\n",
            "190, 2692, 6.8472089767456055, 5\n",
            "125, 495, 7.579235553741455, 10\n",
            "27, 15, 8.102803230285645, 8\n",
            "157, 280, 6.804602146148682, 7\n",
            "81, 5401, 7.84954309463501, 10\n",
            "111, 4162, 6.309831619262695, 8\n",
            "190, 4038, 6.232144832611084, 7\n",
            "148, 3049, 7.479703426361084, 7\n",
            "108, 143, 7.087403774261475, 8\n",
            "131, 173, 5.618647575378418, 6\n",
            "183, 158, 7.935043811798096, 8\n",
            "33, 18, 8.303215026855469, 7\n",
            "197, 99, 9.8021821975708, 9\n",
            "75, 167, 7.149213790893555, 6\n",
            "82, 4930, 8.564902305603027, 8\n",
            "151, 3, 7.039884567260742, 8\n",
            "143, 1075, 8.309571266174316, 9\n",
            "27, 1726, 7.3946332931518555, 9\n",
            "104, 3743, 9.261739730834961, 8\n",
            "172, 3692, 7.168830871582031, 7\n",
            "216, 518, 6.566427707672119, 8\n",
            "35, 4087, 8.564277648925781, 9\n",
            "185, 4880, 7.370814800262451, 8\n",
            "115, 1192, 5.049611568450928, 7\n",
            "134, 5112, 6.776108741760254, 7\n",
            "107, 3667, 6.6095991134643555, 7\n",
            "136, 39, 7.654662609100342, 7\n",
            "63, 373, 4.749300479888916, 7\n",
            "233, 1824, 9.386930465698242, 7\n",
            "107, 453, 7.339202880859375, 6\n",
            "151, 18, 8.00287914276123, 5\n",
            "104, 5758, 8.337051391601562, 8\n",
            "25, 3052, 5.942309856414795, 5\n",
            "134, 4128, 5.87007474899292, 5\n",
            "193, 200, 5.959105014801025, 5\n",
            "81, 5542, 7.691328048706055, 5\n",
            "73, 2015, 5.536308288574219, 4\n",
            "114, 138, 6.938582897186279, 7\n",
            "210, 493, 6.219540596008301, 6\n",
            "10, 3509, 9.226425170898438, 9\n",
            "149, 47, 6.998617172241211, 7\n",
            "192, 3620, 8.363015174865723, 8\n",
            "51, 30, 6.87549352645874, 8\n",
            "172, 4982, 6.405104637145996, 8\n",
            "162, 1358, 7.651028633117676, 9\n",
            "197, 900, 7.671299457550049, 5\n",
            "118, 227, 5.509809970855713, 7\n",
            "20, 308, 6.00282096862793, 5\n",
            "65, 3960, 7.658094882965088, 7\n",
            "59, 759, 6.585171699523926, 4\n",
            "42, 578, 9.37109088897705, 7\n",
            "74, 379, 6.178438663482666, 5\n",
            "73, 41, 5.955049514770508, 5\n",
            "162, 1286, 7.0359086990356445, 8\n",
            "222, 3110, 8.022331237792969, 8\n",
            "68, 2700, 6.668499946594238, 7\n",
            "190, 2925, 6.271519660949707, 8\n",
            "79, 116, 7.674501419067383, 8\n",
            "54, 2439, 9.011751174926758, 9\n",
            "66, 615, 5.254829406738281, 7\n",
            "166, 903, 7.307826042175293, 9\n",
            "107, 4764, 5.923256874084473, 6\n",
            "39, 802, 7.563904762268066, 8\n",
            "216, 42, 5.5284647941589355, 8\n",
            "201, 202, 8.10490608215332, 7\n",
            "190, 3127, 6.766087055206299, 9\n",
            "153, 139, 7.805878639221191, 4\n",
            "210, 10, 8.05555534362793, 8\n",
            "104, 5560, 7.880903720855713, 9\n",
            "104, 494, 7.777589797973633, 8\n",
            "69, 392, 8.261456489562988, 7\n",
            "148, 3447, 7.017941474914551, 6\n",
            "7, 2863, 7.781254768371582, 8\n",
            "162, 3905, 7.927426338195801, 9\n",
            "111, 3766, 8.150620460510254, 3\n",
            "111, 3321, 6.046342849731445, 7\n",
            "21, 2272, 5.325026512145996, 7\n",
            "11, 2320, 6.622136116027832, 7\n",
            "115, 1541, 6.14028263092041, 6\n",
            "172, 3632, 7.7214250564575195, 7\n",
            "110, 88, 7.055943489074707, 7\n",
            "100, 127, 7.005603313446045, 7\n",
            "220, 3836, 6.962414741516113, 9\n",
            "39, 616, 6.406485557556152, 3\n",
            "196, 965, 6.3937506675720215, 5\n",
            "151, 1457, 6.2568511962890625, 7\n",
            "107, 619, 7.2013750076293945, 7\n",
            "151, 2374, 6.095709800720215, 6\n",
            "81, 3968, 5.73118782043457, 6\n",
            "89, 4208, 9.134979248046875, 9\n",
            "134, 4131, 6.39289665222168, 7\n",
            "137, 3133, 6.292889595031738, 8\n",
            "54, 279, 8.951299667358398, 10\n",
            "134, 5007, 7.132901668548584, 7\n",
            "199, 961, 7.78654670715332, 8\n",
            "111, 1460, 7.705186367034912, 7\n",
            "66, 129, 5.972586631774902, 6\n",
            "111, 55, 8.256650924682617, 8\n",
            "172, 1814, 6.997165679931641, 7\n",
            "226, 4498, 7.305947303771973, 8\n",
            "153, 78, 8.239424705505371, 9\n",
            "118, 901, 7.201480388641357, 7\n",
            "220, 1069, 6.370255470275879, 6\n",
            "64, 746, 10.395293235778809, 8\n",
            "71, 201, 7.398708343505859, 9\n",
            "191, 273, 6.435779571533203, 7\n",
            "57, 2915, 8.079639434814453, 6\n",
            "173, 607, 7.031039714813232, 8\n",
            "10, 2, 9.581965446472168, 10\n",
            "180, 23, 8.588245391845703, 10\n",
            "134, 4783, 4.935546875, 4\n",
            "167, 491, 7.797024250030518, 8\n",
            "168, 3357, 5.60481071472168, 6\n",
            "202, 2819, 7.804296493530273, 7\n",
            "117, 122, 8.983107566833496, 9\n",
            "190, 1905, 8.251849174499512, 4\n",
            "168, 2774, 6.217110633850098, 6\n",
            "208, 1539, 8.576482772827148, 9\n",
            "104, 79, 9.263449668884277, 10\n",
            "107, 2520, 6.592977523803711, 8\n",
            "117, 2566, 9.729364395141602, 8\n",
            "81, 3532, 6.081679344177246, 7\n",
            "128, 74, 8.001946449279785, 10\n",
            "39, 535, 6.867682456970215, 6\n",
            "89, 2385, 9.168998718261719, 9\n",
            "229, 3882, 7.577445983886719, 7\n",
            "193, 4317, 7.961984634399414, 8\n",
            "65, 137, 7.7213850021362305, 8\n",
            "67, 14, 7.138771057128906, 7\n",
            "230, 1804, 6.005970001220703, 5\n",
            "59, 3898, 8.2113037109375, 3\n",
            "111, 2616, 6.8908467292785645, 5\n",
            "12, 378, 8.770904541015625, 8\n",
            "131, 171, 7.991208076477051, 8\n",
            "7, 2718, 7.325284957885742, 8\n",
            "81, 4042, 8.558467864990234, 8\n",
            "123, 157, 6.26397705078125, 6\n",
            "165, 146, 6.2940263748168945, 10\n",
            "7, 2700, 5.6070556640625, 6\n",
            "148, 3060, 8.346574783325195, 8\n",
            "196, 613, 6.238170146942139, 7\n",
            "75, 697, 6.713570594787598, 5\n",
            "68, 2659, 8.956371307373047, 10\n",
            "160, 680, 5.770962715148926, 9\n",
            "71, 1490, 5.037680625915527, 4\n",
            "89, 4458, 9.144752502441406, 9\n",
            "168, 3171, 6.140341758728027, 6\n",
            "111, 5415, 6.796471118927002, 9\n",
            "95, 202, 7.18907356262207, 8\n",
            "182, 165, 8.991841316223145, 8\n",
            "93, 422, 7.712244510650635, 9\n",
            "230, 168, 7.183910369873047, 7\n",
            "122, 303, 6.37849235534668, 7\n",
            "190, 1685, 6.834780693054199, 5\n",
            "99, 45, 7.185418128967285, 7\n",
            "210, 150, 7.979298114776611, 8\n",
            "89, 1388, 8.320300102233887, 8\n",
            "224, 2882, 6.713680267333984, 7\n",
            "81, 131, 6.6168718338012695, 7\n",
            "111, 4164, 7.836115837097168, 6\n",
            "205, 3910, 5.8963093757629395, 7\n",
            "207, 110, 6.592229843139648, 9\n",
            "151, 2256, 5.9431657791137695, 5\n",
            "11, 223, 6.249292373657227, 7\n",
            "35, 982, 6.471327304840088, 8\n",
            "193, 4306, 6.671738624572754, 8\n",
            "111, 2660, 6.41358757019043, 7\n",
            "229, 122, 7.695094108581543, 9\n",
            "185, 232, 6.516104698181152, 6\n",
            "128, 1465, 7.197345733642578, 10\n",
            "7, 560, 6.578675270080566, 6\n",
            "107, 272, 6.724410057067871, 8\n",
            "172, 3550, 7.019254207611084, 6\n",
            "226, 5042, 8.448443412780762, 7\n",
            "135, 454, 7.253900527954102, 9\n",
            "111, 4205, 7.364913463592529, 7\n",
            "186, 1267, 7.904321670532227, 9\n",
            "125, 370, 6.84418249130249, 6\n",
            "81, 4996, 7.454775810241699, 6\n",
            "111, 4414, 7.312253952026367, 6\n",
            "0, 436, 7.0344743728637695, 7\n",
            "111, 2743, 5.75989294052124, 7\n",
            "77, 716, 7.876250267028809, 8\n",
            "70, 1179, 5.708107948303223, 7\n",
            "85, 1316, 9.389891624450684, 8\n",
            "6, 937, 6.530344486236572, 8\n",
            "162, 1688, 7.851251602172852, 8\n",
            "107, 118, 7.085179805755615, 7\n",
            "122, 370, 6.046976089477539, 7\n",
            "172, 2630, 6.4452009201049805, 5\n",
            "53, 1075, 7.860798358917236, 7\n",
            "168, 3213, 5.336663246154785, 6\n",
            "201, 2408, 8.751004219055176, 7\n",
            "107, 5525, 7.08588171005249, 6\n",
            "196, 1686, 6.828196048736572, 7\n",
            "168, 747, 6.459759712219238, 5\n",
            "118, 240, 7.953649520874023, 8\n",
            "191, 2257, 6.900433540344238, 7\n",
            "125, 691, 10.499748229980469, 10\n",
            "187, 273, 6.458299160003662, 3\n",
            "129, 1758, 6.365986347198486, 6\n",
            "171, 124, 7.0592498779296875, 10\n",
            "59, 150, 7.531455039978027, 7\n",
            "206, 2732, 6.18165397644043, 5\n",
            "146, 1922, 5.195209503173828, 5\n",
            "190, 1466, 6.307971954345703, 6\n",
            "178, 10, 7.064276695251465, 5\n",
            "66, 67, 6.372158527374268, 6\n",
            "222, 1771, 8.40106201171875, 10\n",
            "192, 1963, 8.411460876464844, 8\n",
            "99, 4789, 8.888260841369629, 9\n",
            "11, 2363, 5.639275074005127, 4\n",
            "111, 2672, 7.988720417022705, 6\n",
            "188, 2639, 7.551801681518555, 8\n",
            "96, 996, 8.508134841918945, 8\n",
            "7, 1824, 8.76428508758545, 6\n",
            "168, 1939, 5.446033954620361, 5\n",
            "192, 1353, 9.823982238769531, 10\n",
            "157, 2191, 6.7697343826293945, 8\n",
            "229, 321, 7.263762474060059, 8\n",
            "16, 3254, 6.983909606933594, 5\n",
            "123, 795, 5.974295139312744, 10\n",
            "81, 815, 6.157470703125, 5\n",
            "40, 1998, 8.104252815246582, 8\n",
            "15, 2003, 8.625408172607422, 8\n",
            "27, 1901, 5.937435150146484, 6\n",
            "125, 112, 7.900108814239502, 8\n",
            "197, 445, 7.750789165496826, 8\n",
            "118, 736, 5.267739295959473, 3\n",
            "104, 5706, 8.330964088439941, 10\n",
            "81, 5520, 8.347512245178223, 8\n",
            "219, 52, 9.028840065002441, 9\n",
            "168, 2401, 5.160135746002197, 5\n",
            "133, 1488, 8.117959022521973, 8\n",
            "111, 2856, 6.84161376953125, 8\n",
            "96, 366, 8.5343017578125, 6\n",
            "153, 750, 9.241291046142578, 10\n",
            "123, 830, 5.826623916625977, 8\n",
            "122, 4721, 6.671232223510742, 8\n",
            "202, 2627, 7.310898780822754, 8\n",
            "230, 789, 5.113121509552002, 5\n",
            "107, 5246, 7.221767902374268, 6\n",
            "82, 2395, 6.322122097015381, 8\n",
            "228, 827, 7.338890075683594, 7\n",
            "81, 5798, 6.301612377166748, 8\n",
            "230, 2229, 7.668822288513184, 7\n",
            "151, 35, 6.376015663146973, 8\n",
            "84, 4438, 7.843367576599121, 7\n",
            "87, 38, 7.8167572021484375, 8\n",
            "162, 2945, 7.7455244064331055, 8\n",
            "32, 25, 10.769405364990234, 10\n",
            "230, 603, 8.293269157409668, 7\n",
            "148, 784, 7.977112770080566, 8\n",
            "121, 38, 8.270896911621094, 10\n",
            "4, 15, 8.343344688415527, 7\n",
            "97, 1774, 9.819056510925293, 9\n",
            "179, 23, 7.625069618225098, 9\n",
            "107, 4930, 8.710604667663574, 7\n",
            "18, 5658, 6.86065673828125, 7\n",
            "194, 113, 9.102855682373047, 8\n",
            "202, 1325, 8.613020896911621, 9\n",
            "171, 3422, 7.142678260803223, 8\n",
            "183, 353, 7.5268378257751465, 8\n",
            "107, 74, 7.272851467132568, 8\n",
            "124, 1503, 6.911692142486572, 6\n",
            "190, 2576, 6.930497169494629, 7\n",
            "168, 78, 6.491965293884277, 6\n",
            "4, 734, 6.702620506286621, 9\n",
            "146, 536, 7.015762805938721, 5\n",
            "111, 4329, 8.730525016784668, 8\n",
            "20, 504, 4.478987693786621, 6\n",
            "27, 2843, 7.230548858642578, 6\n",
            "203, 28, 8.05168342590332, 6\n",
            "94, 2876, 8.995858192443848, 9\n",
            "171, 2069, 7.967975616455078, 8\n",
            "213, 424, 8.131428718566895, 8\n",
            "118, 409, 6.454294204711914, 7\n",
            "104, 4502, 10.063384056091309, 9\n",
            "121, 228, 8.393315315246582, 6\n",
            "122, 307, 8.64022445678711, 7\n",
            "81, 5765, 5.6610612869262695, 6\n",
            "175, 868, 6.177349090576172, 6\n",
            "56, 1045, 7.630183219909668, 8\n",
            "65, 3552, 8.956853866577148, 10\n",
            "153, 338, 8.481474876403809, 9\n",
            "186, 3196, 6.813616752624512, 7\n",
            "174, 351, 7.162102699279785, 6\n",
            "206, 202, 6.821079254150391, 9\n",
            "205, 3866, 7.3021440505981445, 6\n",
            "212, 81, 6.9797821044921875, 9\n",
            "148, 484, 5.946447372436523, 6\n",
            "212, 339, 5.798271179199219, 6\n",
            "156, 2654, 6.17894172668457, 8\n",
            "111, 489, 7.3551788330078125, 7\n",
            "134, 4417, 6.073912620544434, 5\n",
            "133, 2868, 8.375868797302246, 8\n",
            "167, 41, 6.639753341674805, 5\n",
            "151, 794, 6.311792373657227, 7\n",
            "151, 2449, 6.676494598388672, 7\n",
            "115, 158, 8.1292085647583, 6\n",
            "173, 2749, 9.428180694580078, 9\n",
            "111, 1815, 8.430461883544922, 9\n",
            "111, 3902, 6.427265644073486, 2\n",
            "75, 2745, 5.862469673156738, 6\n",
            "111, 3300, 8.21284008026123, 9\n",
            "222, 2929, 8.283288955688477, 10\n",
            "10, 3508, 10.466045379638672, 9\n",
            "20, 4053, 5.655657768249512, 6\n",
            "162, 1197, 8.722516059875488, 8\n",
            "107, 492, 7.120352745056152, 6\n",
            "111, 4274, 7.173954010009766, 9\n",
            "138, 788, 8.105541229248047, 9\n",
            "162, 298, 8.415156364440918, 8\n",
            "96, 856, 8.185237884521484, 7\n",
            "63, 202, 6.338190078735352, 5\n",
            "107, 359, 7.485687732696533, 8\n",
            "81, 4295, 6.239336013793945, 6\n",
            "89, 1417, 8.270549774169922, 7\n",
            "157, 3747, 6.891083717346191, 6\n",
            "211, 1325, 10.107852935791016, 8\n",
            "163, 25, 7.658080101013184, 9\n",
            "168, 2288, 4.696178913116455, 5\n",
            "174, 1539, 8.187410354614258, 3\n",
            "166, 16, 7.864366054534912, 4\n",
            "168, 2731, 6.311915397644043, 6\n",
            "5, 299, 7.083774089813232, 8\n",
            "202, 2364, 6.34613037109375, 5\n",
            "102, 11, 8.34179973602295, 10\n",
            "53, 563, 5.803059101104736, 5\n",
            "149, 4440, 6.997752666473389, 8\n",
            "183, 1330, 7.768691062927246, 7\n",
            "126, 245, 7.405427932739258, 8\n",
            "60, 49, 7.7270097732543945, 6\n",
            "210, 967, 7.306704521179199, 8\n",
            "187, 4219, 5.573880672454834, 7\n",
            "16, 1067, 6.341635704040527, 5\n",
            "121, 98, 8.726482391357422, 10\n",
            "226, 1325, 8.277438163757324, 10\n",
            "11, 171, 7.559273719787598, 7\n",
            "86, 444, 7.322344779968262, 9\n",
            "107, 1472, 5.953235626220703, 5\n",
            "171, 4226, 8.758400917053223, 8\n",
            "156, 5620, 5.063298225402832, 5\n",
            "137, 1301, 8.697388648986816, 7\n",
            "56, 3212, 6.928066253662109, 8\n",
            "172, 3490, 6.648580551147461, 7\n",
            "234, 4076, 5.9177703857421875, 7\n",
            "118, 238, 8.597826957702637, 10\n",
            "0, 27, 7.202154159545898, 8\n",
            "193, 3796, 8.082159996032715, 8\n",
            "163, 323, 6.365554332733154, 6\n",
            "156, 5345, 7.803063869476318, 7\n",
            "220, 1824, 8.880189895629883, 9\n",
            "162, 756, 6.139988899230957, 6\n",
            "110, 116, 9.149284362792969, 7\n",
            "137, 2659, 10.269908905029297, 10\n",
            "36, 3413, 8.44856071472168, 9\n",
            "187, 690, 6.58233642578125, 1\n",
            "167, 321, 6.841212272644043, 7\n",
            "133, 1890, 7.507264614105225, 8\n",
            "129, 95, 5.544808387756348, 7\n",
            "146, 53, 7.535837650299072, 9\n",
            "112, 5770, 8.471920013427734, 9\n",
            "183, 568, 7.801407814025879, 1\n",
            "218, 141, 8.222213745117188, 9\n",
            "194, 734, 7.785487174987793, 8\n",
            "225, 2535, 6.953102111816406, 7\n",
            "151, 2363, 6.400803565979004, 6\n",
            "109, 803, 7.350949287414551, 9\n",
            "81, 4712, 6.368840217590332, 7\n",
            "44, 12, 8.862146377563477, 8\n",
            "118, 54, 6.751991271972656, 9\n",
            "102, 342, 7.896397113800049, 8\n",
            "107, 2009, 6.663531303405762, 8\n",
            "168, 868, 6.349617004394531, 6\n",
            "176, 176, 6.440457344055176, 5\n",
            "194, 1361, 8.415782928466797, 10\n",
            "35, 538, 7.358068466186523, 5\n",
            "223, 4718, 5.020368576049805, 5\n",
            "146, 591, 7.760030269622803, 7\n",
            "73, 363, 8.217514038085938, 7\n",
            "68, 49, 7.764889717102051, 9\n",
            "147, 286, 7.136568069458008, 6\n",
            "231, 1577, 6.3265228271484375, 6\n",
            "157, 2796, 6.837697982788086, 6\n",
            "47, 225, 7.654847621917725, 7\n",
            "218, 1005, 5.534839630126953, 7\n",
            "230, 1433, 4.9340128898620605, 6\n",
            "168, 3411, 7.174468040466309, 5\n",
            "51, 35, 7.464410781860352, 8\n",
            "148, 561, 6.609582901000977, 7\n",
            "172, 531, 8.511600494384766, 8\n",
            "167, 49, 5.659029006958008, 5\n",
            "65, 3186, 9.270386695861816, 8\n",
            "104, 56, 9.078246116638184, 10\n",
            "68, 273, 7.594644546508789, 9\n",
            "118, 652, 6.0145158767700195, 7\n",
            "77, 99, 9.589359283447266, 8\n",
            "7, 1918, 8.337489128112793, 6\n",
            "216, 784, 8.28272819519043, 8\n",
            "100, 433, 8.649538040161133, 8\n",
            "16, 4956, 7.956645965576172, 7\n",
            "229, 146, 6.827798843383789, 6\n",
            "89, 381, 7.851678371429443, 9\n",
            "115, 854, 5.569051742553711, 7\n",
            "107, 4749, 6.04589319229126, 6\n",
            "211, 211, 7.900627613067627, 10\n",
            "178, 5796, 5.765719413757324, 8\n",
            "107, 4724, 7.04879093170166, 7\n",
            "111, 3454, 6.783951759338379, 7\n",
            "85, 220, 8.761873245239258, 10\n",
            "210, 93, 6.22848653793335, 8\n",
            "161, 161, 8.542623519897461, 9\n",
            "1, 3441, 6.8710432052612305, 8\n",
            "89, 4190, 7.359757423400879, 9\n",
            "111, 3261, 7.670784950256348, 9\n",
            "222, 2372, 8.669456481933594, 7\n",
            "116, 129, 8.135601043701172, 9\n",
            "151, 3428, 6.689448833465576, 6\n",
            "168, 412, 6.796636581420898, 9\n",
            "209, 586, 8.429125785827637, 7\n",
            "191, 60, 8.67280101776123, 8\n",
            "85, 5112, 8.514668464660645, 9\n",
            "91, 392, 8.737781524658203, 8\n",
            "111, 700, 6.510012626647949, 7\n",
            "36, 2347, 8.296622276306152, 8\n",
            "164, 521, 7.295365333557129, 9\n",
            "223, 4620, 3.7464919090270996, 5\n",
            "205, 2748, 7.160243034362793, 7\n",
            "0, 134, 7.34898567199707, 6\n",
            "205, 1537, 6.364124774932861, 5\n",
            "82, 4368, 5.9720940589904785, 7\n",
            "81, 1950, 5.40894889831543, 6\n",
            "18, 5270, 8.233495712280273, 7\n",
            "81, 5092, 6.027674674987793, 7\n",
            "81, 3703, 5.673165321350098, 6\n",
            "138, 1046, 7.342360019683838, 9\n",
            "178, 1596, 6.369205474853516, 7\n",
            "82, 5213, 5.982795715332031, 7\n",
            "172, 3599, 8.059155464172363, 7\n",
            "167, 242, 6.7066497802734375, 8\n",
            "24, 3514, 7.337015628814697, 10\n",
            "168, 1347, 5.599351406097412, 4\n",
            "118, 2796, 6.31516695022583, 7\n",
            "129, 1053, 6.367605209350586, 6\n",
            "153, 436, 8.825555801391602, 9\n",
            "66, 1473, 5.1749162673950195, 4\n",
            "81, 5749, 7.859628677368164, 7\n",
            "65, 28, 7.485249996185303, 9\n",
            "123, 218, 6.914012908935547, 4\n",
            "64, 64, 10.362716674804688, 7\n",
            "133, 28, 9.631585121154785, 9\n",
            "190, 365, 7.88922119140625, 8\n",
            "171, 2523, 7.8711981773376465, 8\n",
            "199, 460, 6.503261089324951, 5\n",
            "187, 731, 5.588758945465088, 6\n",
            "61, 122, 8.285539627075195, 7\n",
            "222, 3734, 8.796669960021973, 9\n",
            "157, 2731, 6.926699638366699, 6\n",
            "47, 825, 8.264662742614746, 9\n",
            "81, 8, 8.474679946899414, 7\n",
            "172, 366, 7.772689342498779, 8\n",
            "180, 603, 7.786850929260254, 10\n",
            "111, 2519, 8.518681526184082, 9\n",
            "71, 172, 6.633735179901123, 4\n",
            "90, 2504, 9.265127182006836, 9\n",
            "107, 3110, 8.23947811126709, 9\n",
            "96, 800, 7.761787414550781, 9\n",
            "91, 10, 8.76473617553711, 7\n",
            "36, 2592, 8.49109172821045, 7\n",
            "118, 1198, 5.687198638916016, 7\n",
            "107, 2711, 6.748159408569336, 7\n",
            "149, 5310, 5.053190231323242, 7\n",
            "181, 681, 7.993494510650635, 9\n",
            "106, 199, 7.458979606628418, 7\n",
            "11, 28, 8.683640480041504, 7\n",
            "209, 776, 5.861381530761719, 6\n",
            "81, 3425, 5.1175737380981445, 7\n",
            "73, 46, 6.837206840515137, 7\n",
            "148, 298, 8.048839569091797, 9\n",
            "104, 3541, 9.580411911010742, 10\n",
            "62, 603, 7.313007831573486, 9\n",
            "47, 42, 6.44688081741333, 8\n",
            "81, 3446, 6.842090606689453, 7\n",
            "229, 2113, 7.204813480377197, 7\n",
            "232, 218, 7.40131139755249, 8\n",
            "157, 3658, 5.940868377685547, 4\n",
            "97, 2958, 8.485261917114258, 9\n",
            "89, 3655, 7.815296173095703, 8\n",
            "190, 521, 6.38916015625, 9\n",
            "121, 2155, 7.389525413513184, 7\n",
            "219, 3141, 7.497653961181641, 9\n",
            "73, 172, 4.9436259269714355, 7\n",
            "113, 3852, 6.957027435302734, 8\n",
            "133, 1666, 7.690927505493164, 8\n",
            "1, 539, 7.451601982116699, 6\n",
            "148, 2466, 7.037454605102539, 4\n",
            "81, 2754, 6.6241912841796875, 6\n",
            "24, 4653, 7.547379493713379, 7\n",
            "72, 827, 6.421304702758789, 5\n",
            "190, 2641, 5.909017562866211, 6\n",
            "172, 5472, 6.3190107345581055, 5\n",
            "99, 392, 8.537385940551758, 6\n",
            "143, 2107, 7.759345054626465, 8\n",
            "90, 2069, 7.9235148429870605, 9\n",
            "111, 3066, 7.462785720825195, 8\n",
            "129, 2265, 6.72152042388916, 8\n",
            "134, 2432, 7.543861389160156, 8\n",
            "32, 813, 9.798662185668945, 9\n",
            "125, 316, 7.685287952423096, 7\n",
            "81, 4107, 6.917385101318359, 7\n",
            "131, 750, 8.370654106140137, 6\n",
            "116, 1384, 9.066751480102539, 8\n",
            "148, 436, 7.586349964141846, 7\n",
            "137, 2904, 7.783815860748291, 10\n",
            "81, 1636, 7.012114524841309, 5\n",
            "133, 839, 8.038833618164062, 9\n",
            "104, 4904, 7.567028522491455, 9\n",
            "134, 3769, 7.468131065368652, 6\n",
            "81, 2873, 6.575759410858154, 7\n",
            "118, 843, 5.910782337188721, 5\n",
            "18, 4785, 8.000720977783203, 9\n",
            "125, 585, 6.5794525146484375, 8\n",
            "190, 2457, 6.952170372009277, 5\n",
            "76, 331, 7.041259288787842, 6\n",
            "40, 1682, 8.700865745544434, 7\n",
            "107, 5279, 7.480254173278809, 7\n",
            "32, 124, 10.11849308013916, 8\n",
            "91, 2938, 7.886244773864746, 10\n",
            "168, 5161, 5.261497497558594, 6\n",
            "85, 273, 6.877018928527832, 7\n",
            "92, 201, 6.500205993652344, 3\n",
            "152, 52, 8.87529468536377, 9\n",
            "176, 2385, 7.602320671081543, 7\n",
            "81, 4491, 7.217126846313477, 7\n",
            "74, 375, 6.261715888977051, 5\n",
            "53, 112, 7.812000274658203, 8\n",
            "193, 2551, 7.298700332641602, 8\n",
            "168, 4626, 6.538852691650391, 5\n",
            "117, 1456, 9.972138404846191, 10\n",
            "6, 133, 6.523769378662109, 4\n",
            "47, 317, 6.592833042144775, 7\n",
            "99, 119, 7.029917240142822, 7\n",
            "111, 5354, 4.78139591217041, 8\n",
            "115, 10, 7.0373005867004395, 6\n",
            "171, 3663, 7.431706428527832, 9\n",
            "124, 1250, 7.326901912689209, 9\n",
            "156, 308, 6.01241397857666, 7\n",
            "90, 170, 9.145088195800781, 10\n",
            "153, 1546, 10.294435501098633, 10\n",
            "202, 49, 7.054549217224121, 10\n",
            "27, 4171, 5.7102556228637695, 5\n",
            "149, 3189, 7.757930755615234, 7\n",
            "33, 378, 8.570136070251465, 7\n",
            "219, 4153, 7.775417327880859, 9\n",
            "107, 5115, 6.636898994445801, 6\n",
            "147, 5389, 5.305357933044434, 8\n",
            "77, 247, 7.037480354309082, 9\n",
            "162, 231, 7.717277526855469, 8\n",
            "233, 4189, 7.08182954788208, 9\n",
            "172, 4283, 8.41640853881836, 8\n",
            "111, 1425, 6.4858503341674805, 7\n",
            "133, 10, 9.505807876586914, 7\n",
            "79, 1779, 4.276177406311035, 10\n",
            "191, 3695, 7.698051452636719, 7\n",
            "59, 2145, 8.30097484588623, 9\n",
            "65, 5384, 7.652207851409912, 10\n",
            "172, 5171, 7.256422996520996, 8\n",
            "118, 88, 5.926112651824951, 6\n",
            "149, 5339, 6.613055229187012, 6\n",
            "94, 2816, 7.204293251037598, 8\n",
            "0, 239, 8.890360832214355, 9\n",
            "65, 5752, 6.5901360511779785, 6\n",
            "86, 11, 8.261817932128906, 10\n",
            "70, 597, 6.120993614196777, 7\n",
            "123, 235, 4.962878227233887, 5\n",
            "212, 4443, 5.986007213592529, 3\n",
            "226, 4557, 8.678075790405273, 7\n",
            "108, 4942, 9.581438064575195, 8\n",
            "65, 478, 7.170594215393066, 8\n",
            "137, 239, 10.051704406738281, 10\n",
            "111, 982, 6.256601333618164, 8\n",
            "185, 1361, 10.006827354431152, 6\n",
            "118, 2341, 4.3569488525390625, 8\n",
            "58, 851, 8.21352481842041, 10\n",
            "178, 5024, 6.300886154174805, 8\n",
            "166, 334, 7.277447700500488, 10\n",
            "111, 4571, 7.174285411834717, 8\n",
            "8, 146, 9.610383987426758, 9\n",
            "219, 5502, 6.996765613555908, 7\n",
            "162, 2960, 6.03913688659668, 6\n",
            "111, 2413, 6.889577388763428, 7\n",
            "27, 133, 8.114202499389648, 5\n",
            "209, 29, 6.826930999755859, 8\n",
            "104, 5694, 8.39086627960205, 8\n",
            "199, 1225, 6.60351037979126, 7\n",
            "118, 2419, 5.28018856048584, 6\n",
            "172, 2506, 6.679184436798096, 7\n",
            "81, 4958, 6.019874572753906, 6\n",
            "194, 342, 8.031779289245605, 9\n",
            "81, 3984, 7.491816520690918, 7\n",
            "147, 4038, 5.142139434814453, 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import no_grad\n",
        "\n",
        "precisions = dict()\n",
        "recalls = dict()\n",
        "\n",
        "k=100\n",
        "threshold=3.5\n",
        "\n",
        "with no_grad():\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # get the number of actual relevant item\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # get the number of recommended item that are predicted relevant and within topk\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # get the number of recommended item that are also actually relevant within topk\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        print(f\"uid {uid}, n_rel {n_rel}, n_rec_k {n_rec_k}, n_rel_and_rec_k {n_rel_and_rec_k}\")\n",
        "\n",
        "        # Precision@k: Proportion of recommended items that are relevant\n",
        "        # when number of recommended item is undefined. We here set it to 0.\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@k: Proportion or recommended items that are recommended\n",
        "        # When n_rel is 0; Recall is undefined. We here set it to 0.\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n"
      ],
      "metadata": {
        "id": "hlz9HxPhJ2OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e330be-7bda-4dbf-f53e-150d80574852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uid 33, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 199, n_rel 26, n_rec_k 28, n_rel_and_rec_k 26\n",
            "uid 193, n_rel 39, n_rec_k 40, n_rel_and_rec_k 39\n",
            "uid 1, n_rel 23, n_rec_k 25, n_rel_and_rec_k 23\n",
            "uid 20, n_rel 14, n_rec_k 15, n_rel_and_rec_k 14\n",
            "uid 84, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 210, n_rel 41, n_rec_k 41, n_rel_and_rec_k 41\n",
            "uid 216, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 111, n_rel 182, n_rec_k 100, n_rel_and_rec_k 99\n",
            "uid 212, n_rel 27, n_rec_k 29, n_rel_and_rec_k 27\n",
            "uid 209, n_rel 18, n_rec_k 18, n_rel_and_rec_k 18\n",
            "uid 61, n_rel 50, n_rec_k 50, n_rel_and_rec_k 50\n",
            "uid 156, n_rel 78, n_rec_k 81, n_rel_and_rec_k 78\n",
            "uid 81, n_rel 161, n_rec_k 100, n_rel_and_rec_k 100\n",
            "uid 96, n_rel 31, n_rec_k 31, n_rel_and_rec_k 31\n",
            "uid 168, n_rel 108, n_rec_k 100, n_rel_and_rec_k 100\n",
            "uid 162, n_rel 80, n_rec_k 81, n_rel_and_rec_k 80\n",
            "uid 71, n_rel 6, n_rec_k 7, n_rel_and_rec_k 6\n",
            "uid 230, n_rel 35, n_rec_k 36, n_rel_and_rec_k 35\n",
            "uid 226, n_rel 37, n_rec_k 39, n_rel_and_rec_k 37\n",
            "uid 27, n_rel 39, n_rec_k 39, n_rel_and_rec_k 39\n",
            "uid 233, n_rel 21, n_rec_k 21, n_rel_and_rec_k 21\n",
            "uid 7, n_rel 60, n_rec_k 61, n_rel_and_rec_k 60\n",
            "uid 151, n_rel 92, n_rec_k 92, n_rel_and_rec_k 92\n",
            "uid 153, n_rel 50, n_rec_k 50, n_rel_and_rec_k 50\n",
            "uid 123, n_rel 28, n_rec_k 29, n_rel_and_rec_k 28\n",
            "uid 100, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 175, n_rel 22, n_rec_k 23, n_rel_and_rec_k 22\n",
            "uid 206, n_rel 26, n_rec_k 26, n_rel_and_rec_k 26\n",
            "uid 125, n_rel 33, n_rec_k 33, n_rel_and_rec_k 33\n",
            "uid 148, n_rel 66, n_rec_k 69, n_rel_and_rec_k 66\n",
            "uid 149, n_rel 77, n_rec_k 80, n_rel_and_rec_k 77\n",
            "uid 74, n_rel 35, n_rec_k 35, n_rel_and_rec_k 35\n",
            "uid 211, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 31, n_rel 19, n_rec_k 19, n_rel_and_rec_k 19\n",
            "uid 213, n_rel 23, n_rec_k 23, n_rel_and_rec_k 23\n",
            "uid 218, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 107, n_rel 89, n_rec_k 89, n_rel_and_rec_k 89\n",
            "uid 41, n_rel 12, n_rec_k 13, n_rel_and_rec_k 12\n",
            "uid 217, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 174, n_rel 22, n_rec_k 23, n_rel_and_rec_k 22\n",
            "uid 78, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 65, n_rel 32, n_rec_k 34, n_rel_and_rec_k 32\n",
            "uid 99, n_rel 20, n_rec_k 20, n_rel_and_rec_k 20\n",
            "uid 89, n_rel 97, n_rec_k 97, n_rel_and_rec_k 97\n",
            "uid 11, n_rel 19, n_rec_k 19, n_rel_and_rec_k 19\n",
            "uid 197, n_rel 31, n_rec_k 31, n_rel_and_rec_k 31\n",
            "uid 146, n_rel 28, n_rec_k 30, n_rel_and_rec_k 28\n",
            "uid 188, n_rel 31, n_rec_k 32, n_rel_and_rec_k 31\n",
            "uid 225, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 104, n_rel 86, n_rec_k 86, n_rel_and_rec_k 86\n",
            "uid 66, n_rel 28, n_rec_k 29, n_rel_and_rec_k 28\n",
            "uid 190, n_rel 66, n_rec_k 68, n_rel_and_rec_k 66\n",
            "uid 231, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 63, n_rel 13, n_rec_k 13, n_rel_and_rec_k 13\n",
            "uid 58, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 124, n_rel 32, n_rec_k 32, n_rel_and_rec_k 32\n",
            "uid 54, n_rel 9, n_rec_k 10, n_rel_and_rec_k 9\n",
            "uid 221, n_rel 13, n_rec_k 13, n_rel_and_rec_k 13\n",
            "uid 112, n_rel 16, n_rec_k 16, n_rel_and_rec_k 16\n",
            "uid 187, n_rel 18, n_rec_k 21, n_rel_and_rec_k 18\n",
            "uid 178, n_rel 30, n_rec_k 30, n_rel_and_rec_k 30\n",
            "uid 57, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 129, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 43, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 118, n_rel 107, n_rec_k 100, n_rel_and_rec_k 98\n",
            "uid 75, n_rel 22, n_rec_k 22, n_rel_and_rec_k 22\n",
            "uid 32, n_rel 22, n_rec_k 22, n_rel_and_rec_k 22\n",
            "uid 55, n_rel 9, n_rec_k 9, n_rel_and_rec_k 9\n",
            "uid 10, n_rel 9, n_rec_k 9, n_rel_and_rec_k 9\n",
            "uid 192, n_rel 28, n_rec_k 28, n_rel_and_rec_k 28\n",
            "uid 0, n_rel 33, n_rec_k 33, n_rel_and_rec_k 33\n",
            "uid 25, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 181, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 39, n_rel 23, n_rec_k 24, n_rel_and_rec_k 23\n",
            "uid 207, n_rel 14, n_rec_k 15, n_rel_and_rec_k 14\n",
            "uid 222, n_rel 31, n_rec_k 31, n_rel_and_rec_k 31\n",
            "uid 143, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 105, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 184, n_rel 13, n_rec_k 13, n_rel_and_rec_k 13\n",
            "uid 115, n_rel 23, n_rec_k 23, n_rel_and_rec_k 23\n",
            "uid 232, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 93, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 38, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 171, n_rel 38, n_rec_k 39, n_rel_and_rec_k 38\n",
            "uid 172, n_rel 109, n_rec_k 100, n_rel_and_rec_k 99\n",
            "uid 179, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 166, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 69, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 202, n_rel 30, n_rec_k 30, n_rel_and_rec_k 30\n",
            "uid 223, n_rel 36, n_rec_k 36, n_rel_and_rec_k 36\n",
            "uid 194, n_rel 19, n_rec_k 19, n_rel_and_rec_k 19\n",
            "uid 144, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 116, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 12, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 180, n_rel 24, n_rec_k 25, n_rel_and_rec_k 24\n",
            "uid 60, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 198, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 40, n_rel 23, n_rec_k 23, n_rel_and_rec_k 23\n",
            "uid 106, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 219, n_rel 25, n_rec_k 25, n_rel_and_rec_k 25\n",
            "uid 15, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 228, n_rel 12, n_rec_k 12, n_rel_and_rec_k 12\n",
            "uid 136, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 167, n_rel 23, n_rec_k 23, n_rel_and_rec_k 23\n",
            "uid 152, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 36, n_rel 19, n_rec_k 19, n_rel_and_rec_k 19\n",
            "uid 131, n_rel 25, n_rec_k 27, n_rel_and_rec_k 25\n",
            "uid 186, n_rel 16, n_rec_k 17, n_rel_and_rec_k 16\n",
            "uid 163, n_rel 29, n_rec_k 29, n_rel_and_rec_k 29\n",
            "uid 51, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 157, n_rel 27, n_rec_k 27, n_rel_and_rec_k 27\n",
            "uid 128, n_rel 18, n_rec_k 19, n_rel_and_rec_k 18\n",
            "uid 82, n_rel 26, n_rec_k 26, n_rel_and_rec_k 26\n",
            "uid 95, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 224, n_rel 24, n_rec_k 24, n_rel_and_rec_k 24\n",
            "uid 189, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 208, n_rel 18, n_rec_k 19, n_rel_and_rec_k 18\n",
            "uid 86, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 133, n_rel 44, n_rec_k 44, n_rel_and_rec_k 44\n",
            "uid 29, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 94, n_rel 22, n_rec_k 22, n_rel_and_rec_k 22\n",
            "uid 4, n_rel 24, n_rec_k 24, n_rel_and_rec_k 24\n",
            "uid 134, n_rel 62, n_rec_k 62, n_rel_and_rec_k 62\n",
            "uid 19, n_rel 10, n_rec_k 11, n_rel_and_rec_k 10\n",
            "uid 165, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 164, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 117, n_rel 35, n_rec_k 35, n_rel_and_rec_k 35\n",
            "uid 122, n_rel 37, n_rec_k 37, n_rel_and_rec_k 37\n",
            "uid 234, n_rel 28, n_rec_k 29, n_rel_and_rec_k 28\n",
            "uid 137, n_rel 24, n_rec_k 24, n_rel_and_rec_k 24\n",
            "uid 214, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 97, n_rel 17, n_rec_k 18, n_rel_and_rec_k 17\n",
            "uid 119, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 83, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 147, n_rel 17, n_rec_k 18, n_rel_and_rec_k 17\n",
            "uid 183, n_rel 12, n_rec_k 13, n_rel_and_rec_k 12\n",
            "uid 59, n_rel 20, n_rec_k 22, n_rel_and_rec_k 20\n",
            "uid 158, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 70, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 64, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 85, n_rel 29, n_rec_k 29, n_rel_and_rec_k 29\n",
            "uid 91, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 56, n_rel 22, n_rec_k 22, n_rel_and_rec_k 22\n",
            "uid 132, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 176, n_rel 17, n_rec_k 19, n_rel_and_rec_k 17\n",
            "uid 76, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 73, n_rel 35, n_rec_k 38, n_rel_and_rec_k 35\n",
            "uid 90, n_rel 32, n_rec_k 32, n_rel_and_rec_k 32\n",
            "uid 35, n_rel 23, n_rec_k 23, n_rel_and_rec_k 23\n",
            "uid 92, n_rel 4, n_rec_k 5, n_rel_and_rec_k 4\n",
            "uid 102, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 44, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 173, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 80, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 47, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 26, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 229, n_rel 27, n_rec_k 27, n_rel_and_rec_k 27\n",
            "uid 53, n_rel 12, n_rec_k 13, n_rel_and_rec_k 12\n",
            "uid 37, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 110, n_rel 9, n_rec_k 9, n_rel_and_rec_k 9\n",
            "uid 68, n_rel 18, n_rec_k 19, n_rel_and_rec_k 18\n",
            "uid 6, n_rel 17, n_rec_k 18, n_rel_and_rec_k 17\n",
            "uid 185, n_rel 13, n_rec_k 13, n_rel_and_rec_k 13\n",
            "uid 191, n_rel 29, n_rec_k 29, n_rel_and_rec_k 29\n",
            "uid 204, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 9, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 114, n_rel 20, n_rec_k 21, n_rel_and_rec_k 20\n",
            "uid 16, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 45, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 21, n_rel 6, n_rec_k 7, n_rel_and_rec_k 6\n",
            "uid 235, n_rel 2, n_rec_k 3, n_rel_and_rec_k 2\n",
            "uid 205, n_rel 18, n_rec_k 18, n_rel_and_rec_k 18\n",
            "uid 23, n_rel 5, n_rec_k 6, n_rel_and_rec_k 5\n",
            "uid 130, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 24, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 109, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 22, n_rel 10, n_rec_k 10, n_rel_and_rec_k 10\n",
            "uid 103, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 138, n_rel 14, n_rec_k 14, n_rel_and_rec_k 14\n",
            "uid 108, n_rel 18, n_rec_k 19, n_rel_and_rec_k 18\n",
            "uid 196, n_rel 22, n_rec_k 22, n_rel_and_rec_k 22\n",
            "uid 150, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 42, n_rel 9, n_rec_k 9, n_rel_and_rec_k 9\n",
            "uid 28, n_rel 12, n_rec_k 12, n_rel_and_rec_k 12\n",
            "uid 220, n_rel 31, n_rec_k 31, n_rel_and_rec_k 31\n",
            "uid 72, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 79, n_rel 12, n_rec_k 12, n_rel_and_rec_k 12\n",
            "uid 201, n_rel 11, n_rec_k 11, n_rel_and_rec_k 11\n",
            "uid 155, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 139, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 88, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 98, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 170, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 161, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 87, n_rel 15, n_rec_k 15, n_rel_and_rec_k 15\n",
            "uid 145, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 3, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 18, n_rel 9, n_rec_k 9, n_rel_and_rec_k 9\n",
            "uid 215, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 160, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 2, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 121, n_rel 17, n_rec_k 17, n_rel_and_rec_k 17\n",
            "uid 120, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 5, n_rel 7, n_rec_k 7, n_rel_and_rec_k 7\n",
            "uid 113, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 203, n_rel 3, n_rec_k 4, n_rel_and_rec_k 3\n",
            "uid 126, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 49, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 135, n_rel 6, n_rec_k 6, n_rel_and_rec_k 6\n",
            "uid 67, n_rel 4, n_rec_k 4, n_rel_and_rec_k 4\n",
            "uid 14, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 140, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 8, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 62, n_rel 3, n_rec_k 3, n_rel_and_rec_k 3\n",
            "uid 77, n_rel 8, n_rec_k 8, n_rel_and_rec_k 8\n",
            "uid 101, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 17, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 48, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 13, n_rel 2, n_rec_k 2, n_rel_and_rec_k 2\n",
            "uid 177, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 169, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n",
            "uid 195, n_rel 5, n_rec_k 5, n_rel_and_rec_k 5\n",
            "uid 182, n_rel 1, n_rec_k 1, n_rel_and_rec_k 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision and recall can then be averaged over all users\n",
        "precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
        "recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
        "print(f\"precision @ {k}: {sum(prec for prec in precisions.values()) / len(precisions)}\")\n",
        "print(f\"recall @ {k}: {sum(rec for rec in recalls.values()) / len(recalls)}\")\n",
        "\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "print(f\"F1 score @ {k}: {f1_score}\")"
      ],
      "metadata": {
        "id": "0-OLEY7HKX5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb2b102-3c5b-4eb3-aab7-4435cb26c9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision @ 100: 0.9832076557038668\n",
            "recall @ 100: 0.9951568960424356\n",
            "F1 score @ 100: 0.98914618941362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.jointplot(x='mean_rating', y='number_of_ratings', data=agg_ratings_GT200, alpha=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "lgKnyASXwhFq",
        "outputId": "3e8c412f-95a0-44f1-af58-038770b9a153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.JointGrid at 0x7b4c6b1a5c30>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}